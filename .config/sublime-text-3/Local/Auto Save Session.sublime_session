{
	"folder_history":
	[
		"/home/mmphego/mnt/cmc3/home/mmphego/learning_fast",
		"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src",
		"/home/mmphego/mnt/cmc3/home/mmphego/src/katsdpingest",
		"/home/mmphego/mnt/cmc3/home/alec/katsdpingest",
		"/home/mmphego/exercism",
		"/home/mmphego/mnt/cmc3/srv/casperfpga",
		"/home/mmphego/mnt/cmc3/srv/corr2",
		"/home/mmphego/mnt/cmc3/usr/local/src/corr2",
		"/home/mmphego/mnt/cmc3/usr/local/src/corr2/scripts",
		"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests",
		"/home/mmphego/GitHub/OracleExecise",
		"/home/mmphego/mnt/cmc3/home/mmphego/src",
		"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Notes",
		"/home/mmphego/jenkins",
		"/home/mmphego",
		"/home/mmphego/GitHub/CBF-Tests-Automation",
		"/home/mmphego/mnt/cmc3/usr/local/src",
		"/home/mmphego/GitHub/programming-talks",
		"/home/mmphego/GitHub/mmphego.github.io/_site",
		"/home/mmphego/GitHub/axxess_scrapper",
		"/home/mmphego/GitHub",
		"/home/mmphego/mnt/dbelab04/home/mmphego/src/mkat_fpga_tests",
		"/home/mmphego/mnt/cmc3/usr/local/src/nosekatreport",
		"/home/mmphego/mnt/cmc1/home/avnuser/AVNTests",
		"/home/mmphego/mnt/cmc1/home/avnuser/AVN_Tests/mkat_fpga_tests",
		"/home/mmphego/GitHub/SublimeProj",
		"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress",
		"/home/mmphego/GitHub/mmphego.github.io",
		"/home/mmphego/GitHub/mmphego.github.io/img",
		"/home/mmphego/mnt/cmc3/home/mmphego/src/CBF-System-Dashboard",
		"/home/mmphego/mnt/dbelab06/srv/corr2",
		"/home/mmphego/mnt/cmc3/usr/local/src/casperfpga",
		"/home/mmphego/mnt/dbelab06/srv/casperfpga",
		"/home/mmphego/mnt/dbelab06/home/mmphego/src/mkat_fpga_tests",
		"/home/mmphego/mnt/pi/home",
		"/home/mmphego/mnt/cmc3/home/mmphego",
		"/home/mmphego/mnt/dbelab06/home/mmphego/src",
		"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/C.Programming",
		"/home/mmphego/Dropbox/Telkom",
		"/home/mmphego/Documents/Arduino/espurna",
		"/home/mmphego/mnt/dbelab06/home/mmphego/src/node-red-docker",
		"/home/mmphego/mnt/dbelab06/home/mmphego/src/CBF-System-Dashboard",
		"/home/mmphego/tmp/tweeterBot",
		"/home/mmphego/tmp/gitpages",
		"/home/mmphego/tmp/anuditverma.github.io",
		"/home/mmphego/tmp/mmphego.github.io",
		"/home/mmphego/tmp/hyd",
		"/home/mmphego/tmp/tweeterBot/TwitterFollowBot",
		"/home/mmphego/mnt/cmc3/home/mmphego/cbf_dash",
		"/home/mmphego/mnt/cmc2/home/mmphego/src/mkat_fpga_tests",
		"/home/mmphego/mnt/cmc2/home/mmphego/src",
		"/home/mmphego/mnt/dbelab06/srv/corr2/corr2",
		"/home/mmphego/mnt/dbelab06/etc/mkat_cbf_config",
		"/home/mmphego/mnt/cmc2/srv/corr2",
		"/home/mmphego/mnt/cmc2/home/mmphego/src/mkat_fpga_tests/scripts",
		"/home/mmphego/mnt/cmc2/srv/katcp-python",
		"/home/mmphego/mnt/cmc2/srv/casperfpga",
		"/home/mmphego/mnt/dbelab04/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
		"/home/mmphego/mnt/dbelab04/home/mmphego/mkat_fpga_tests/mkat_fpga_tests",
		"/home/mmphego/mnt/dbelab04/usr/local/src/nosekatreport",
		"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/C.Programming/Snippets/Sampled_Values_example",
		"/home/mmphego/mnt/cmc3/usr/local/src/corr2/src",
		"/home/mmphego/mnt/cmc2/srv/casperfpga/src",
		"/home/mmphego/mnt/dbelab04/usr/local/src/corr2",
		"/home/mmphego/Work/espurna/code",
		"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/C.Programming/Snippets",
		"/home/mmphego/mnt/pi/home/pi/AlexaPI",
		"/home/mmphego/mnt/pi/home/pi/AmazonAWS/Homely",
		"/home/mmphego/aws/alexa-smarthome/sample_lambda/python",
		"/home/mmphego/mnt/pi/home/pi/AmazonAWS",
		"/home/mmphego/aws/DSTV-aws-iot-alexa-voice",
		"/home/mmphego/aws/intel-edison-aws-iot-alexa-voice",
		"/home/mmphego/aws/alexa_home_control",
		"/home/mmphego/Dropbox/MTech Stuff(Deprecated)/HomeAutoPi/Homely/1. Raspberry Pi/1. AlexaPi/IOT-Pi3-Alexa-Automation",
		"/home/mmphego/tmp",
		"/home/mmphego/mnt/dbelab04/usr/local/src/corr2/scripts",
		"/home/mmphego/mnt/dbelab04/home/mmphego/mkat_fpga_tests",
		"/home/mmphego/mnt/cmc3/usr/local",
		"/home/mmphego/mnt/dbelab04/home/mmphego",
		"/home/mmphego/Work/sanketplus.github.io",
		"/home/mmphego/mnt/dbelab04/home/mmphego/src",
		"/home/mmphego/Work/DSTV_A6_ESP8266_Remote",
		"/home/mmphego/Dropbox/Dropbox/mmphego.github.io",
		"/home/mmphego/mnt/dbelab04/usr/local/src",
		"/home/mmphego/Work/espurna",
		"/home/mmphego/Arduino/libraries",
		"/home/mmphego/mnt/dbelab04/usr/local/src/CBF-System-Dashboard",
		"/home/mmphego/mnt/dbelab04/home/mmphego/temp/CBF-System-Dashboard",
		"/home/mmphego/mnt/dbelab04/home/mmphego/CBF-System-Dashboard",
		"/home/mmphego/mnt/dbelab04/usr/local/src/CBF-Tests-Automation",
		"/home/mmphego/mnt/dbelab04/home/mmphego/Docker-nodered",
		"/home/mmphego/mnt/dbelab04/usr/local/src/cbf-jenkins-docker",
		"/home/mmphego/mnt/pi/home/pi",
		"/home/mmphego/mnt/dbelab04/usr/local/src/casperfpga",
		"/home/mmphego/mnt/dbelab04/usr/local/src/katcp-python",
		"/home/mmphego/Dropbox/Dropbox/MTech Stuff/HomeAutoPi/1. Raspberry Pi/3. Telegram/TelegramBot",
		"/home/mmphego/mnt/pi/home/pi/AlexaPi",
		"/home/mmphego/BackupHDD/DISTROS/osmc/PyWhatsapp",
		"/home/mmphego/RaspberryPiProjects/pywakeonlan/wakeonlan",
		"/home/mmphego/mnt/dbelab04"
	],
	"last_version": 3176,
	"last_window_id": 169,
	"log_indexing": false,
	"settings":
	{
		"new_window_height": 0.0,
		"new_window_settings":
		{
			"auto_complete":
			{
				"selected_items":
				[
					[
						"time",
						"timedebug"
					],
					[
						"log",
						"logLevel"
					],
					[
						"LO",
						"LoggingClass"
					],
					[
						"Stre",
						"StreamHandler\tclass"
					],
					[
						"Lo",
						"LoggingClass"
					],
					[
						"std",
						"stderr\tinstance"
					],
					[
						"hand",
						"handlers\tstatement"
					],
					[
						"_dump_",
						"_dump_timestamp_readable"
					],
					[
						"_co",
						"_config_info"
					],
					[
						"dict",
						"dictsMerger\tfunction"
					],
					[
						"_lo",
						"_logLevel"
					],
					[
						"logg",
						"logger"
					],
					[
						"IP",
						"IPython"
					],
					[
						"cret",
						"create"
					],
					[
						"corr",
						"correlator"
					],
					[
						"mer",
						"merge_dicts"
					],
					[
						"sensor",
						"sensors_info"
					],
					[
						"_dum",
						"_dump_timestamp_readable"
					],
					[
						"cle",
						"clearall"
					],
					[
						"logi",
						"logging"
					],
					[
						"set",
						"setLevel\tfunction"
					],
					[
						"s",
						"stop"
					],
					[
						"r",
						"RUN"
					],
					[
						"WORK",
						"WORKDIR\t(Dockerfile)"
					],
					[
						"mk",
						"mkat_fpga_tests\t(test_cbf.py)"
					],
					[
						"mkat",
						"mkat_fpga_tests"
					],
					[
						"bit",
						"bitstream\t(test_cbf.py)"
					],
					[
						"file",
						"filename\t(test_cbf.py)"
					],
					[
						"get_s",
						"get_system_information\t(test_cbf.py)"
					],
					[
						"logs",
						"logs_sensors"
					],
					[
						"tear",
						"teardown_package"
					],
					[
						"ac",
						"activeCount\tstatement"
					],
					[
						"Array",
						"Array-List"
					],
					[
						"_kat",
						"_katcp_rct_sensor"
					],
					[
						"reosue",
						"resource_client"
					],
					[
						"exc_",
						"exc_info=True\t(sensor_poll.py)"
					],
					[
						"ger",
						"get_sensors"
					],
					[
						"Ke",
						"KeyboardInterrupt\tclass"
					],
					[
						"repl",
						"reply.reply_ok"
					],
					[
						"info",
						"informs"
					],
					[
						"katc",
						"katcp_rct_sensor"
					],
					[
						"Sens",
						"SensorPoll"
					],
					[
						"sen",
						"sensor_poll\t(sensor_poll.py)"
					],
					[
						"Not",
						"NotImplementedError\tclass"
					],
					[
						"katcp_cli",
						"katcp_client_port"
					],
					[
						"NotI",
						"NotImplementedError\tclass"
					],
					[
						"arra",
						"array_name"
					],
					[
						"if",
						"ifmain\tif __name__ == '__main__'"
					],
					[
						"exc",
						"exc_info=True"
					],
					[
						"sec",
						"sec_sensors_katcp_con"
					],
					[
						"e",
						"except"
					],
					[
						"new_",
						"new_mapping"
					],
					[
						"colle",
						"collections"
					],
					[
						"order",
						"ordered_sensor_dict"
					],
					[
						"prim",
						"primary_client"
					],
					[
						"fom",
						"format"
					],
					[
						"json",
						"json_dumps"
					],
					[
						"js",
						"json_dumps\t(sensor_poll.py)"
					],
					[
						"cbf",
						"cbf_sensors_dash.py"
					],
					[
						"bh",
						"bhost_fpga"
					],
					[
						"fp",
						"fhost_fpga\tmodule"
					],
					[
						"Run",
						"RuntimeError"
					],
					[
						"thre",
						"threaded_fpga_operation"
					],
					[
						"auto",
						"automagically"
					],
					[
						"start",
						"startall"
					],
					[
						"sona",
						"sonarstart"
					],
					[
						"port",
						"portainerstart"
					],
					[
						"poe",
						"portainerstop"
					],
					[
						"por",
						"portainer"
					],
					[
						"soan",
						"sonar"
					],
					[
						"act",
						"active_frames"
					],
					[
						"quit",
						"quit_event"
					],
					[
						"real",
						"realimag"
					],
					[
						"basel",
						"baseline_correlation_products_n_chans"
					],
					[
						"baseli",
						"baselines"
					],
					[
						"baselie",
						"baseline_correlation_products_n_bls"
					],
					[
						"baseline",
						"baseline_correlation_products_n_bls"
					],
					[
						"n",
						"n_accs"
					],
					[
						"baseloi",
						"baseline_correlation_products_n_bls"
					],
					[
						"chan",
						"channels"
					],
					[
						"get_",
						"get_plot_data"
					],
					[
						"baseline_c",
						"baseline_correlation_products_n_chans"
					],
					[
						"base",
						"baselines"
					],
					[
						"le",
						"legend"
					],
					[
						"get",
						"getattr"
					],
					[
						"n-",
						"n-xengs"
					],
					[
						"qui",
						"quit_event"
					],
					[
						"f",
						"figure"
					],
					[
						"inf",
						"info"
					],
					[
						"de",
						"debug"
					],
					[
						"star",
						"startswith"
					],
					[
						"Ru",
						"RuntimeError"
					],
					[
						"Ex",
						"Exception\t(utils.py)"
					],
					[
						"conf",
						"config_info\tstatement"
					],
					[
						"config",
						"config_info"
					],
					[
						"feng",
						"fengine_conf"
					],
					[
						"outp",
						"output_products"
					],
					[
						"des",
						"destination"
					],
					[
						"Dict",
						"DictObject"
					],
					[
						"cong",
						"config_info"
					],
					[
						"con",
						"config_info"
					],
					[
						"n_c",
						"n_chans\tstatement"
					],
					[
						"Ska",
						"SkarabTransport"
					],
					[
						"trans",
						"transport\t(transport_tapcp.py)"
					],
					[
						"clas",
						"classmethod\tclass"
					],
					[
						"stop",
						"stop_substream\tstatement"
					],
					[
						"end",
						"end_ip"
					],
					[
						"has",
						"hasattr"
					],
					[
						"Asse",
						"AssertionError"
					],
					[
						"serve",
						"servlet_ip"
					],
					[
						"serv",
						"servlet_ip"
					],
					[
						"ser",
						"servlet_port"
					],
					[
						"se",
						"sensors"
					],
					[
						"confi",
						"config_info"
					],
					[
						"Ba",
						"BASELINES"
					],
					[
						"h5",
						"h5_file"
					],
					[
						"output",
						"output_products"
					],
					[
						"xeng",
						"xengine_conf"
					],
					[
						"xe",
						"xengine_conf"
					],
					[
						"fen",
						"fengine_conf"
					],
					[
						"fe",
						"fengine_conf"
					],
					[
						"stat",
						"staticmethod\tclass"
					],
					[
						"Thre",
						"Thread"
					],
					[
						"di",
						"div\tTag"
					],
					[
						"local",
						"local_threadpool"
					],
					[
						"NUM_",
						"NUM_XENG"
					],
					[
						"heap",
						"heap_data"
					],
					[
						"n_chan",
						"n_chans_per_substream"
					]
				]
			},
			"build_system_choices":
			[
				[
					[
						[
							"Packages/C++/C++ Single File.sublime-build",
							""
						],
						[
							"Packages/C++/C++ Single File.sublime-build",
							"Run"
						]
					],
					[
						"Packages/C++/C++ Single File.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/Makefile/Make.sublime-build",
							""
						],
						[
							"Packages/Makefile/Make.sublime-build",
							"Clean"
						],
						[
							"Packages/Python/Python.sublime-build",
							""
						],
						[
							"Packages/Python/Python.sublime-build",
							"Syntax Check"
						],
						[
							"Packages/User/C++.sublime-build",
							""
						],
						[
							"Packages/User/C++.sublime-build",
							"Run"
						]
					],
					[
						"Packages/Python/Python.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/Python/Python.sublime-build",
							""
						],
						[
							"Packages/Python/Python.sublime-build",
							"Syntax Check"
						]
					],
					[
						"Packages/Python/Python.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/Python/Python.sublime-build",
							""
						],
						[
							"Packages/Python/Python.sublime-build",
							"Syntax Check"
						],
						[
							"Packages/User/C++.sublime-build",
							""
						],
						[
							"Packages/User/C++.sublime-build",
							"Run"
						]
					],
					[
						"Packages/Python/Python.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/User/C++.sublime-build",
							""
						],
						[
							"Packages/User/C++.sublime-build",
							"Run"
						]
					],
					[
						"Packages/User/C++.sublime-build",
						"Run"
					]
				]
			],
			"build_varint": "",
			"command_palette":
			{
				"height": 392.0,
				"last_filter": "",
				"selected_items":
				[
					[
						"Package Control: ",
						"Package Control: Install Package"
					],
					[
						"Package Control: ins",
						"Package Control: Install Package"
					],
					[
						"in",
						"Package Control: Install Package"
					],
					[
						"pac",
						"Package Control: Install Package"
					],
					[
						"outli",
						"Browse Mode: Outline (Left)"
					],
					[
						"instal",
						"Package Control: Install Package"
					],
					[
						"Snippet: ",
						"Snippet: #include <…>"
					],
					[
						"insta",
						"Package Control: Install Package"
					],
					[
						"Snippet: int",
						"Snippet: printf …"
					],
					[
						"install",
						"Package Control: Install Package"
					],
					[
						"Package Control: install",
						"Package Control: Install Package"
					],
					[
						"ins",
						"Package Control: Install Package"
					],
					[
						"menu",
						"View: Toggle Menu"
					],
					[
						"Snippet: ip",
						"Snippet: ipython"
					],
					[
						"Snippet:",
						"Snippet: __magic__"
					],
					[
						"parkage",
						"Package Control: Install Package"
					],
					[
						"python",
						"Set Syntax: Python"
					]
				],
				"width": 551.0
			},
			"console":
			{
				"height": 502.0,
				"history":
				[
					"exit",
					"ls"
				]
			},
			"distraction_free":
			{
				"menu_visible": true,
				"show_minimap": false,
				"show_open_files": false,
				"show_tabs": false,
				"side_bar_visible": false,
				"status_bar_visible": false
			},
			"file_history":
			[
				"/home/mmphego/mnt/cmc3/srv/casperfpga/build/lib.linux-x86_64-2.7/casperfpga/casperfpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/__init__.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/aqf_utils.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/test_cbf.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_fengops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/utils.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/instrument.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/beam.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_bengops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/xhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/sensors.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_xengops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_filterops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/filthost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/corr2/corr2LogHandlers.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/bhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/data_stream.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/dsimhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/host_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/fxcorrelator.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/src/transport_skarab.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/casperfpga/transport_skarab.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/corr2/fxcorrelator.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/fhost_fpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/corr2/host_fpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/corr2/fhost_fpga.py",
				"/home/mmphego/GitHub/My-Dockerfiles/fast.ai/Dockerfile",
				"/home/mmphego/GitHub/corr2/corr2/fxcorrelator.py",
				"/home/mmphego/GitHub/corr2/src/corr2LogHandlers.py",
				"/home/mmphego/GitHub/corr2/src/fxcorrelator.py",
				"/home/mmphego/GitHub/corr2/corr2/instrument.py",
				"/home/mmphego/GitHub/new_DSTV_A6_esp8266_IRRemote/.piolibdeps/ArduinoJson/third-party/catch/catch.hpp",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/Corr_RX.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/corr2_rx.py",
				"/home/mmphego/GitHub/corr2/src/host_fpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/delays_debugging.sh",
				"/home/mmphego/GitHub/My-Dockerfiles/fast.ai/Makefile",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-11-05-My-docker-container-has-no-internet.md",
				"/home/mmphego/GitHub/My-Dockerfiles/fast.ai/README.md",
				"/home/mmphego/GitHub/learning_fastai/Dockerfile",
				"/home/mmphego/mnt/cmc3/home/mmphego/learning_fast/Dockerfile",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/.coverage",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/casperfpga/utils.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/dsimhost_fpga.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/sensor_poll.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/run_cbf_tests.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/setup_virtualenv.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/pre_setup.sh",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/poll.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/Dockerfile",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/DockerfileSensorPoll",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/cbf_sensors_dash.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/Makefile",
				"/home/mmphego/mnt/cmc3/home/mmphego/temp/index.html",
				"/home/mmphego/mnt/cmc3/home/mmphego/temp/test.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/temp/flask.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/rx_test_4.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/config/test_conf_site.ini",
				"/home/mmphego/.config/sublime-text-3/Packages/User/highlight_duplicates.sublime-settings",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-09-25-Automated-Qualification-Testing-for-the-64-Antennas-MeerKAT-Correlator-Beamformer.md",
				"/home/mmphego/Dropbox/MEng_Stuff/CPUT Logistics/ITS CPUT Logins",
				"/home/mmphego/Dropbox/BTech Project/Proposal and Reports 2015/Final Report/test.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Notes/Section B/Literature-Review.md",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Proposal_Latex/misc/abbreviations.tex",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/README.md",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/Makefile",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/json_dumps/sensor_values.json",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/pip-requirements.txt",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/corr2_sensor_servlet.py",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-10-23-How-I-configured-JenkinsCI-server-in-a-Docker-container-2.md",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/readme.md",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/Dockerfile",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-08-28-How-I-configured-JenkinsCI-server-in-a-Docker-container-2.md",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-08-20-How-I-configured-JenkinsCI-server-in-a-Docker-container.md",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/Jenkinsfile",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/fabfile.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/corr2LogHandlers.py",
				"/tmp/mozilla_mmphego0/code.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/git-hooks/hooks/pre-commit",
				"/home/mmphego/mnt/cmc3/usr/local/src/nosekatreport/nosekatreport/decorators.py",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-10-22-Better-Git-Commit-Messages-using-Templates.md",
				"/tmp/mozilla_mmphego0/dbelab06ProfilerResultsSortedByNoCalls.txt",
				"/home/mmphego/mnt/cmc3/usr/local/src/git-hooks/templates/README.md",
				"/home/mmphego/.cache/.fr-R9JoZp/WhatsApp Chat with Mpho.txt",
				"/home/mmphego/mnt/cmc3/usr/local/src/git-hooks/README.md",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/example.bib",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/main.tex",
				"/home/mmphego/.cache/.fr-vRhRD6/main.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/Appendices/AppendixA.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/Appendices/AppendixTemplate.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/main.aux",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/MastersThesis.cls",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/MastersDoctoralThesis.cls",
				"/home/mmphego/Dropbox/MEng_Stuff/Tests/Chapters/ChapterTemplate.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/Tests/Chapters/.Chapter1.tex.swp",
				"/home/mmphego/Dropbox/MEng_Stuff/Tests/Chapters/Chapter1.tex",
				"/home/mmphego/.cache/.fr-nEtW8x/LibreOffice_6.1.2.1_Linux_x86-64_deb/readmes/README_en-US",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/test.txt",
				"/home/mmphego/mnt/cmc3/srv/corr2/debug/vaccbug/inspect_rx_packets.py",
				"/home/mmphego/.cache/.fr-WV1LlY/python-data-science/03-matplotlib/02-matplotlib-subplots.ipynb",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/scripts-2.7/corr2_rx.py",
				"/home/mmphego/mnt/cmc3/home/alec/katsdpingest/katsdpingest/receiver.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/corr2_dsim_control.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/src/casperfpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/corr2/host_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/src/transport_tapcp.py",
				"/tmp/mozilla_mmphego0/errorband_lineplots.py",
				"/home/mmphego/GitHub/mmphego.github.io/must-watch-talks.md",
				"/home/mmphego/GitHub/linkedin/http_api.py",
				"/home/mmphego/GitHub/linkedin/.env",
				"/home/mmphego/mnt/cmc3/home/alec/katsdpingest/spead2/examples/test_recv.py",
				"/home/mmphego/Python/python-data-science/Makefile",
				"/home/mmphego/GitHub/linkedin/linkedin.py",
				"/home/mmphego/Python/python-data-science/README.md",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/spead2_rx_debug.py",
				"/home/mmphego/GitHub/mmphego.github.io/resume.html",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/Makefile",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/init_instrument_3.sh",
				"/home/mmphego/GitHub/mmphego.github.io/_data/resume.yml",
				"/home/mmphego/GitHub/mmphego.github.io/mentions.md",
				"/home/mmphego/GitHub/mmphego.github.io/assets/devopsdays.jpeg",
				"/home/mmphego/.cache/.fr-rqHVKv/netl1c63x64.inf",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/check_dep_2.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/install_dep_1.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/setup.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/run_test_5.sh"
			],
			"find":
			{
				"height": 29.0
			},
			"find_in_files":
			{
				"height": 352.0,
				"where_history":
				[
					"/home/mmphego/mnt/cmc3/srv/casperfpga",
					"/home/mmphego/mnt/cmc3/srv/corr2/src",
					"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src",
					"/home/mmphego/GitHub/mmphego.github.io",
					"/home/mmphego/mnt/cmc3/srv/corr2",
					"/home/mmphego/mnt/cmc3/srv/casperfpga/src",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/srv/casperfpga",
					"/home/mmphego/mnt/cmc3/srv/corr2/src",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation",
					"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Notes/Summarised.Papers",
					"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation",
					"/home/mmphego/mnt/cmc1/home/avnuser/AVNTests/AVNTests/avn_tests",
					"/home/mmphego/mnt/cmc1/home/avnuser/AVNTests/AVNTests",
					"/home/mmphego/mnt/cmc3/usr/local/src/katcp-python",
					"/home/mmphego/mnt/cmc3/usr/local/src/corr2",
					"/home/mmphego/mnt/cmc3/usr/local/src/corr2/src"
				]
			},
			"find_state":
			{
				"case_sensitive": true,
				"find_history":
				[
					"self._frames",
					"_read_stream",
					"get_delay_bounds",
					"DTIME",
					"pdebug",
					"corr_config",
					"raise",
					"CorrReceiver",
					"print ",
					"LoggingClass",
					"handler",
					"self",
					"corr_instance",
					"self",
					"DictObject",
					"evaluate_corr",
					"#!/",
					"test_heading",
					"logging.ERROR",
					"ERROR",
					"logging.ERROR",
					"ERROR",
					"logging.ERROR",
					"IPyt",
					"FEngineOperations",
					"LOGGER",
					"IPython",
					"self.init",
					"initialise",
					"FEngineOperations",
					"configure",
					"logging.INFO",
					"log_level=INFO",
					"INFO",
					"getLogger",
					"logLevel",
					"INFO",
					"FpgaHost",
					"IPy",
					"FpgaHost",
					"SkarabTransport",
					"__init__",
					"SkarabTransport",
					"IPyth",
					"getLogger",
					"INFO",
					"getLogger",
					"INFO",
					"_create_hosts",
					"INFO",
					"info",
					"INFO",
					"\\\n",
					"IPy",
					"print",
					"_test_delay_tracking",
					"get_sensors",
					"sync_time",
					"get_sensors",
					"scale_factor_timestamp",
					"scale_f",
					"process_xeng_data",
					"logger",
					"Logger",
					"LOGGER",
					"self.logger",
					"logger",
					"Logger",
					"LOGGER",
					"_spead_stream",
					"corr2_rx",
					"corr2",
					"%i",
					"FATAL",
					"jenkins",
					"_delays_setup",
					"_test_report_config",
					"fft_shift = 511",
					"gain = \"113+0j\"",
					"awgn_scale = 0.0645",
					"cw_scale",
					"self.get_clean_dump()",
					"self.get_clean_dump",
					"get_clean_dump",
					"print (time.",
					"\n        ",
					"\n    ",
					"Cleanup",
					"cleanup",
					"hostname_mapping",
					"merged_sensors_dict",
					"get_sensor_values",
					"Sensor",
					"sensor",
					"cleanup",
					"self.cleanup",
					"self.cleanu",
					"LoggingClass",
					"get_inputlabel",
					"sensor_request",
					"sensor-value",
					"conte",
					"context",
					"add_cleanup",
					"atexit.register",
					"self._errmsg",
					"),",
					"logger",
					"katcp_rct_sensor",
					"raise",
					"display_page",
					".endswith(\"4k\")",
					"test_chan =",
					"test_chan=",
					"1500",
					"        with RunTestWithTimeout(\n",
					"\n            ",
					"with RunTestWithTimeout(\n",
					"with RunTestWithTimeout(",
					"CorrRx",
					"')\n",
					"join",
					"atexit.register(",
					"atexit",
					"atexit.register",
					"start",
					"_timeout",
					"=_timeout"
				],
				"highlight": false,
				"in_selection": false,
				"preserve_case": false,
				"regex": false,
				"replace_history":
				[
					"heading",
					"_logLevel",
					"self.receiver.get_clean_dump()",
					"     ",
					"SensorPoll",
					"channels",
					"network",
					"Warning -m pip",
					"$(command -v  python) -W ignore::Warning pip",
					"Section-A",
					"-",
					"avn_tests"
				],
				"reverse": false,
				"show_context": true,
				"use_buffer2": true,
				"whole_word": false,
				"wrap": false
			},
			"incremental_find":
			{
				"height": 29.0
			},
			"input":
			{
				"height": 123.0
			},
			"menu_visible": true,
			"output.1484047395.6373365":
			{
				"height": 38.0
			},
			"output.build|/home/mmphego/Apts/arduino-1.6.12/test|1500630185.3137703":
			{
				"height": 118.0
			},
			"output.build|/home/mmphego/Apts/arduino-1.6.12/test|1500630228.8832595":
			{
				"height": 118.0
			},
			"output.clangautocomplete":
			{
				"height": 171.0
			},
			"output.exec":
			{
				"height": 37.0
			},
			"output.find_results":
			{
				"height": 0.0
			},
			"output.mdpopups":
			{
				"height": 0.0
			},
			"output.unsaved_changes":
			{
				"height": 132.0
			},
			"output.upload|/home/mmphego/Arduino/hcsr04|1488449906.015194":
			{
				"height": 94.0
			},
			"output.upload|/home/mmphego/OneDrive/Documents/Proposal 2016/HomeAutoPi/MQTT Pub/mqtt_esp8266_nodemcuV2|1484047356.5805616":
			{
				"height": 178.0
			},
			"pinned_build_system": "",
			"replace":
			{
				"height": 54.0
			},
			"save_all_on_build": false,
			"select_file":
			{
				"height": 0.0,
				"last_filter": "",
				"selected_items":
				[
					[
						"test",
						"mkat_fpga_tests/test_cbf.py"
					],
					[
						"repor",
						"report_generator/report.py"
					],
					[
						"943",
						"CBF_tests_reports/bc8n856M32k-20170911-14h22/html/_static/jquery-3.1.0.js"
					],
					[
						"baseline",
						"mkat_fpga_tests/ipython_notebooks/experimental/baseline_product_test.ipynb"
					],
					[
						"",
						"PFB_ch_test.py~"
					]
				],
				"width": 0.0
			},
			"select_project":
			{
				"height": 500.0,
				"last_filter": "",
				"selected_items":
				[
				],
				"width": 380.0
			},
			"select_symbol":
			{
				"height": 392.0,
				"last_filter": "",
				"selected_items":
				[
				],
				"width": 1308.0
			},
			"show_minimap": false,
			"show_open_files": true,
			"show_tabs": true,
			"side_bar_visible": true,
			"side_bar_width": 240.0,
			"status_bar_visible": true,
			"template_settings":
			{
				"max_columns": 2
			}
		},
		"new_window_width": 0.0
	},
	"windows":
	[
		{
			"auto_complete":
			{
				"selected_items":
				[
					[
						"Aq",
						"Aqfs"
					],
					[
						"exc",
						"exc_info=True"
					],
					[
						"exc_info",
						"exc_info=True"
					],
					[
						"ERR",
						"Error\tfunction"
					],
					[
						"Loggin",
						"LoggingClass"
					],
					[
						"Lo",
						"LoggingClass\t(__init__.py)"
					],
					[
						"Log",
						"LogMixin"
					],
					[
						"LO",
						"LOGGING_LEVEL"
					],
					[
						"logging",
						"LOGGING_LEVEL\tstatement"
					],
					[
						"D",
						"DEBUG"
					],
					[
						"DE",
						"DEBUG\tstatement"
					],
					[
						"logg",
						"logging"
					],
					[
						"Loggi",
						"LoggingClass"
					],
					[
						"Logg",
						"LoggingClass"
					],
					[
						"log",
						"log_level\tstatement"
					],
					[
						"time",
						"timedebug"
					],
					[
						"Stre",
						"StreamHandler\tclass"
					],
					[
						"std",
						"stderr\tinstance"
					],
					[
						"hand",
						"handlers\tstatement"
					],
					[
						"_dump_",
						"_dump_timestamp_readable"
					],
					[
						"_co",
						"_config_info"
					],
					[
						"dict",
						"dictsMerger\tfunction"
					],
					[
						"_lo",
						"_logLevel"
					],
					[
						"IP",
						"IPython"
					],
					[
						"cret",
						"create"
					],
					[
						"corr",
						"correlator"
					],
					[
						"mer",
						"merge_dicts"
					],
					[
						"sensor",
						"sensors_info"
					],
					[
						"_dum",
						"_dump_timestamp_readable"
					],
					[
						"cle",
						"clearall"
					],
					[
						"logi",
						"logging"
					],
					[
						"set",
						"setLevel\tfunction"
					],
					[
						"s",
						"stop"
					],
					[
						"r",
						"RUN"
					],
					[
						"WORK",
						"WORKDIR\t(Dockerfile)"
					],
					[
						"mk",
						"mkat_fpga_tests\t(test_cbf.py)"
					],
					[
						"mkat",
						"mkat_fpga_tests"
					],
					[
						"bit",
						"bitstream\t(test_cbf.py)"
					],
					[
						"file",
						"filename\t(test_cbf.py)"
					],
					[
						"get_s",
						"get_system_information\t(test_cbf.py)"
					],
					[
						"logs",
						"logs_sensors"
					],
					[
						"tear",
						"teardown_package"
					],
					[
						"ac",
						"activeCount\tstatement"
					],
					[
						"Array",
						"Array-List"
					],
					[
						"_kat",
						"_katcp_rct_sensor"
					],
					[
						"reosue",
						"resource_client"
					],
					[
						"exc_",
						"exc_info=True\t(sensor_poll.py)"
					],
					[
						"ger",
						"get_sensors"
					],
					[
						"Ke",
						"KeyboardInterrupt\tclass"
					],
					[
						"repl",
						"reply.reply_ok"
					],
					[
						"info",
						"informs"
					],
					[
						"katc",
						"katcp_rct_sensor"
					],
					[
						"Sens",
						"SensorPoll"
					],
					[
						"sen",
						"sensor_poll\t(sensor_poll.py)"
					],
					[
						"Not",
						"NotImplementedError\tclass"
					],
					[
						"katcp_cli",
						"katcp_client_port"
					],
					[
						"NotI",
						"NotImplementedError\tclass"
					],
					[
						"arra",
						"array_name"
					],
					[
						"if",
						"ifmain\tif __name__ == '__main__'"
					],
					[
						"sec",
						"sec_sensors_katcp_con"
					],
					[
						"e",
						"except"
					],
					[
						"new_",
						"new_mapping"
					],
					[
						"colle",
						"collections"
					],
					[
						"order",
						"ordered_sensor_dict"
					],
					[
						"prim",
						"primary_client"
					],
					[
						"fom",
						"format"
					],
					[
						"json",
						"json_dumps"
					],
					[
						"js",
						"json_dumps\t(sensor_poll.py)"
					],
					[
						"cbf",
						"cbf_sensors_dash.py"
					],
					[
						"bh",
						"bhost_fpga"
					],
					[
						"fp",
						"fhost_fpga\tmodule"
					],
					[
						"Run",
						"RuntimeError"
					],
					[
						"thre",
						"threaded_fpga_operation"
					],
					[
						"auto",
						"automagically"
					],
					[
						"start",
						"startall"
					],
					[
						"sona",
						"sonarstart"
					],
					[
						"port",
						"portainerstart"
					],
					[
						"poe",
						"portainerstop"
					],
					[
						"por",
						"portainer"
					],
					[
						"soan",
						"sonar"
					],
					[
						"act",
						"active_frames"
					],
					[
						"quit",
						"quit_event"
					],
					[
						"real",
						"realimag"
					],
					[
						"basel",
						"baseline_correlation_products_n_chans"
					],
					[
						"baseli",
						"baselines"
					],
					[
						"baselie",
						"baseline_correlation_products_n_bls"
					],
					[
						"baseline",
						"baseline_correlation_products_n_bls"
					],
					[
						"n",
						"n_accs"
					],
					[
						"baseloi",
						"baseline_correlation_products_n_bls"
					],
					[
						"chan",
						"channels"
					],
					[
						"get_",
						"get_plot_data"
					],
					[
						"baseline_c",
						"baseline_correlation_products_n_chans"
					],
					[
						"base",
						"baselines"
					],
					[
						"le",
						"legend"
					],
					[
						"get",
						"getattr"
					],
					[
						"n-",
						"n-xengs"
					],
					[
						"qui",
						"quit_event"
					],
					[
						"f",
						"figure"
					],
					[
						"inf",
						"info"
					],
					[
						"de",
						"debug"
					],
					[
						"star",
						"startswith"
					],
					[
						"Ru",
						"RuntimeError"
					],
					[
						"Ex",
						"Exception\t(utils.py)"
					],
					[
						"conf",
						"config_info\tstatement"
					],
					[
						"config",
						"config_info"
					],
					[
						"feng",
						"fengine_conf"
					],
					[
						"outp",
						"output_products"
					],
					[
						"des",
						"destination"
					],
					[
						"Dict",
						"DictObject"
					],
					[
						"cong",
						"config_info"
					],
					[
						"con",
						"config_info"
					],
					[
						"n_c",
						"n_chans\tstatement"
					],
					[
						"Ska",
						"SkarabTransport"
					],
					[
						"trans",
						"transport\t(transport_tapcp.py)"
					],
					[
						"clas",
						"classmethod\tclass"
					],
					[
						"stop",
						"stop_substream\tstatement"
					],
					[
						"end",
						"end_ip"
					],
					[
						"has",
						"hasattr"
					],
					[
						"Asse",
						"AssertionError"
					],
					[
						"serve",
						"servlet_ip"
					],
					[
						"serv",
						"servlet_ip"
					],
					[
						"ser",
						"servlet_port"
					],
					[
						"se",
						"sensors"
					],
					[
						"confi",
						"config_info"
					],
					[
						"Ba",
						"BASELINES"
					],
					[
						"h5",
						"h5_file"
					],
					[
						"output",
						"output_products"
					],
					[
						"xeng",
						"xengine_conf"
					]
				]
			},
			"buffers":
			[
				{
					"file": "mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/__init__.py",
					"settings":
					{
						"buffer_size": 33557,
						"encoding": "UTF-8",
						"line_ending": "Unix"
					}
				},
				{
					"contents": "#!/usr/bin/env python\n# https://stackoverflow.com/a/44077346\n###############################################################################\n# SKA South Africa (http://ska.ac.za/)                                        #\n# Author: cbf@ska.ac.za                                                       #\n# Maintainer: mmphego@ska.ac.za, alec@ska.ac.za                               #\n# Copyright @ 2016 SKA SA. All rights reserved.                               #\n#                                                                             #\n# THIS SOFTWARE MAY NOT BE COPIED OR DISTRIBUTED IN ANY FORM WITHOUT THE      #\n# WRITTEN PERMISSION OF SKA SA.                                               #\n###############################################################################\n\nfrom __future__ import division\n\nimport gc\nimport glob\nimport os\nimport Queue\nimport random\nimport socket\nimport struct\nimport subprocess\nimport sys\nimport time\nimport unittest\n# MEMORY LEAKS DEBUGGING\n# To use, add @DetectMemLeaks decorator to function\n# from memory_profiler import profile as DetectMemLeaks\nfrom datetime import datetime\nfrom inspect import getframeinfo, stack\n\nimport casperfpga\nimport corr2\nimport katcp\nimport matplotlib.pyplot as plt\nimport ntplib\nimport numpy as np\nimport pandas as pd\nimport scipy.interpolate\nimport scipy.signal\nimport spead2\nfrom dotenv import find_dotenv, load_dotenv\nfrom katcp.testutils import start_thread_with_cleanup\nfrom mkat_fpga_tests import CorrelatorFixture, add_cleanup\nfrom mkat_fpga_tests.aqf_utils import *\nfrom mkat_fpga_tests.utils import *\nfrom nosekatreport import *\nfrom termcolor import colored\n\nfrom Corr_RX import CorrRx\nfrom descriptions import TestProcedure\nfrom Logger import LoggingClass\nfrom power_logger import PowerLogger\n\nload_dotenv(find_dotenv())\n\n# How long to wait for a correlator dump to arrive in tests\nDUMP_TIMEOUT = 10\n# ToDo MM (2017-07-21) Improve the logging for debugging\nset_dsim_epoch = False\ndsim_timeout = 60\n\n# Set same logging level as per nosetests\nLOGGING_LEVEL = ''.join(\n    [i.split('=')[-1] for i in sys.argv if i.startswith('--logging-level')])\nif not LOGGING_LEVEL:\n    LOGGING_LEVEL = \"INFO\"\n\n\nclass AqfReporter(object):\n\n    def Failed(self, msg, *args, **kwargs):\n        caller = getframeinfo(stack()[1][0])\n        Aqf.failed(msg)\n        self.logger.warn(\"-> Line:%d: - %s\" % (caller.lineno, msg))\n\n    def Error(self, msg, *args, **kwargs):\n        caller = getframeinfo(stack()[1][0])\n        Aqf.failed(msg)\n        exception_info = kwargs.get('exc_info', False)\n        self.logger.error(\"-> Line:%d: - %s\" % (caller.lineno, msg), exc_info=exception_info)\n\n    def Step(self, msg, *args, **kwargs):\n        caller = getframeinfo(stack()[1][0])\n        Aqf.step(msg)\n        self.logger.debug(\"-> Line:%d: - %s\" % (caller.lineno, msg))\n\n    def Progress(self, msg, *args, **kwargs):\n        caller = getframeinfo(stack()[1][0])\n        Aqf.progress(msg)\n        self.logger.info(\"-> Line:%d: - %s\" % (caller.lineno, msg))\n\n    def Note(self, msg, *args, **kwargs):\n        caller = getframeinfo(stack()[1][0])\n        Aqf.note(msg)\n        self.logger.info(\"-> Line:%d: - %s\" % (caller.lineno, msg))\n\n\n\n@cls_end_aqf\n@system(\"meerkat\")\nclass test_CBF(unittest.TestCase, LoggingClass, AqfReporter):\n    \"\"\" Unit-testing class for mkat_fpga_tests\"\"\"\n\n    cur_path = os.path.split(os.path.dirname(os.path.abspath(__file__)))[0]\n    _katreport_dir = os.path.join(cur_path, \"katreport\")\n    _csv_filename = os.path.join(cur_path, \"docs/Manual_Tests.csv\")\n    _images_dir = os.path.join(cur_path, \"docs/manual_tests_images\")\n    if os.path.exists(_csv_filename):\n        csv_manual_tests = CSV_Reader(_csv_filename, set_index=\"Verification Event Number\")\n\n    def setUp(self):\n        global set_dsim_epoch\n        AqfReporter.__init__(self)\n        super(test_CBF, self).setUp()\n        self.receiver = None\n        self._dsim_set = False\n        self.corr_fix = CorrelatorFixture()\n        self.logger.setLevel(LOGGING_LEVEL)\n        self.logs_path = None\n        try:\n            self.logs_path = create_logs_directory(self)\n            self.conf_file = self.corr_fix.test_config\n            self.corr_fix.katcp_client = self.conf_file[\"instrument_params\"][\"katcp_client\"]\n            self.katcp_req = self.corr_fix.katcp_rct.req\n            self.katcp_req_sensors = self.corr_fix.katcp_rct_sensor.req\n            self.Note(\"Connecting to katcp client on %s\" % self.corr_fix.katcp_client)\n        except Exception:\n            self.Error(\"Failed to read test config file.\", exc_info=True)\n        try:\n            self.dhost = self.corr_fix.dhost\n            errmsg = \"Failed to instantiate the dsim, investigate\"\n            assert isinstance(self.dhost, corr2.dsimhost_fpga.FpgaDsimHost), errmsg\n        except Exception:\n            self.logger.exception(errmsg)\n        else:\n            # See: https://docs.python.org/2/library/functions.html#super\n            if set_dsim_epoch is False:\n                try:\n                    self.logger.info(\"This should only run once...\")\n                    self.fhosts, self.xhosts = (get_hosts(self, \"fhost\"), get_hosts(self, \"xhost\"))\n                    if not self.dhost.is_running():\n                        errmsg = \"Dsim is not running, ensure dsim is running before test commences\"\n                        Aqf.end(message=errmsg)\n                        sys.exit(errmsg)\n                    self.dhost.get_system_information(filename=self.dhost.config.get(\"bitstream\"))\n                    errmsg = \"Issues with the defined instrument, figure it out\"\n                    assert isinstance(self.corr_fix.instrument, str), errmsg\n                    # cbf_title_report(self.corr_fix.instrument)\n                    # Disable warning messages(logs) once\n                    disable_warnings_messages()\n                    errmsg = \"katcp connection could not be established, investigate!!!\"\n                    self.assertIsInstance(\n                        self.corr_fix.katcp_rct,\n                        katcp.resource_client.ThreadSafeKATCPClientResourceWrapper\n                    ), errmsg\n                    errmsg = \"Failed to set Digitiser sync epoch via CAM interface.\"\n                    reply, informs = self.katcp_req.sensor_value(\"synchronisation-epoch\")\n                    assert reply.reply_ok(), errmsg\n                    sync_time = float(informs[0].arguments[-1])\n                    errmsg = \"Issues with reading Sync epoch\"\n                    assert isinstance(sync_time, float), errmsg\n                    reply, informs = self.katcp_req.digitiser_synch_epoch(sync_time)\n                    errmsg = \"Failed to set digitiser sync epoch\"\n                    assert reply.reply_ok(), errmsg\n                    self.logger.info(\"Digitiser sync epoch set successfully\")\n                    set_dsim_epoch = self._dsim_set = True\n                except Exception:\n                    self.Error(errmsg, exc_info=True)\n\n\n    # This needs proper testing\n    def tearDown(self):\n        try:\n            self.katcp_req = None\n            assert not self.receiver\n        except AssertionError:\n            self.logger.info(\"Cleaning up the receiver!!!!\")\n            add_cleanup(self.receiver.stop)\n            self.receiver = None\n            del self.receiver\n\n    def set_instrument(self, acc_time=None, **kwargs):\n        self.receiver = None\n        acc_timeout = 60\n        self.errmsg = None\n        # Reset digitiser simulator to all Zeros\n        init_dsim_sources(self.dhost)\n        self.cam_sensors = GetSensors(self.corr_fix)\n        self.addCleanup(init_dsim_sources, self.dhost)\n\n        try:\n            self.Step(\"Confirm running instrument, else start a new instrument\")\n            self.instrument = self.cam_sensors.get_value(\"instrument_state\").split(\"_\")[0]\n            self.Progress(\n                \"Currently running instrument %s-%s as per /etc/corr\" % (self.corr_fix.array_name, self.instrument)\n            )\n        except Exception:\n            errmsg = \"No running instrument on array: %s, Exiting....\" % self.corr_fix.array_name\n            self.logger.exception(errmsg)\n            Aqf.end(message=errmsg)\n            sys.exit(errmsg)\n\n        if self._dsim_set:\n            self.Step(\"Configure a digitiser simulator to be used as input source to F-Engines.\")\n            self.Progress(\"Digitiser Simulator running on host: %s\" % self.dhost.host)\n\n        try:\n            n_ants = int(self.cam_sensors.get_value(\"n_ants\"))\n            n_chans = int(self.cam_sensors.get_value(\"n_chans\"))\n            if acc_time:\n                pass\n            elif n_ants == 4:\n                acc_time = 0.5\n            else:\n                acc_time = n_ants / 32.0\n            reply, informs = self.katcp_req.accumulation_length(acc_time, timeout=acc_timeout)\n            assert reply.reply_ok()\n            acc_time = float(reply.arguments[-1])\n            self.Step(\"Set and confirm accumulation period via CAM interface.\")\n            self.Progress(\"Accumulation time set to {:.3f} seconds\".format(acc_time))\n        except Exception:\n            self.Error(\"Failed to set accumulation time.\", exc_info=True)\n\n        try:\n            output_product = self.conf_file[\"instrument_params\"][\"output_product\"]\n            data_output_ip, data_output_port = self.cam_sensors.get_value(\n                output_product.replace(\"-\", \"_\") + \"_destination\"\n            ).split(\":\")\n            self.Step(\n                \"Starting SPEAD receiver listening on %s:%s, CBF output product: %s\"\n                % (data_output_ip, data_output_port, output_product)\n            )\n            katcp_ip = self.corr_fix.katcp_client\n            katcp_port = int(self.corr_fix.katcp_rct.port)\n            self.Step(\"Connected to katcp on %s\" % katcp_ip)\n            # ToDo maybe select stop channels depending on the no of ants\n            start_channels = int(self.conf_file[\"instrument_params\"].get(\"start_channels\", 0))\n            if n_ants == 64 and n_chans == 4096:\n                stop_channels = 2047\n            elif n_chans == 1024:\n                stop_channels = 1023\n            else:\n                stop_channels = int(self.conf_file[\"instrument_params\"].get(\"stop_channels\", 2047))\n            self.Step(\n                \"Starting receiver on port %s, will only capture channels between %s-%s\"\n                % (data_output_port, start_channels, stop_channels)\n            )\n            self.Note(\n                \"Configuring SPEAD receiver to capture %s channels from %s to %s.\"\n                % (stop_channels - start_channels + 1, start_channels, stop_channels)\n            )\n            self.receiver = CorrRx(\n                product_name=output_product,\n                katcp_ip=katcp_ip,\n                katcp_port=katcp_port,\n                port=data_output_port,\n                channels=(start_channels, stop_channels),\n            )\n            self.receiver.setName(\"CorrRx Thread\")\n            self.errmsg = \"Failed to create SPEAD data receiver\"\n            self.assertIsInstance(self.receiver, CorrRx), self.errmsg\n            start_thread_with_cleanup(self, self.receiver, timeout=10, start_timeout=1)\n            self.errmsg = \"Spead Receiver not Running, possible \"\n            assert self.receiver.isAlive(), self.errmsg\n            self.corr_fix.start_x_data\n            self.logger.info(\"Getting a test dump to confirm number of channels else, test fails \" \"if cannot retrieve dump\")\n            _test_dump = self.receiver.get_clean_dump()\n            self.errmsg = \"Getting empty dumps!!!!\"\n            self.assertIsInstance(_test_dump, dict, self.errmsg)\n            self.n_chans_selected = int(_test_dump.get(\"n_chans_selected\", self.cam_sensors.get_value(\"n_chans\")))\n            self.logger.info(\"Confirmed number of channels %s, from initial dump\" % self.n_chans_selected)\n        except Exception:\n            self.Error(str(e), exc_info=True)\n            return False\n        else:\n            # Run system tests before each test is ran\n            # self._systems_tests()\n            self.addCleanup(self.corr_fix.stop_x_data)\n            self.addCleanup(self.receiver.stop)\n            self.addCleanup(executed_by)\n            # self.addCleanup(self._systems_tests)\n            self.addCleanup(gc.collect)\n            return True\n\n    @instrument_1k\n    @instrument_4k\n    @aqf_vr(\"CBF.V.3.30\")\n    @aqf_requirements(\"CBF-REQ-0126\", \"CBF-REQ-0047\", \"CBF-REQ-0046\", \"CBF-REQ-0043\", \"CBF-REQ-0053\")\n    def test_channelisation_wideband_course(self):\n        Aqf.procedure(TestProcedure.Channelisation)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                n_chans = self.n_chans_selected\n                test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n                heading(\"CBF Channelisation Wideband Coarse L-band\")\n                num_discards = 1\n                if n_chans > 2048:\n                    self._test_channelisation(\n                        test_chan, no_channels=n_chans, req_chan_spacing=250e3, num_discards=num_discards\n                    )\n                else:\n                    self._test_channelisation(\n                        test_chan, no_channels=n_chans, req_chan_spacing=1000e3, num_discards=num_discards\n                    )\n            else:\n                self.Failed(self.errmsg)\n\n    @instrument_32k\n    @aqf_vr(\"CBF.V.3.30\")\n    @aqf_requirements(\"CBF-REQ-0126\", \"CBF-REQ-0047\", \"CBF-REQ-0046\", \"CBF-REQ-0043\", \"CBF-REQ-0053\")\n    def test_channelisation_wideband_fine(self):\n        # Aqf.procedure(TestProcedure.Channelisation)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                n_chans = self.n_chans_selected\n                test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n                heading(\"CBF Channelisation Wideband Fine L-band\")\n                self._test_channelisation(test_chan, no_channels=32768, req_chan_spacing=30e3)\n            else:\n                self.Failed(self.errmsg)\n\n    @slow\n    @instrument_1k\n    @instrument_4k\n    @aqf_vr(\"CBF.V.3.30\")\n    @aqf_requirements(\"CBF-REQ-0126\", \"CBF-REQ-0047\", \"CBF-REQ-0046\", \"CBF-REQ-0043\", \"CBF-REQ-0053\")\n    def test_channelisation_wideband_course_sfdr_peaks(self):\n        Aqf.procedure(TestProcedure.ChannelisationSFDR)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                heading(\"CBF Channelisation Wideband Coarse SFDR L-band\")\n                n_ch_to_test = int(self.conf_file[\"instrument_params\"].get(\"sfdr_ch_to_test\", self.n_chans_selected))\n                self._test_sfdr_peaks(required_chan_spacing=250e3, no_channels=n_ch_to_test)  # Hz\n            else:\n                self.Failed(self.errmsg)\n\n    @slow\n    @instrument_32k\n    @aqf_vr(\"CBF.V.3.30\")\n    @aqf_requirements(\"CBF-REQ-0126\", \"CBF-REQ-0047\", \"CBF-REQ-0046\", \"CBF-REQ-0043\", \"CBF-REQ-0053\")\n    def test_channelisation_wideband_fine_sfdr_peaks(self):\n        # Aqf.procedure(TestProcedure.ChannelisationSFDR)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                heading(\"CBF Channelisation Wideband Fine SFDR L-band\")\n                n_ch_to_test = int(self.conf_file[\"instrument_params\"].get(\"sfdr_ch_to_test\", self.n_chans_selected))\n                self._test_sfdr_peaks(required_chan_spacing=30e3, no_channels=n_ch_to_test)  # Hz\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.46\")\n    @aqf_requirements(\"CBF-REQ-0164\", \"CBF-REQ-0191\")\n    def test_power_consumption(self):\n        Aqf.procedure(TestProcedure.PowerConsumption)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            self.Step(\"Test is being qualified by CBF.V.3.30\")\n\n    # @generic_test\n    # @aqf_vr('CBF.V.3.35')\n    # @aqf_requirements(\"CBF-REQ-0124\")\n    # def test_beamformer_efficiency(self):\n    #     Aqf.procedure(TestProcedure.BeamformerEfficiency)\n    #     try:\n    #         assert eval(os.getenv('DRY_RUN', 'False'))\n    #     except AssertionError:\n    #         instrument_success = self.set_instrument()\n    #         if instrument_success:\n    #             # self._test_efficiency()\n    #             pass\n    #         else:\n    #             self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.4.10\")\n    @aqf_requirements(\"CBF-REQ-0127\")\n    def test_lband_efficiency(self):\n        Aqf.procedure(TestProcedure.LBandEfficiency)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_efficiency()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"TBD\")\n    @aqf_requirements(\"TBD\")\n    def test_linearity(self):\n        # Aqf.procedure(TestProcedure.LBandEfficiency)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_linearity(\n                    test_channel=100, cw_start_scale=1, noise_scale=0.001,\n                    gain=\"10+j\", fft_shift=8191, max_steps=20\n                )\n            else:\n                self.Failed(self.errmsg)\n\n    @instrument_1k\n    @instrument_4k\n    @aqf_vr(\"CBF.V.3.34\")\n    @aqf_requirements(\"CBF-REQ-0094\", \"CBF-REQ-0117\", \"CBF-REQ-0118\", \"CBF-REQ-0123\", \"CBF-REQ-0183\")\n    def test_beamforming(self):\n        Aqf.procedure(TestProcedure.Beamformer)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_beamforming()\n            else:\n                self.Failed(self.errmsg)\n\n    # Test still under development, Alec will put it under test_informal\n    @instrument_1k\n    @instrument_4k\n    def test_beamforming_timeseries(self):\n        # Aqf.procedure(TestProcedure.Beamformer)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_beamforming_timeseries()\n            else:\n                self.Failed(self.errmsg)\n\n    @wipd  # Test still under development, Alec will put it under test_informal\n    @instrument_1k\n    @instrument_4k\n    def test_group_delay(self):\n        # Aqf.procedure(TestProcedure.Beamformer)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_group_delay()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.4.4\")\n    @aqf_requirements(\"CBF-REQ-0087\", \"CBF-REQ-0225\", \"CBF-REQ-0104\")\n    def test_baseline_correlation_product(self):\n        Aqf.procedure(TestProcedure.BaselineCorrelation)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_product_baselines()\n                self._test_back2back_consistency()\n                self._test_freq_scan_consistency()\n                self._test_spead_verify()\n                self._test_product_baseline_leakage()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.62\")\n    @aqf_requirements(\"CBF-REQ-0238\")\n    def test_imaging_data_product_set(self):\n        Aqf.procedure(TestProcedure.ImagingDataProductSet)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_data_product(_baseline=True)\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.67\")\n    @aqf_requirements(\"CBF-REQ-0120\")\n    def test_tied_array_aux_baseline_correlation_products(self):\n        Aqf.procedure(TestProcedure.TiedArrayAuxBaselineCorrelationProducts)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_data_product(_baseline=True, _tiedarray=True)\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.64\")\n    @aqf_requirements(\"CBF-REQ-0242\")\n    def test_tied_array_voltage_data_product_set(self):\n        Aqf.procedure(TestProcedure.TiedArrayVoltageDataProductSet)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_data_product(_tiedarray=True)\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.4.7\")\n    @aqf_requirements(\"CBF-REQ-0096\")\n    def test_accumulation_length(self):\n        # The CBF shall set the Baseline Correlation Products accumulation interval to a fixed time\n        # in the range $$500 +0 -20ms$$.\n        Aqf.procedure(TestProcedure.VectorAcc)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                if \"32k\" in self.instrument:\n                    self.Step(\n                        \"Testing maximum channels to %s due to quantiser snap-block and \"\n                        \"system performance limitations.\" % self.n_chans_selected\n                    )\n                chan_index = self.n_chans_selected\n                n_chans = self.cam_sensors.get_value(\"n_chans\")\n                test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n                n_ants = self.cam_sensors.get_value(\"n_ants\")\n                if n_ants == 4:\n                    acc_time = 0.998\n                else:\n                    acc_time = 2 * n_ants / 32.0\n                self._test_vacc(test_chan, chan_index, acc_time)\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.4.9\")\n    @aqf_requirements(\"CBF-REQ-0119\")\n    def test_gain_correction(self):\n        # The CBF shall apply gain correction per antenna, per polarisation, per frequency channel\n        # with a range of at least $$\\pm 6 \\; dB$$ and a resolution of $$\\le 1 \\; db$$.\n        Aqf.procedure(TestProcedure.GainCorr)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_gain_correction()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.4.23\")\n    @aqf_requirements(\"CBF-REQ-0013\")\n    def test_product_switch(self):\n        # The CBF shall, on request via the CAM interface, switch between Sub-Array data product\n        #  combinations, using the same combination of Receptors, in less than 60 seconds.\n        Aqf.procedure(TestProcedure.ProductSwitching)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            self.Failed(\"This requirement is currently not being tested in this release.\")\n            # _running_inst = which_instrument(self, instrument)\n            # instrument_success = self.set_instrument()\n            # if instrument_success:\n            #     with RunTestWithTimeout(300):\n            #         self._test_product_switch(instrument)\n            # else:\n            #     self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.31\")\n    @aqf_requirements(\"CBF-REQ-0066\", \"CBF-REQ-0072\", \"CBF-REQ-0077\", \"CBF-REQ-0110\", \"CBF-REQ-0200\")\n    def test_delay_phase_compensation_control(self):\n        Aqf.procedure(TestProcedure.CBF_Delay_Phase_Compensation_Control)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_delays_control()\n                clear_all_delays(self)\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.32\")\n    @aqf_requirements(\"CBF-REQ-0112\", \"CBF-REQ-0128\", \"CBF-REQ-0185\", \"CBF-REQ-0187\", \"CBF-REQ-0188\")\n    def test_delay_phase_compensation_functional(self):\n        Aqf.procedure(TestProcedure.CBF_Delay_Phase_Compensation)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            acc_time = int(self.conf_file[\"instrument_params\"][\"delay_test_acc_time\"])\n            instrument_success = self.set_instrument(acc_time=acc_time)\n            if instrument_success:\n                self._test_delay_tracking()\n                self._test_delay_rate()\n                self._test_fringe_rate()\n                self._test_fringe_offset()\n                self._test_delay_inputs()\n                clear_all_delays(self)\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.27\")\n    @aqf_requirements(\"CBF-REQ-0178\")\n    def test_report_configuration(self):\n        # The CBF shall, on request via the CAM interface, report sensors that identify the installed\n        # configuration of the CBF unambiguously, including hardware, software and firmware part\n        # numbers and versions.\n        Aqf.procedure(TestProcedure.ReportConfiguration)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_report_config()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.29\")\n    @aqf_requirements(\"CBF-REQ-0067\")\n    def test_systematic_error_reporting(self):\n        # The CBF shall detect and flag data where the signal integrity has been compromised due to:\n        #     a. Digitiser data acquisition and/or signal processing (e.g. ADC saturation),\n        #     b. Signal processing and/or data manipulation performed in the CBF (e.g. FFT overflow).\n        Aqf.procedure(TestProcedure.PFBFaultDetection)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_fft_overflow()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.28\")\n    @aqf_requirements(\"CBF-REQ-0157\")\n    def test_fault_detection(self):\n        # The CBF shall monitor functions which are in use, and report detected failures of those\n        # functions including but not limited to:\n        #     a) processing pipeline failures\n        #     b) memory errors (SKARAB uses HMC instead of QDR might be tricky to test)\n        #     c) network link errors\n        # Detected failures shall be reported over the CBF-CAM interface.\n        Aqf.procedure(TestProcedure.LinkFaultDetection)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                # self._test_network_link_error()\n                # self._test_memory_error()\n                heading(\"Processing Pipeline Failures\")\n                self.Note(\"Test is being qualified by CBF.V.3.29\")\n                heading(\"HMC Memory errors\")\n                self.Note(\"See waiver\")\n                heading(\"Network Link errors\")\n                self.Note(\"See waiver\")\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.26\")\n    @aqf_requirements(\"CBF-REQ-0056\", \"CBF-REQ-0068\", \"CBF-REQ-0069\")\n    def test_monitor_sensors(self):\n        # The CBF shall report the following transient search monitoring data:\n        #     a) Transient buffer ready for triggering\n        # The CBF shall, on request via the CAM interface, report sensor values.\n        # The CBF shall, on request via the CAM interface, report time synchronisation status.\n        Aqf.procedure(TestProcedure.MonitorSensors)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._test_sensor_values()\n                # self._test_host_sensors_status()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    @aqf_vr(\"CBF.V.3.38\")\n    @aqf_requirements(\"CBF-REQ-0203\")\n    def test_time_synchronisation(self):\n        Aqf.procedure(TestProcedure.TimeSync)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            self._test_time_sync()\n\n    @generic_test\n    @aqf_vr(\"CBF.V.4.26\")\n    @aqf_requirements(\"CBF-REQ-0083\", \"CBF-REQ-0084\", \"CBF-REQ-0085\", \"CBF-REQ-0086\", \"CBF-REQ-0221\")\n    def test_antenna_voltage_buffer(self):\n        Aqf.procedure(TestProcedure.VoltageBuffer)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n            if instrument_success:\n                self._small_voltage_buffer()\n            else:\n                self.Failed(self.errmsg)\n\n    @generic_test\n    def _test_bc8n856M4k_linearity(self, instrument=\"bc8n856M4k\"):\n        \"\"\"Linearity Test (bc8n856M4k)\n        Step noise dithered CW and plot output power\n        \"\"\"\n        # Aqf.procedure(TestProcedure.Linearity)\n        try:\n            assert eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            instrument_success = self.set_instrument()\n\n            # self.Step('Determining CBF linearity: {}\\n'.format(\n            #     self.corr_fix.get_running_instrument()))\n            if instrument_success:\n                self._linearity(\n                    test_channel=100, cw_start_scale=1, noise_scale=0.001, gain=\"10+j\",\n                    fft_shift=8191, max_steps=20\n                )\n            else:\n                self.Failed(self.errmsg)\n\n    # ---------------------------------------------------------------------------------------------------\n    # ----------------------------------------------MANUAL TESTS-----------------------------------------\n    # ---------------------------------------------------------------------------------------------------\n\n    # Perhaps, enlist all manual tests here with VE & REQ\n\n    @manual_test\n    @aqf_vr(\"CBF.V.3.56\")\n    @aqf_requirements(\"CBF-REQ-0228\")\n    def test__subarray(self):\n        self._test_global_manual(\"CBF.V.3.56\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.37\")\n    @aqf_requirements(\"CBF-REQ-0071\", \"CBF-REQ-0204\")\n    def test__control(self):\n        self._test_global_manual(\"CBF.V.3.37\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.37*\"))\n        caption_list = [\"Screenshot of the command executed and reply: CAM interface\"]\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.1.11\")\n    @aqf_requirements(\"CBF-REQ-0137\")\n    def test__procured_items_emc_certification(self):\n        self._test_global_manual(\"CBF.V.1.11\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.3\")\n    @aqf_requirements(\"CBF-REQ-0018\", \"CBF-REQ-0019\", \"CBF-REQ-0022\", \"CBF-REQ-0024\")\n    @aqf_requirements(\"CBF-REQ-0011\", \"CBF-REQ-0012\", \"CBF-REQ-0014\", \"CBF-REQ-0016\", \"CBF-REQ-0017\")\n    @aqf_requirements(\"CBF-REQ-0027\", \"CBF-REQ-0064\")\n    def test__states_and_modes_ve(self):\n        self._test_global_manual(\"CBF.V.3.3\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.77\")\n    @aqf_requirements(\"CBF-REQ-0021\")\n    def test__full_functional_mode_ve(self):\n        self._test_global_manual(\"CBF.V.3.77\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.15\")\n    @aqf_requirements(\"CBF-REQ-0131\", \"CBF-REQ-0132\", \"CBF-REQ-0133\")\n    def test__power_supply_ve(self):\n        self._test_global_manual(\"CBF.V.3.15\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.16\")\n    @aqf_requirements(\"CBF-REQ-0199\")\n    def test__safe_design_ve(self):\n        self._test_global_manual(\"CBF.V.3.16\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.17\")\n    @aqf_requirements(\"CBF-REQ-0061\")\n    def test__lru_status_and_display_ve(self):\n        self._test_global_manual(\"CBF.V.3.17\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.18\")\n    @aqf_requirements(\"CBF-REQ-0197\")\n    def test__cots_lru_status_and_display_ve(self):\n        self._test_global_manual(\"CBF.V.3.18\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.18*\"))\n        caption_list = [\n            \"Mellanox SX1710 switches and status LEDs visible from front of rack.\",\n            \"Dell PowerEdge servers and status via front panel display visible.\",\n            \"AP8981 PDUs have status LEDs visible from the back of the rack.\",\n        ]\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.19\")\n    @aqf_requirements(\"CBF-REQ-0182\")\n    def test__interchangeability_ve(self):\n        self._test_global_manual(\"CBF.V.3.19\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.20\")\n    @aqf_requirements(\"CBF-REQ-0168\", \"CBF-REQ-0171\")\n    def test__periodic_maintenance_lru_storage_ve(self):\n        self._test_global_manual(\"CBF.V.3.20\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.21\")\n    @aqf_requirements(\"CBF-REQ-0169\", \"CBF-REQ-0170\", \"CBF-REQ-0172\", \"CBF-REQ-0173\")\n    def test__lru_storage_ve(self):\n        self._test_global_manual(\"CBF.V.3.21\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.22\")\n    @aqf_requirements(\"CBF-REQ-0147\", \" CBF-REQ-0148\")\n    def test__item_handling_ve(self):\n        self._test_global_manual(\"CBF.V.3.22\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.23\")\n    @aqf_requirements(\"CBF-REQ-0152\", \"CBF-REQ-0153\", \"CBF-REQ-0154\", \"CBF-REQ-0155\", \"CBF-REQ-0184\")\n    def test__item_marking_and_labelling_ve(self):\n        self._test_global_manual(\"CBF.V.3.23\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.23*\"))\n        caption_list = [\n            \"Mellanox SX1710 - Supplier name and model number visible with switch installed in rack.\",\n            \"Dell PowerEdge servers - Supplier name, model number and serial number visible with \"\n            \"server installed in rack.\",\n            \"SKARAB Processing nodes.\",\n            \"All data switch port numbers are labelled.\",\n            \"All internal CBF cables are labelled.\",\n            \"All internal CBF cables are labelled.\",\n            \"HMC Mezzanine SRUs are labelled as specified but supplier name is obscured by heatsink\",\n            \"QSFP+ Mezzanine SRUs are labelled as specified\",\n            \"HMC mezzanine supplier name is obscured by heatsink.\",\n        ]\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.24\")\n    @aqf_requirements(\"CBF-REQ-0162\")\n    def test__use_of_cots_equipment_ve(self):\n        self._test_global_manual(\"CBF.V.3.24\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.25\")\n    @aqf_requirements(\"CBF-REQ-0060\", \"CBF-REQ-0177\", \"CBF-REQ-0196\")\n    def test__logging_ve(self):\n        self._test_global_manual(\"CBF.V.3.25\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.25*\"))\n        caption_list = [\n            \"Screenshot of the command executed via CAM interface (log-level)\"] * len(image_files)\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.33\")\n    @aqf_requirements(\"CBF-REQ-0103\")\n    def test__accumulator_dynamic_range_ve(self):\n        self._test_global_manual(\"CBF.V.3.33\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.36\")\n    @aqf_requirements(\"CBF-REQ-0001\")\n    def test__data_products_available_for_all_receivers_ve(self):\n        self._test_global_manual(\"CBF.V.3.36\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.39\")\n    @aqf_requirements(\"CBF-REQ-0140\")\n    def test__cooling_method_ve(self):\n        self._test_global_manual(\"CBF.V.3.39\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.39*\"))\n        caption_list = [\n            \"Rear doors of all CBF racks are perforated\",\n            \"Front doors of all CBF racks are perforated\"\n            ]\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.40\")\n    @aqf_requirements(\"CBF-REQ-0142\", \"CBF-REQ-0143\")\n    def test__humidity_ve(self):\n        self._test_global_manual(\"CBF.V.3.40\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.41\")\n    @aqf_requirements(\"CBF-REQ-0145\")\n    def test__storage_environment_ve(self):\n        self._test_global_manual(\"CBF.V.3.41\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.42\")\n    @aqf_requirements(\"CBF-REQ-0141\")\n    def test__temperature_range_ve(self):\n        self._test_global_manual(\"CBF.V.3.42\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.43\")\n    @aqf_requirements(\"CBF-REQ-0146\")\n    def test__transportation_of_components_ve(self):\n        self._test_global_manual(\"CBF.V.3.43\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.44\")\n    @aqf_requirements(\"CBF-REQ-0156\")\n    def test__product_marking_environmentals_ve(self):\n        self._test_global_manual(\"CBF.V.3.44\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.44*\"))\n        caption_list = [\n            \"All equipment labels are still attached on {}\".format(i.split(\"/\")[-1].split(\".jpg\")[0])\n            for i in image_files\n        ]\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.45\")\n    @aqf_requirements(\"CBF-REQ-0158\", \"CBF-REQ-0160\")\n    def test__fail_safe_ve(self):\n        self._test_global_manual(\"CBF.V.3.45\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.47\")\n    @aqf_requirements(\"CBF-REQ-0161\", \"CBF-REQ-0186\")\n    def test__safe_physical_design_ve(self):\n        self._test_global_manual(\"CBF.V.3.47\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.48\")\n    @aqf_requirements(\"CBF-REQ-0107\")\n    def test__digitiser_cam_data_ve(self):\n        self._test_global_manual(\"CBF.V.3.48\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.50\")\n    @aqf_requirements(\"CBF-REQ-0149\")\n    def test__mtbf_ve(self):\n        self._test_global_manual(\"CBF.V.3.50\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.52\")\n    @aqf_requirements(\"CBF-REQ-0179\", \"CBF-REQ-0180\", \"CBF-REQ-0190\", \" CBF-REQ-0194\")\n    @aqf_requirements(\"CBF-REQ-0201\", \"CBF-REQ-0202\")\n    def test__internal_interfaces_ve(self):\n        self._test_global_manual(\"CBF.V.3.52\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.53\")\n    @aqf_requirements(\"CBF-REQ-0136\", \"CBF-REQ-0166\")\n    def test__external_interfaces_ve(self):\n        self._test_global_manual(\"CBF.V.3.53\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.54\")\n    @aqf_requirements(\"CBF-REQ-0150\", \"CBF-REQ-0151\")\n    def test__lru_replacement_ve(self):\n        self._test_global_manual(\"CBF.V.3.54\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.3.54*\"))\n        caption_list = [\n            \"LRU replacement: {}\".format(i.split(\"/\")[-1].split(\".jpg\")[0])\n            for i in image_files\n        ]\n        Report_Images(image_files, caption_list)\n\n    @untested\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.57\")\n    @aqf_requirements(\"CBF-REQ-0193\")\n    # @aqf_requirements(\"CBF-REQ-0195\", \"CBF-REQ-0230\", \"CBF-REQ-0231\", \"CBF-REQ-0232\",)\n    # @aqf_requirements(\"CBF-REQ-0233\", \"CBF-REQ-0235\")\n    def test__data_subscribers_link_ve(self):\n        self._test_global_manual(\"CBF.V.3.57\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.6.9\")\n    @aqf_requirements(\"CBF-REQ-0138\")\n    def test__design_to_emc_sans_standard_ve(self):\n        self._test_global_manual(\"CBF.V.6.9\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.6.9*\"))\n        caption_list = [\n            \"Cables are bundled separately but the separation distance is not more than \"\n            \"500mm due to space constraints in the racks.\"\n        ] * len(image_files)\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.6.10\")\n    @aqf_requirements(\"CBF-REQ-0139\")\n    def test__design_standards_ve(self):\n        self._test_global_manual(\"CBF.V.6.10\")\n        image_files = sorted(glob.glob(self._images_dir + \"/CBF.V.6.10*\"))\n        caption_list = [\"CBF processing nodes contains an integrated power filter.\"]\n        Report_Images(image_files, caption_list)\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.66\")\n    @aqf_requirements(\"CBF-REQ-0223\")\n    def test__channelised_voltage_data_transfer_ve(self):\n        self._test_global_manual(\"CBF.V.3.66\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.49\")\n    @aqf_requirements(\"CBF-REQ-0224\")\n    def test__route_basic_spectrometer_data_ve(self):\n        self._test_global_manual(\"CBF.V.3.49\")\n\n    @manual_test\n    @generic_test\n    @aqf_vr(\"CBF.V.3.58\")\n    @aqf_requirements(\"CBF-REQ-0237\")\n    def test__subarray_data_product_set_ve(self):\n        self._test_global_manual(\"CBF.V.3.58\")\n\n    # ----------------------------------------------NOT TESTED-----------------------------------------\n    # ---------------------------------------------------------------------------------------------------\n\n    # @untested\n    # @generic_test\n    # @aqf_vr('CBF.V.3.61')\n    # @aqf_requirements(\"CBF-REQ-0007\")\n    # def test_1_vlbi_data_product(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be qualified on AR3.\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr('CBF.V.3.68')\n    # @aqf_requirements(\"CBF-REQ-0025.1\")\n    # def test_1_data_product_xband(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be qualified on AR3.\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr('CBF.V.3.30')\n    # @aqf_requirements(\"CBF-REQ-0035\", \"CBF-REQ-0036\", \"CBF-REQ-0039\")\n    # @aqf_requirements(\"CBF-REQ-0041\", \"CBF-REQ-0044\", \"CBF-REQ-0050\")\n    # @aqf_requirements(\"CBF-REQ-0051\", \"CBF-REQ-0052\", \"CBF-REQ-0054\", \"CBF-REQ-0198\", \"CBF-REQ-0226\")\n    # @aqf_requirements(\"CBF-REQ-0227\", \"CBF-REQ-0236\", \"CBF-REQ-0243\")\n    # def test__channelisation(self):\n    #     # Aqf.procedure(TestProcedure.Channelisation)\n    #     Aqf.not_tested(\"This requirement will not be qualified on AR3.\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.71\")\n    # @aqf_requirements(\"CBF-REQ-0076\")\n    # def test__tied_array_repoint_time(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.76\")\n    # @aqf_requirements(\"CBF-REQ-0081\", \"CBF-REQ-0082\")\n    # def test__incoherent_beam_total_power_ve(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.7.11\")\n    # @aqf_requirements(\"CBF-REQ-0088\", \"CBF-REQ-0089\", \"CBF-REQ-0090\", \"CBF-REQ-0091\")\n    # def test__antenna_correlation_products(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.69\")\n    # @aqf_requirements(\"CBF-REQ-0093\", \"CBF-REQ-0042\")\n    # def test__vlbi_channelisation(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.63\")\n    # @aqf_requirements(\"CBF-REQ-0095\", \"CBF-REQ-0030\")\n    # def test__pulsar_timing_data_product_set(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.75\")\n    # @aqf_requirements(\"CBF-REQ-0114\", \"CBF-REQ-0115\")\n    # def test__polarisation_correction_ve(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.72\")\n    # @aqf_requirements(\"CBF-REQ-0121\")\n    # def test__ta_antenna_delay_correction(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.73\")\n    # @aqf_requirements(\"CBF-REQ-0122\")\n    # def test__ta_beam_pointing(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.70\")\n    # @aqf_requirements(\"CBF-REQ-0220\")\n    # def test__beam_pointing_polynomial(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.74\")\n    # @aqf_requirements(\"CBF-REQ-0229\")\n    # def test__incoherent_summation(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.65\")\n    # @aqf_requirements(\"CBF-REQ-0239\")\n    # def test__transient_search_data_product_set(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.59\")\n    # @aqf_requirements(\"CBF-REQ-0240\")\n    # def test__flys_eye_data_product_set(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    # @untested\n    # @generic_test\n    # @aqf_vr(\"CBF.V.3.60\")\n    # @aqf_requirements(\"CBF-REQ-0241\")\n    # def test__generic_tiedarray_data_product_set(self):\n    #     Aqf.procedure(\"TBD\")\n    #     Aqf.not_tested(\"This requirement will not be tested on AR3\")\n\n    @generic_test\n    @manual_test\n    @aqf_vr(\"CBF.V.A.IF\")\n    def test__informal(self):\n        Aqf.procedure(\n            \"This verification event pertains to tests that are executed, \"\n            \"but do not verify any formal requirements.\"\n            \"The procedures and results shall be available in the Qualification Test Report.\"\n        )\n        self._test_informal()\n\n    # -----------------------------------------------------------------------------------------------------\n\n    def _systems_tests(self):\n        \"\"\"Checking system stability before and after use\"\"\"\n        try:\n            FNULL = open(os.devnull, \"w\")\n            subprocess.check_call([\"pgrep\", \"-fol\", \"corr2_sensor_servlet.py\"], stdout=FNULL, stderr=FNULL)\n        except Exception:\n            self.Error(\"Sensor_Servlet PID could not be discovered, might not be running.\",\n                exc_info=True)\n\n        if not confirm_out_dest_ip(self):\n            self.Failed(\n                \"Output destination IP is not the same as the one stored in the register, \"\n                \"i.e. data is being spewed elsewhere.\"\n            )\n            set_default_eq(self)\n        # ---------------------------------------------------------------\n        try:\n            self.Step(\"Checking system sensors stability\")\n            for i in xrange(1):\n                try:\n                    reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value(timeout=30)\n                except Exception:\n                    reply, informs = self.katcp_req.sensor_value(timeout=30)\n                time.sleep(10)\n\n            _errored_sensors_ = \", \".join(\n                sorted(list(set([i.arguments[2] for i in informs if \"error\" in i.arguments[-2]])))\n            )\n            _warning_sensors_ = \", \".join(\n                sorted(list(set([i.arguments[2] for i in informs if \"warn\" in i.arguments[-2]])))\n            )\n        except Exception:\n            self.Note(\"Could not retrieve sensors via CAM interface.\")\n        else:\n            if _errored_sensors_:\n                self.Note(\"Following sensors have ERRORS: %s\" % _errored_sensors_)\n                # print('Following sensors have ERRORS: %s' % _errored_sensors_)\n            if _warning_sensors_:\n                self.Note(\"Following sensors have WARNINGS: %s\" % _warning_sensors_)\n                # print('Following sensors have WARNINGS: %s' % _warning_sensors_)\n\n    def _delays_setup(self, test_source_idx=2):\n        # Put some correlated noise on both outputs\n        if \"4k\" in self.instrument:\n            # 4K\n            awgn_scale = 0.0645\n            gain = \"113+0j\"\n            fft_shift = 511\n        else:\n            # 32K\n            awgn_scale = 0.063\n            gain = \"344+0j\"\n            fft_shift = 4095\n\n        self.Step(\"Configure digitiser simulator to generate Gaussian noise.\")\n        self.Progress(\n            \"Digitiser simulator configured to generate Gaussian noise with scale: {}, \"\n            \"gain: {} and fft shift: {}.\".format(awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(self, awgn_scale=awgn_scale, fft_shift=fft_shift, gain=gain)\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        # local_src_names = self.cam_sensors.custom_input_labels\n        network_latency = float(self.conf_file[\"instrument_params\"][\"network_latency\"])\n        cam_max_load_time = int(self.conf_file[\"instrument_params\"][\"cam_max_load_time\"])\n        source_names = self.cam_sensors.input_labels\n        # Get name for test_source_idx\n        test_source = source_names[test_source_idx]\n        ref_source = source_names[0]\n        num_inputs = len(source_names)\n        # Number of integrations to load delays in the future\n        num_int = int(self.conf_file[\"instrument_params\"][\"num_int_delay_load\"])\n        self.Step(\"Clear all coarse and fine delays for all inputs before test commences.\")\n        delays_cleared = clear_all_delays(self)\n        if not delays_cleared:\n            self.Failed(\"Delays were not completely cleared, data might be corrupted.\")\n        else:\n            Aqf.passed(\"Cleared all previously applied delays prior to test.\")\n\n        self.Step(\"Retrieve initial SPEAD accumulation, in-order to calculate all \" \"relevant parameters.\")\n        try:\n            initial_dump = self.get_clean_dump()\n        except Queue.Empty:\n            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue might be Empty.\"\n            self.Failed(errmsg, exc_info=True)\n        else:\n            self.Progress(\"Successfully retrieved initial spead accumulation\")\n            int_time = self.cam_sensors.get_value(\"int_time\")\n            synch_epoch = self.cam_sensors.get_value(\"synch_epoch\")\n            # n_accs = self.cam_sensors.get_value('n_accs')]\n            # no_chans = range(self.n_chans_selected)\n            time_stamp = initial_dump[\"timestamp\"]\n            # ticks_between_spectra = initial_dump['ticks_between_spectra'].value\n            # int_time_ticks = n_accs * ticks_between_spectra\n            t_apply = initial_dump[\"dump_timestamp\"] + num_int * int_time\n            t_apply_readable = datetime.fromtimestamp(t_apply).strftime(\"%H:%M:%S\")\n            curr_time = time.time()\n            curr_time_readable = datetime.fromtimestamp(curr_time).strftime(\"%H:%M:%S\")\n            try:\n                baseline_lookup = get_baselines_lookup(self)\n                # Choose baseline for phase comparison\n                baseline_index = baseline_lookup[(ref_source, test_source)]\n                self.Step(\"Get list of all the baselines present in the correlator output\")\n                self.Progress(\n                    \"Selected input and baseline for testing respectively: %s, %s.\" % (test_source, baseline_index)\n                )\n                self.Progress(\n                    \"Time to apply delays: %s (%s), Current cmc time: %s (%s), Delays will be \"\n                    \"applied %s integrations/accumulations in the future.\"\n                    % (t_apply, t_apply_readable, curr_time, curr_time_readable, num_int)\n                )\n            except KeyError:\n                self.Failed(\"Initial SPEAD accumulation does not contain correct baseline ordering format.\")\n                return False\n            else:\n                return {\n                    \"baseline_index\": baseline_index,\n                    \"baseline_lookup\": baseline_lookup,\n                    \"initial_dump\": initial_dump,\n                    \"int_time\": int_time,\n                    \"network_latency\": network_latency,\n                    \"num_inputs\": num_inputs,\n                    \"sample_period\": self.cam_sensors.sample_period,\n                    \"t_apply\": t_apply,\n                    \"test_source\": test_source,\n                    \"test_source_ind\": test_source_idx,\n                    \"time_stamp\": time_stamp,\n                    \"synch_epoch\": synch_epoch,\n                    \"num_int\": num_int,\n                    \"cam_max_load_time\": cam_max_load_time,\n                }\n\n    def _get_actual_data(self, setup_data, dump_counts, delay_coefficients, max_wait_dumps=50):\n        try:\n            self.Step(\"Request Fringe/Delay(s) Corrections via CAM interface.\")\n            load_strt_time = time.time()\n            reply, _informs = self.katcp_req.delays(\n                setup_data[\"t_apply\"], *delay_coefficients, timeout=30)\n            load_done_time = time.time()\n            errmsg = (\"%s: Failed to set delays via CAM interface with load-time: %s, \"\n                      \"Delay coefficients: %s\" % (\n                            str(reply).replace(\"\\_\", \" \"),\n                            setup_data[\"t_apply\"],\n                            delay_coefficients,\n                        ))\n            assert reply.reply_ok(), errmsg\n            actual_delay_coef = reply.arguments[1:]\n            assert \"updated\" in actual_delay_coef[0]\n            cmd_load_time = round(load_done_time - load_strt_time, 3)\n            self.Step(\"Fringe/Delay load command took {} seconds\".format(cmd_load_time))\n            # _give_up = int(setup_data['num_int'] * setup_data['int_time'] * 3)\n            # while True:\n            #    _give_up -= 1\n            #    try:\n            #        self.logger.info('Waiting for the delays to be updated on sensors: %s retry' % _give_up)\n            #        try:\n            #            reply_, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value()\n            #        except:\n            #            reply_, informs = self.katcp_req.sensor_value()\n            #        assert reply_.reply_ok()\n            #    except Exception:\n            #        self.logger.exception('Weirdly I could not get the sensor values')\n            #    else:\n            #        delays_updated = list(set([int(i.arguments[-1]) for i in informs\n            #                                if '.cd.delay' in i.arguments[2]]))[0]\n            #        if delays_updated:\n            #            self.logger.info('Delays have been successfully set')\n            #            msg = ('Delays set successfully via CAM interface: reply %s' % str(reply))\n            #            Aqf.passed(msg)\n            #            break\n            #    if _give_up == 0:\n            #        msg = (\"Could not confirm the delays in the time stipulated, exiting\")\n            #        self.logger.error(msg)\n            #        self.Failed(msg)\n            #        break\n            #    time.sleep(1)\n\n            # Tested elsewhere\n            # cam_max_load_time = setup_data['cam_max_load_time']\n            # msg = 'Time it took to load delay/fringe(s) %s is less than %ss' % (cmd_load_time,\n            #        cam_max_load_time)\n            # Aqf.less(cmd_load_time, cam_max_load_time, msg)\n        except Exception:\n            self.Failed(errmsg, exc_info=True)\n            return\n\n        last_discard = setup_data[\"t_apply\"] - setup_data[\"int_time\"]\n        num_discards = 0\n        fringe_dumps = []\n        self.Step(\n            \"Getting SPEAD accumulation containing the change in fringes(s) on input: %s \"\n            \"baseline: %s, and discard all irrelevant accumulations.\"\n            % (setup_data[\"test_source\"], setup_data[\"baseline_index\"])\n        )\n        while True:\n            num_discards += 1\n            try:\n                dump = self.receiver.data_queue.get()\n                self.assertIsInstance(dump, dict)\n            except Exception:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue might be Empty.\"\n                self.Failed(errmsg, exc_info=True)\n            else:\n                time_diff = np.abs(dump[\"dump_timestamp\"] - last_discard)\n                if time_diff < 0.1 * setup_data[\"int_time\"]:\n                    fringe_dumps.append(dump)\n                    msg = (\n                        \"Received final accumulation before fringe \"\n                        \"application with dump timestamp: %s, relevant to time apply: %s \"\n                        \"(Difference %s)\" % (dump[\"dump_timestamp\"], setup_data[\"t_apply\"], time_diff)\n                    )\n                    Aqf.passed(msg)\n                    self.logger.info(msg)\n                    break\n\n                if num_discards > max_wait_dumps:\n                    self.Failed(\n                        \"Could not get accumulation with correct timestamp within %s \"\n                        \"accumulation periods.\" % max_wait_dumps\n                    )\n                    # break\n                    return\n                else:\n                    msg = (\n                        \"Discarding (#%d) Spead accumulation with dump timestamp: %s\"\n                        \", relevant to time to apply: %s\"\n                        \"(Difference %.2f), Current cmc time: %s.\"\n                        % (\n                            num_discards, dump[\"dump_timestamp\"],\n                            setup_data[\"t_apply\"], time_diff, time.time())\n                    )\n                    if num_discards <= 2:\n                        self.Progress(msg)\n                    elif num_discards == 3:\n                        self.Progress(\"...\")\n                    elif time_diff < 3:\n                        self.Progress(msg)\n\n        def _force_discard():\n            self.receiver.data_queue.get()\n            self.receiver.data_queue.get()\n\n        # For debugging, for some weird reason we have to discard 2 dumps before capturing the\n        # data with the change in phase\n        _force_discard()\n        for i in xrange(dump_counts - 1):\n            self.Progress(\"Getting subsequent SPEAD accumulation {}.\".format(i + 1))\n            try:\n                dump = self.receiver.data_queue.get()\n                self.assertIsInstance(dump, dict)\n            except Exception:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue might be Empty.\"\n                self.Error(errmsg, exc_info=True)\n            else:\n                fringe_dumps.append(dump)\n\n        chan_resp = []\n        phases = []\n        for acc in fringe_dumps:\n            dval = acc[\"xeng_raw\"]\n            freq_response = normalised_magnitude(dval[:, setup_data[\"baseline_index\"], :])\n            chan_resp.append(freq_response)\n            data = complexise(dval[:, setup_data[\"baseline_index\"], :])\n            phases.append(np.angle(data))\n        return zip(phases, chan_resp)\n\n    def _get_expected_data(self, setup_data, dump_counts, delay_coefficients, actual_phases):\n        def calc_actual_delay(setup_data):\n            no_ch = self.cam_sensors.get_value(\"n_chans\")\n            first_dump = np.unwrap(actual_phases[0])\n            actual_slope = np.polyfit(xrange(0, no_ch), first_dump, 1)[0] * no_ch\n            actual_delay = self.cam_sensors.sample_period * actual_slope / np.pi\n            return actual_delay\n\n        def gen_delay_vector(delay, setup_data):\n            res = []\n            no_ch = self.cam_sensors.get_value(\"n_chans\")\n            delay_slope = np.pi * (delay / self.cam_sensors.sample_period)\n            c = delay_slope / 2\n            for i in xrange(0, no_ch):\n                m = i / float(no_ch)\n                res.append(delay_slope * m - c)\n            return res\n\n        def gen_delay_data(delay, delay_rate, dump_counts, setup_data):\n            expected_phases = []\n            prev_delay_rate = 0\n            for dump in xrange(0, dump_counts):\n                # For delay rate the expected delay is the average of delays\n                # applied during the integration. This is equal to the\n                # delay delta over the integration divided by two\n                max_delay_rate = dump * delay_rate\n                avg_delay_rate = ((max_delay_rate - prev_delay_rate) / 2) + prev_delay_rate\n                prev_delay_rate = max_delay_rate\n                tot_delay = delay + avg_delay_rate * self.cam_sensors.get_value(\"int_time\")\n                expected_phases.append(gen_delay_vector(tot_delay, setup_data))\n            return expected_phases\n\n        def calc_actual_offset(setup_data):\n            # mid_ch = no_ch / 2\n            first_dump = actual_phases[0]\n            # Determine average offset around 5 middle channels\n            actual_offset = np.average(first_dump)  # [mid_ch-3:mid_ch+3])\n            return actual_offset\n\n        def gen_fringe_vector(offset, setup_data):\n            return [offset] * self.cam_sensors.get_value(\"n_chans\")\n\n        def gen_fringe_data(fringe_offset, fringe_rate, dump_counts, setup_data):\n            expected_phases = []\n            prev_fringe_rate = 0\n            for dump in xrange(0, dump_counts):\n                # For fringe rate the expected delay is the average of delays\n                # applied during the integration. This is equal to the\n                # delay delta over the integration divided by two\n                max_fringe_rate = dump * fringe_rate\n                avg_fringe_rate = ((max_fringe_rate - prev_fringe_rate) / 2) + prev_fringe_rate\n                prev_fringe_rate = max_fringe_rate\n                offset = -(fringe_offset + avg_fringe_rate * self.cam_sensors.get_value(\"int_time\"))\n                expected_phases.append(gen_fringe_vector(offset, setup_data))\n            return expected_phases\n\n        ant_delay = []\n        for delay in delay_coefficients:\n            bits = delay.strip().split(\":\")\n            if len(bits) != 2:\n                raise ValueError(\"%s is not a valid delay setting\" % delay)\n            delay = bits[0]\n            delay = delay.split(\",\")\n            delay = (float(delay[0]), float(delay[1]))\n            fringe = bits[1]\n            fringe = fringe.split(\",\")\n            fringe = (float(fringe[0]), float(fringe[1]))\n            ant_delay.append((delay, fringe))\n\n        ant_idx = setup_data[\"test_source_ind\"]\n        delay = ant_delay[ant_idx][0][0]\n        delay_rate = ant_delay[ant_idx][0][1]\n        fringe_offset = ant_delay[ant_idx][1][0]\n        fringe_rate = ant_delay[ant_idx][1][1]\n\n        delay_data = np.array((gen_delay_data(delay, delay_rate, dump_counts + 1, setup_data)))[1:]\n        fringe_data = np.array(gen_fringe_data(fringe_offset, fringe_rate, dump_counts + 1, setup_data))[1:]\n        result = delay_data + fringe_data\n        wrapped_results = (result + np.pi) % (2 * np.pi) - np.pi\n\n        if (fringe_offset or fringe_rate) != 0:\n            fringe_phase = [np.abs((np.min(phase) + np.max(phase)) / 2.0) for phase in fringe_data]\n            return zip(fringe_phase, wrapped_results)\n        else:\n            delay_phase = [np.abs((np.min(phase) - np.max(phase)) / 2.0) for phase in delay_data]\n            return zip(delay_phase, wrapped_results)\n\n    def _process_power_log(self, start_timestamp, power_log_file):\n        max_power_per_rack = 6.25\n        max_power_diff_per_rack = 33\n        max_power_cbf = 60\n        time_gap = 60\n\n        df = pd.read_csv(power_log_file, delimiter=\"\\t\")\n        headers = list(df.keys())\n        exp_headers = [\"Sample Time\", \"PDU Host\", \"Phase Current\", \"Phase Power\"]\n        if headers != exp_headers:\n            raise IOError(power_log_file)\n        pdus = list(set(list(df[headers[1]])))\n        # Slice out requested time block\n        end_ts = df[\"Sample Time\"].iloc[-1]\n        try:\n            strt_idx = df[df[\"Sample Time\"] >= int(start_timestamp)].index\n        except TypeError:\n            msg = \"\"\n            self.Error(msg, exc_info=True)\n        else:\n            df = df.loc[strt_idx]\n            end_idx = df[df[\"Sample Time\"] <= end_ts].index\n            df = df.loc[end_idx]\n            # Check for gaps and warn\n            time_stamps = df[\"Sample Time\"].values\n            ts_diff = np.diff(time_stamps)\n            time_gaps = np.where(ts_diff > time_gap)\n            for idx in time_gaps[0]:\n                ts = time_stamps[idx]\n                diff_time = datetime.fromtimestamp(int(ts)).strftime(\"%Y-%m-%d_%H:%M\")\n                diff = ts_diff[idx]\n                self.Step(\"Time gap of {}s found at {} in PDU samples.\".format(diff, diff_time))\n            # Convert power column to floats and build new array\n            df_list = np.asarray(df.values.tolist())\n            power_col = [x.split(\",\") for x in df_list[:, 3]]\n            power_col = [[float(x) for x in y] for y in power_col]\n            curr_col = [x.split(\",\") for x in df_list[:, 2]]\n            curr_col = [[float(x) for x in y] for y in curr_col]\n            cp_col = zip(curr_col, power_col)\n            power_array = []\n            for idx, val in enumerate(cp_col):\n                power_array.append([df_list[idx, 0], df_list[idx, 1], val[0], val[1]])\n            # Cut array into sets containing all pdus for a time slice\n            num_pdus = len(pdus)\n            rolled_up_samples = []\n            time_slice = []\n            name_found = []\n            pdus = np.asarray(pdus)\n            # Create dictionary with rack names\n            pdu_samples = {x: [] for x in pdus}\n            for _time, name, cur, power in power_array:\n                try:\n                    name_found.index(name)\n                except ValueError:\n                    # Remove NANs\n                    if not (np.isnan(cur[0]) or np.isnan(power[0])):\n                        time_slice.append([_time, name, cur, power])\n                    name_found.append(name)\n                else:\n                    # Only add time slices with samples from all PDUS\n                    if len(time_slice) == num_pdus:\n                        rolled_up = np.zeros(3)\n                        for sample in time_slice:\n                            rolled_up += np.asarray(sample[3])\n                        # add first timestamp from slice\n                        rolled_up = np.insert(rolled_up, 0, int(time_slice[0][0]))\n                        rolled_up_samples.append(rolled_up)\n                        # Populate samples per pdu\n                        for name in pdus:\n                            sample = next(x for x in time_slice if x[1] == name)\n                            sample = (sample[2], sample[3])\n                            smple = np.asarray(sample)\n                            pdu_samples[name].append(smple)\n\n                    time_slice = []\n                    name_found = []\n            if rolled_up_samples:\n                start_time = datetime.fromtimestamp(rolled_up_samples[0][0]).strftime(\"%Y-%m-%d %H:%M:%S\")\n                end_time = datetime.fromtimestamp(rolled_up_samples[-1][0]).strftime(\"%Y-%m-%d %H:%M:%S\")\n                ru_smpls = np.asarray(rolled_up_samples)\n                tot_power = ru_smpls[:, 1:4].sum(axis=1)\n                self.Step(\"Compile Power consumption report while running SFDR test.\")\n                self.Progress(\"Power report from {} to {}\".format(start_time, end_time))\n                self.Progress(\"Average sample time: {}s\".format(int(np.diff(ru_smpls[:, 0]).mean())))\n                # Add samples for pdus in same rack\n                rack_samples = {x[: x.find(\"-\")]: [] for x in pdus}\n                for name in pdu_samples:\n                    rack_name = name[: name.find(\"-\")]\n                    if rack_samples[rack_name] != []:\n                        sample = np.add(rack_samples[rack_name], pdu_samples[name])\n                    else:\n                        sample = pdu_samples[name]\n                    rack_samples[rack_name] = sample\n                for rack in rack_samples:\n                    val = np.asarray(rack_samples[rack])\n                    curr = val[:, 0]\n                    power = val[:, 1]\n                    watts = power.sum(axis=1).mean()\n                    self.Step(\"Measure CBF Power rack and confirm power consumption is less than 6.25kW\")\n                    msg = \"Measured power for rack {} ({:.2f}kW) is less than {}kW\".format(\n                        rack, watts, max_power_per_rack\n                    )\n                    Aqf.less(watts, max_power_per_rack, msg)\n                    phase = np.zeros(3)\n                    for i, x in enumerate(phase):\n                        phase[i] = curr[:, i].mean()\n                    self.Step(\"Measure CBF Power and confirm power consumption is less than 60kW\")\n                    self.Progress(\n                        \"Average current per phase for rack {}: P1={:.2f}A, P2={:.2f}A, \"\n                        \"P3={:.2f}A\".format(rack, phase[0], phase[1], phase[2])\n                    )\n                    ph_m = np.max(phase)\n                    max_diff = np.max([100 * (x / ph_m) for x in ph_m - phase])\n                    max_diff = float(\"{:.1f}\".format(max_diff))\n                    self.Step(\"Measure CBF Peak Power and confirm power consumption is less than 60kW\")\n                    msg = \"Maximum difference in current per phase for rack {} ({:.1f}%) is \" \"less than {}%\".format(\n                        rack, max_diff, max_power_diff_per_rack\n                    )\n                    # Aqf.less(max_diff,max_power_diff_per_rack,msg)\n                    # Aqf.waived(msg)\n                watts = tot_power.mean()\n                msg = \"Measured power for CBF ({:.2f}kW) is less than {}kW\".format(watts, max_power_cbf)\n                Aqf.less(watts, max_power_cbf, msg)\n                watts = tot_power.max()\n                msg = \"Measured peak power for CBF ({:.2f}kW) is less than {}kW\".format(watts, max_power_cbf)\n                Aqf.less(watts, max_power_cbf, msg)\n\n    #################################################################\n    #                       Test Methods                            #\n    #################################################################\n\n    def _test_channelisation(self, test_chan=1500, no_channels=None, req_chan_spacing=None, num_discards=3):\n        # Get baseline 0 data, i.e. auto-corr of m000h\n        test_baseline = 0\n        # [CBF-REQ-0053]\n        min_bandwithd_req = 770e6\n        # [CBF-REQ-0126] CBF channel isolation\n        cutoff = 53  # dB\n        # Placeholder of actual frequencies that the signal generator produces\n        actual_test_freqs = []\n        # Channel magnitude responses for each frequency\n        chan_responses = []\n        last_source_freq = None\n\n        print_counts = 3\n\n        if \"1k\" in self.instrument:\n            cw_scale = 0.9\n            awgn_scale = 0.085\n            gain = \"7+0j\"\n            fft_shift = 8191\n            test_chan = 596\n        elif \"4k\" in self.instrument:\n            cw_scale = 0.9\n            awgn_scale = 0.085\n            gain = \"7+0j\"\n            fft_shift = 8191\n            # cw_scale = 0.9\n            # awgn_scale = 0.1\n            # gain = '7+0j'\n            # fft_shift = 8191\n            # cw_scale = 0.9\n            # awgn_scale = 0.0\n            # gain = '7+0j'\n            # fft_shift = 8191\n        elif \"32k\":\n            # 32K\n            cw_scale = 0.375\n            awgn_scale = 0.085\n            gain = \"11+0j\"\n            fft_shift = 32767\n        else:\n            msg = \"Instrument not found: {}\".format(self.instrument)\n            self.logger.exception(msg)\n            self.Failed(msg)\n\n        requested_test_freqs = self.cam_sensors.calc_freq_samples(test_chan, samples_per_chan=101, chans_around=2)\n        expected_fc = self.cam_sensors.ch_center_freqs[test_chan]\n        # Why is this necessary\n        # http://library.nrao.edu/public/memos/ovlbi/OVLBI_038.pdf\n        # https://www.prosoundtraining.com/2010/03/11/hand-in-hand-phase-and-group-delay/\n        self.Note(\"Residual delay is excluded from this test.\")\n        self.Step(\n            \"Digitiser simulator configured to generate a continuous wave (cwg0), \"\n            \"with cw scale: {}, awgn scale: {}, eq gain: {}, fft shift: {}\".format(\n                cw_scale, awgn_scale, gain, fft_shift\n            )\n        )\n        dsim_set_success = set_input_levels(\n            self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=expected_fc, fft_shift=fft_shift, gain=gain\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n        try:\n            self.Step(\n                \"Randomly select a frequency channel to test. Capture an initial correlator \"\n                \"SPEAD accumulation, determine the number of frequency channels\"\n            )\n            # initial_dump = self.receiver.get_clean_dump(discard=num_discards * 10)\n            initial_dump = self.receiver.get_clean_dump(discard=5)\n            self.assertIsInstance(initial_dump, dict)\n        except Exception:\n            errmsg = \"Could not retrieve initial clean SPEAD accumulation: Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n            return\n        else:\n            bls_to_test = eval(self.cam_sensors.get_value(\"bls_ordering\"))[test_baseline]\n            self.Progress(\n                \"Randomly selected frequency channel to test: {} and \"\n                \"selected baseline {} / {} to test.\".format(test_chan, test_baseline, bls_to_test)\n            )\n            # Aqf.equals(4096, no_channels,\n            #           'Confirm that the number of channels in the SPEAD accumulation, is equal '\n            #           'to the number of frequency channels as calculated: {}'.format(\n            #              no_channels))\n            self.Step(\n                \"The CBF, when configured to produce the Imaging data product set and Wideband \"\n                \"Fine resolution channelisation, shall channelise a total bandwidth of >= %s\" % (min_bandwithd_req)\n            )\n            Aqf.is_true(\n                self.cam_sensors.get_value(\"bandwidth\") >= min_bandwithd_req,\n                \"Channelise total bandwidth {}Hz shall be >= {}Hz.\".format(\n                    self.cam_sensors.get_value(\"bandwidth\"), min_bandwithd_req\n                ),\n            )\n            # TODO (MM) 2016-10-27, As per JM\n            # Channel spacing is reported as 209.266kHz. This is probably spot-on, considering we're\n            # using a dsim that's not actually sampling at 1712MHz. But this is problematic for the\n            # test report. We would be getting 1712MHz/8192=208.984375kHz on site.\n            # Maybe we should be reporting this as a fraction of total sampling rate rather than\n            # an absolute value? ie 1/4096=2.44140625e-4 I will speak to TA about how to handle this.\n            # chan_spacing = 856e6 / np.shape(initial_dump['xeng_raw'])[0]\n            chan_spacing = self.cam_sensors.get_value(\"bandwidth\") / self.cam_sensors.get_value(\"n_chans\")\n            chan_spacing_tol = [chan_spacing - (chan_spacing * 1 / 100), chan_spacing + (chan_spacing * 1 / 100)]\n            self.Step(\n                \"CBF-REQ-0043 and CBF-REQ-0053 Confirm that the number of calculated channel \"\n                \"frequency step is within requirement.\"\n            )\n            msg = \"Verify that the calculated channel frequency (%s Hz)step size is between %s and \" \"%s Hz\" % (\n                chan_spacing,\n                req_chan_spacing / 2,\n                req_chan_spacing,\n            )\n            Aqf.in_range(chan_spacing, req_chan_spacing / 2, req_chan_spacing, msg)\n\n            self.Step(\n                \"CBF-REQ-0046 and CBF-REQ-0047 Confirm that the channelisation spacing and \"\n                \"confirm that it is within the maximum tolerance.\"\n            )\n            msg = \"Channelisation spacing is within maximum tolerance of 1% of the \" \"channel spacing.\"\n            Aqf.in_range(chan_spacing, chan_spacing_tol[0], chan_spacing_tol[1], msg)\n            initial_dump = self.receiver.get_clean_dump(discard=num_discards)\n            initial_freq_response = normalised_magnitude(initial_dump[\"xeng_raw\"][:, test_baseline, :])\n            where_is_the_tone = np.argmax(initial_freq_response)\n            max_tone_val = np.max(initial_freq_response)\n            self.Note(\n                \"Single peak found at channel %s, with max power of %.5f(%.5fdB)\"\n                % (where_is_the_tone, max_tone_val, 10 * np.log10(max_tone_val))\n            )\n\n            plt_filename = \"{}/{}_overall_channel_resolution_Initial_capture.png\".format(\n                self.logs_path, self._testMethodName\n            )\n            plt_title = \"Initial Overall frequency response at %s\" % test_chan\n            caption = (\n                \"An overall frequency response at the centre frequency %s,\"\n                \"and selected baseline %s to test. Digitiser simulator is configured to \"\n                \"generate a continuous wave, with cw scale: %s, awgn scale: %s, Eq gain: %s \"\n                \"and FFT shift: %s\" % (test_chan, test_baseline, cw_scale, awgn_scale, gain, fft_shift)\n            )\n            aqf_plot_channels(initial_freq_response, plt_filename, plt_title, caption=caption, ylimits=(-100, 1))\n\n        self.Step(\n            \"Sweep the digitiser simulator over the centre frequencies of at \"\n            \"least all the channels that fall within the complete L-band\"\n        )\n        failure_count = 0\n        for i, freq in enumerate(requested_test_freqs):\n            _msg = \"Getting channel response for freq {} @ {}: {:.3f} MHz.\".format(\n                i + 1, len(requested_test_freqs), freq / 1e6\n            )\n            if i < print_counts:\n                self.Progress(_msg)\n            elif i == print_counts:\n                self.Progress(\".\" * print_counts)\n            elif i >= (len(requested_test_freqs) - print_counts):\n                self.Progress(_msg)\n            else:\n                self.logger.debug(_msg)\n\n            self.dhost.sine_sources.sin_0.set(frequency=freq, scale=cw_scale)\n            # self.dhost.sine_sources.sin_1.set(frequency=freq, scale=cw_scale)\n            this_source_freq = self.dhost.sine_sources.sin_0.frequency\n\n            if this_source_freq == last_source_freq:\n                self.logger.debug(\n                    \"Skipping channel response for freq %s @ %s: %s MHz.\\n\"\n                    \"Digitiser frequency is same as previous.\" % (i + 1, len(requested_test_freqs), freq / 1e6)\n                )\n                continue  # Already calculated this one\n            else:\n                last_source_freq = this_source_freq\n\n            try:\n                this_freq_dump = self.receiver.get_clean_dump(discard=num_discards)\n                self.assertIsInstance(this_freq_dump, dict)\n            except AssertionError:\n                failure_count += 1\n                errmsg = \"Could not retrieve clean accumulation for freq (%s @ %s: %sMHz).\" % (\n                    i + 1,\n                    len(requested_test_freqs),\n                    freq / 1e6,\n                )\n                self.Error(errmsg, exc_info=True)\n                if failure_count >= 5:\n                    _errmsg = \"Cannot continue running the test, Not receiving clean accumulations.\"\n                    self.Failed(_errmsg)\n                    return False\n            else:\n                # No of spead heap discards relevant to vacc\n                discards = 0\n                max_wait_dumps = 50\n                while True:\n                    try:\n                        queued_dump = self.receiver.data_queue.get(timeout=DUMP_TIMEOUT)\n                        self.assertIsInstance(queued_dump, dict)\n                        deng_timestamp = float(self.dhost.registers.sys_clkcounter.read().get(\"timestamp\"))\n                        assert isinstance(deng_timestamp, float)\n                    except Exception:\n                        errmsg = \"Could not retrieve clean queued accumulation for freq(%s @ %s: \" \"%s MHz).\" % (\n                            i + 1,\n                            len(requested_test_freqs),\n                            freq / 1e6,\n                        )\n                        self.Error(errmsg, exc_info=True)\n                        break\n                    else:\n                        timestamp_diff = np.abs(queued_dump[\"dump_timestamp\"] - deng_timestamp)\n                        # print colored(timestamp_diff, 'red')\n                        if timestamp_diff < 2:\n                            msg = (\n                                \"Received correct accumulation timestamp: %s, relevant to \"\n                                \"DEngine timestamp: %s (Difference %.2f)\"\n                                % (queued_dump[\"dump_timestamp\"], deng_timestamp, timestamp_diff)\n                            )\n                            self.logger.info(_msg)\n                            self.logger.info(msg)\n                            break\n\n                        if discards > max_wait_dumps:\n                            errmsg = (\n                                \"Could not get accumulation with correct timestamp within %s \"\n                                \"accumulation periods.\" % max_wait_dumps\n                            )\n                            self.Failed(errmsg)\n                            if discards > 10:\n                                return\n                            break\n                        else:\n                            msg = (\n                                \"Discarding subsequent dumps (%s) with dump timestamp (%s) \"\n                                \"and DEngine timestamp (%s) with difference of %s.\"\n                                % (discards, queued_dump[\"dump_timestamp\"], deng_timestamp, timestamp_diff)\n                            )\n                            self.logger.info(msg)\n                        deng_timestamp = None\n                    discards += 1\n\n                this_freq_data = queued_dump[\"xeng_raw\"]\n                this_freq_response = normalised_magnitude(this_freq_data[:, test_baseline, :])\n                # print(\"{} {} \".format(np.max(this_freq_response), np.argmax(this_freq_response)))\n                actual_test_freqs.append(this_source_freq)\n                chan_responses.append(this_freq_response)\n\n            # Plot an overall frequency response at the centre frequency just as\n            # a sanity check\n\n            if np.abs(freq - expected_fc) < 0.1:\n                plt_filename = \"{}/{}_overall_channel_resolution.png\".format(self.logs_path, self._testMethodName)\n                plt_title = \"Overall frequency response at {} at {:.3f}MHz.\".format(test_chan, this_source_freq / 1e6)\n                max_peak = np.max(loggerise(this_freq_response))\n                self.Note(\n                    \"Single peak found at channel %s, with max power of %s (%fdB) midway \"\n                    \"channelisation, to confirm if there is no offset.\"\n                    % (np.argmax(this_freq_response), np.max(this_freq_response), max_peak)\n                )\n                new_cutoff = max_peak - cutoff\n                y_axis_limits = (-100, 1)\n                caption = (\n                    \"An overall frequency response at the centre frequency, and ({:.3f}dB) \"\n                    \"and selected baseline {} / {} to test. CBF channel isolation [max channel\"\n                    \" peak ({:.3f}dB) - ({}dB) cut-off] when \"\n                    \"digitiser simulator is configured to generate a continuous wave, with \"\n                    \"cw scale: {}, awgn scale: {}, Eq gain: {} and FFT shift: {}\".format(\n                        new_cutoff, test_baseline, bls_to_test, max_peak, cutoff, cw_scale, awgn_scale, gain, fft_shift\n                    )\n                )\n                aqf_plot_channels(\n                    this_freq_response,\n                    plt_filename,\n                    plt_title,\n                    caption=caption,\n                    ylimits=y_axis_limits,\n                    cutoff=new_cutoff,\n                )\n\n        if not where_is_the_tone == test_chan:\n            self.Note(\n                \"We expect the channel response at %s, but in essence it is in channel %s, ie \"\n                \"There's a channel offset of %s\" % (test_chan, where_is_the_tone, np.abs(test_chan - where_is_the_tone))\n            )\n            test_chan += np.abs(test_chan - where_is_the_tone)\n\n        # Convert the lists to numpy arrays for easier working\n        actual_test_freqs = np.array(actual_test_freqs)\n        chan_responses = np.array(chan_responses)\n        df = self.cam_sensors.delta_f\n        try:\n            rand_chan_response = len(chan_responses[random.randrange(len(chan_responses))])\n            # assert rand_chan_response == self.n_chans_selected\n        except AssertionError:\n            errmsg = (\n                \"Number of channels (%s) found on the spead data is inconsistent with the \"\n                \"number of channels (%s) expected.\" % (rand_chan_response, self.n_chans_selected)\n            )\n            self.Error(errmsg, exc_info=True)\n        else:\n            csv_filename = \"/\".join([self._katreport_dir, r\"CBF_Efficiency_Data.csv\"])\n            np.savetxt(csv_filename, zip(chan_responses[:, test_chan], requested_test_freqs), delimiter=\",\")\n            plt_filename = \"{}/{}_Channel_Response.png\".format(self.logs_path, self._testMethodName)\n            plot_data = loggerise(chan_responses[:, test_chan], dynamic_range=90, normalise=True, no_clip=True)\n            plt_caption = (\n                \"Frequency channel {} @ {}MHz response vs source frequency and \"\n                \"selected baseline {} / {} to test.\".format(test_chan, expected_fc / 1e6, test_baseline, bls_to_test)\n            )\n            plt_title = \"Channel {} @ {:.3f}MHz response.\".format(test_chan, expected_fc / 1e6)\n            # Plot channel response with -53dB cutoff horizontal line\n            aqf_plot_and_save(\n                freqs=actual_test_freqs[1:-1],\n                data=plot_data[1:-1],\n                df=df,\n                expected_fc=expected_fc,\n                plot_filename=plt_filename,\n                plt_title=plt_title,\n                caption=plt_caption,\n                cutoff=-cutoff,\n            )\n            try:\n                # CBF-REQ-0126\n                pass_bw_min_max = np.argwhere((np.abs(plot_data) >= 3.0) & (np.abs(plot_data) <= 3.3))\n                pass_bw = float(np.abs(actual_test_freqs[pass_bw_min_max[0]] - actual_test_freqs[pass_bw_min_max[-1]]))\n\n                att_bw_min_max = [\n                    np.argwhere(plot_data == i)[0][0]\n                    for i in plot_data\n                    if (abs(i) >= (cutoff - 1)) and (abs(i) <= (cutoff + 1))\n                ]\n                att_bw = actual_test_freqs[att_bw_min_max[-1]] - actual_test_freqs[att_bw_min_max[0]]\n\n            except Exception:\n                msg = (\n                    \"Could not compute if, CBF performs channelisation such that the 53dB \"\n                    \"attenuation bandwidth is less/equal to 2x the pass bandwidth\"\n                )\n                self.Error(msg, exc_info=True)\n            else:\n                msg = (\n                    \"The CBF shall perform channelisation such that the 53dB attenuation bandwidth(%s)\"\n                    \"is less/equal to 2x the pass bandwidth(%s)\" % (att_bw, pass_bw)\n                )\n                Aqf.is_true(att_bw >= pass_bw, msg)\n\n            # Get responses for central 80% of channel\n            df = self.cam_sensors.delta_f\n            central_indices = (actual_test_freqs <= expected_fc + 0.4 * df) & (\n                actual_test_freqs >= expected_fc - 0.4 * df\n            )\n            central_chan_responses = chan_responses[central_indices]\n            central_chan_test_freqs = actual_test_freqs[central_indices]\n\n            # Plot channel response for central 80% of channel\n            graph_name_central = \"{}/{}_central.png\".format(self.logs_path, self._testMethodName)\n            plot_data_central = loggerise(\n                central_chan_responses[:, test_chan], dynamic_range=90, normalise=True, no_clip=True\n            )\n\n            n_chans = self.n_chans_selected\n            caption = (\n                \"Channel {} central response vs source frequency on max channels {} and \"\n                \"selected baseline {} / {} to test.\".format(test_chan, n_chans, test_baseline, bls_to_test)\n            )\n            plt_title = \"Channel {} @ {:.3f} MHz response @ 80%\".format(test_chan, expected_fc / 1e6)\n\n            aqf_plot_and_save(\n                central_chan_test_freqs,\n                plot_data_central,\n                df,\n                expected_fc,\n                graph_name_central,\n                plt_title,\n                caption=caption,\n            )\n\n            self.Step(\n                \"Test that the peak channeliser response to input frequencies in central 80% of \"\n                \"the test channel frequency band are all in the test channel\"\n            )\n            fault_freqs = []\n            fault_channels = []\n            for i, freq in enumerate(central_chan_test_freqs):\n                max_chan = np.argmax(np.abs(central_chan_responses[i]))\n                if max_chan != test_chan:\n                    fault_freqs.append(freq)\n                    fault_channels.append(max_chan)\n            if fault_freqs:\n                self.Failed(\n                    \"The following input frequencies (first and last): {!r} \"\n                    \"respectively had peak channeliser responses in channels \"\n                    \"{!r}\\n, and not test channel {} as expected.\".format(\n                        fault_freqs[1::-1], set(sorted(fault_channels)), test_chan\n                    )\n                )\n\n                self.logger.error(\n                    \"The following input frequencies: %s respectively had \"\n                    \"peak channeliser responses in channels %s, not \"\n                    \"channel %s as expected.\" % (fault_freqs, set(sorted(fault_channels)), test_chan)\n                )\n\n            Aqf.less(\n                np.max(np.abs(central_chan_responses[:, test_chan])),\n                0.99,\n                \"Confirm that the VACC output is at < 99% of maximum value, if fails \"\n                \"then it is probably over-ranging.\",\n            )\n\n            max_central_chan_response = np.max(10 * np.log10(central_chan_responses[:, test_chan]))\n            min_central_chan_response = np.min(10 * np.log10(central_chan_responses[:, test_chan]))\n            chan_ripple = max_central_chan_response - min_central_chan_response\n            acceptable_ripple_lt = 1.5\n            Aqf.hop(\n                \"80% channel cut-off ripple at {:.2f} dB, should be less than {} dB\".format(\n                    chan_ripple, acceptable_ripple_lt\n                )\n            )\n\n            # Get frequency samples closest channel fc and crossover points\n            co_low_freq = expected_fc - df / 2\n            co_high_freq = expected_fc + df / 2\n\n            def get_close_result(freq):\n                ind = np.argmin(np.abs(actual_test_freqs - freq))\n                source_freq = actual_test_freqs[ind]\n                response = chan_responses[ind, test_chan]\n                return ind, source_freq, response\n\n            fc_ind, fc_src_freq, fc_resp = get_close_result(expected_fc)\n            co_low_ind, co_low_src_freq, co_low_resp = get_close_result(co_low_freq)\n            co_high_ind, co_high_src_freq, co_high_resp = get_close_result(co_high_freq)\n            # [CBF-REQ-0047] CBF channelisation frequency resolution requirement\n            self.Step(\n                \"Confirm that the response at channel-edges are -3 dB \"\n                \"relative to the channel centre at {:.3f} Hz, actual source freq \"\n                \"{:.3f} Hz\".format(expected_fc, fc_src_freq)\n            )\n\n            desired_cutoff_resp = -6  # dB\n            acceptable_co_var = 0.1  # dB, TODO 2015-12-09 NM: thumbsuck number\n            co_mid_rel_resp = 10 * np.log10(fc_resp)\n            co_low_rel_resp = 10 * np.log10(co_low_resp)\n            co_high_rel_resp = 10 * np.log10(co_high_resp)\n\n            co_lo_band_edge_rel_resp = co_mid_rel_resp - co_low_rel_resp\n            co_hi_band_edge_rel_resp = co_mid_rel_resp - co_high_rel_resp\n\n            low_rel_resp_accept = np.abs(desired_cutoff_resp + acceptable_co_var)\n            hi_rel_resp_accept = np.abs(desired_cutoff_resp - acceptable_co_var)\n\n            cutoff_edge = np.abs((co_lo_band_edge_rel_resp + co_hi_band_edge_rel_resp) / 2)\n\n            no_of_responses = 3\n            center_bin = [150, 250, 350]\n            y_axis_limits = (-90, 1)\n            legends = [\n                \"Channel {} / Sample {} \\n@ {:.3f} MHz\".format(\n                    ((test_chan + i) - 1), v, self.cam_sensors.ch_center_freqs[test_chan + i] / 1e6\n                )\n                for i, v in zip(range(no_of_responses), center_bin)\n            ]\n            # center_bin.append('Channel spacing: {:.3f}kHz'.format(856e6 / self.n_chans_selected / 1e3))\n            center_bin.append(\"Channel spacing: {:.3f}kHz\".format(chan_spacing / 1e3))\n\n            channel_response_list = [chan_responses[:, test_chan + i - 1] for i in range(no_of_responses)]\n            np.savetxt(\"Boop.csv\", channel_response_list, delimiter=\",\")\n            plot_title = \"PFB Channel Response\"\n            plot_filename = \"{}/{}_adjacent_channels.png\".format(self.logs_path, self._testMethodName)\n\n            caption = (\n                \"Sample PFB central channel response between channel {} and selected baseline \"\n                \"{}/{},with channelisation spacing of {:.3f}kHz within tolerance of 1%, with \"\n                \"the digitiser simulator configured to generate a continuous wave, with cw scale:\"\n                \" {}, awgn scale: {}, Eq gain: {} and FFT shift: {}\".format(\n                    test_chan, test_baseline, bls_to_test, chan_spacing / 1e3, cw_scale, awgn_scale, gain, fft_shift\n                )\n            )\n\n            aqf_plot_channels(\n                zip(channel_response_list, legends),\n                plot_filename,\n                plot_title,\n                normalise=True,\n                caption=caption,\n                cutoff=-cutoff_edge,\n                vlines=center_bin,\n                xlabel=\"Sample Steps\",\n                ylimits=y_axis_limits,\n            )\n\n            self.Step(\n                \"Measure the power difference between the middle of the center and the middle of \"\n                \"the next adjacent bins and confirm that is > -%sdB\" % cutoff\n            )\n            for bin_num, chan_resp in enumerate(channel_response_list, 1):\n                power_diff = np.max(loggerise(chan_resp)) - cutoff\n                msg = \"Confirm that the power difference (%.2fdB) in bin %s is more than %sdB\" % (\n                    power_diff,\n                    bin_num,\n                    -cutoff,\n                )\n                Aqf.less(power_diff, -cutoff, msg)\n\n            # Plot Central PFB channel response with ylimit 0 to -6dB\n            y_axis_limits = (-7, 1)\n            plot_filename = \"{}/{}_central_adjacent_channels.png\".format(self.logs_path, self._testMethodName)\n            plot_title = \"PFB Central Channel Response\"\n            caption = (\n                \"Sample PFB central channel response between channel {} and selected baseline \"\n                \"{}/{}, with the digitiser simulator configured to generate a continuous wave, \"\n                \"with cw scale: {}, awgn scale: {}, Eq gain: {} and FFT shift: {}\".format(\n                    test_chan, test_baseline, bls_to_test, cw_scale, awgn_scale, gain, fft_shift\n                )\n            )\n\n            aqf_plot_channels(\n                zip(channel_response_list, legends),\n                plot_filename,\n                plot_title,\n                normalise=True,\n                caption=caption,\n                cutoff=-1.5,\n                xlabel=\"Sample Steps\",\n                ylimits=y_axis_limits,\n            )\n\n            Aqf.is_true(\n                low_rel_resp_accept <= co_lo_band_edge_rel_resp <= hi_rel_resp_accept,\n                \"Confirm that the relative response at the low band-edge \"\n                \"(-{co_lo_band_edge_rel_resp} dB @ {co_low_freq} Hz, actual source freq \"\n                \"{co_low_src_freq}) is within the range of {desired_cutoff_resp} +- 1% \"\n                \"relative to channel centre response.\".format(**locals()),\n            )\n\n            Aqf.is_true(\n                low_rel_resp_accept <= co_hi_band_edge_rel_resp <= hi_rel_resp_accept,\n                \"Confirm that the relative response at the high band-edge \"\n                \"(-{co_hi_band_edge_rel_resp} dB @ {co_high_freq} Hz, actual source freq \"\n                \"{co_high_src_freq}) is within the range of {desired_cutoff_resp} +- 1% \"\n                \"relative to channel centre response.\".format(**locals()),\n            )\n\n    def _test_sfdr_peaks(self, required_chan_spacing, no_channels, cutoff=53, plots_debug=False, log_power=True):\n        \"\"\"Test channel spacing and out-of-channel response\n\n        Check that the correct channels have the peak response to each\n        frequency and that no other channels have significant relative power.\n\n        Will loop over all the channels, placing the source frequency as close to the\n        centre frequency of that channel as possible.\n\n        Parameters\n        ----------\n        required_chan_spacing: float\n        no_channels: int\n        cutoff : float\n            Responses in other channels must be at least `-cutoff` dB below the response\n            of the channel with centre frequency corresponding to the source frequency\n\n        \"\"\"\n        # Start a power logger in a thread\n        if log_power:\n            try:\n                power_logger = PowerLogger(self.corr_fix._test_config_file)\n                power_logger.start()\n                power_logger.setName(\"CBF Power Consumption\")\n                self.addCleanup(power_logger.stop)\n            except Exception:\n                errmsg = \"Failed to start power usage logging.\"\n                self.Error(errmsg, exc_info=True)\n\n        # Get baseline 0 data, i.e. auto-corr of m000h\n        test_baseline = 0\n        # Placeholder of actual frequencies that the signal generator produces\n        actual_test_freqs = []\n        # Channel no with max response for each frequency\n        max_channels = []\n        # Channel responses higher than -cutoff dB relative to expected channel\n        extra_peaks = []\n\n        # Checking for all channels.\n        n_chans = self.n_chans_selected\n        msg = (\n            \"This tests confirms that the correct channels have the peak response to each\"\n            \" frequency and that no other channels have significant relative power, while logging \"\n            \"the power usage of the CBF in the background.\"\n        )\n        self.Step(msg)\n        if log_power:\n            self.Progress(\"Logging power usage in the background.\")\n\n        if \"4k\" in self.instrument:\n            # 4K\n            cw_scale = 0.675\n            awgn_scale = 0.05\n            gain = \"11+0j\"\n            fft_shift = 8191\n        else:\n            # 32K\n            cw_scale = 0.375\n            awgn_scale = 0.085\n            gain = \"11+0j\"\n            fft_shift = 32767\n\n        self.Step(\n            \"Digitiser simulator configured to generate a continuous wave, \"\n            \"with cw scale: {}, awgn scale: {}, eq gain: {}, fft shift: {}\".format(\n                cw_scale, awgn_scale, gain, fft_shift\n            )\n        )\n\n        dsim_set_success = set_input_levels(\n            self,\n            awgn_scale=awgn_scale,\n            cw_scale=cw_scale,\n            freq=self.cam_sensors.get_value(\"bandwidth\") / 2.0,\n            fft_shift=fft_shift,\n            gain=gain,\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        self.Step(\n            \"Capture an initial correlator SPEAD accumulation, determine the \"\n            \"number of frequency channels.\")\n        try:\n            initial_dump = self.receiver.get_clean_dump()\n            self.assertIsInstance(initial_dump, dict)\n        except AssertionError:\n            self.Error(\"Could not retrieve clean SPEAD accumulation: Queue is Empty.\", exc_info=True)\n        else:\n            # Aqf.equals(np.shape(initial_dump['xeng_raw'])[0], no_channels,\n            #           'Captured an initial correlator SPEAD accumulation, '\n            #           'determine the number of channels and processing bandwidth: '\n            #           '{}Hz.'.format(self.cam_sensors.get_value('bandwidth')))\n            # chan_spacing = (self.cam_sensors.get_value('bandwidth') / np.shape(initial_dump['xeng_raw'])[0])\n            chan_spacing = self.cam_sensors.get_value(\"bandwidth\") / self.cam_sensors.get_value(\"n_chans\")\n            # [CBF-REQ-0043]\n            calc_channel = (required_chan_spacing / 2) <= chan_spacing <= required_chan_spacing\n            self.Step(\"Confirm that the number of calculated channel frequency step is within requirement.\")\n            msg = (\"Confirm that the calculated channel frequency step size is between {} and \"\n                   \"{} Hz\".format(required_chan_spacing / 2, required_chan_spacing))\n            Aqf.is_true(calc_channel, msg)\n\n        self.Step(\n            \"Sweep a digitiser simulator tone over the all channels that fall within the \"\n            \"complete L-band.\")\n        channel_response_lst = []\n        print_counts = 4\n        start_chan = 1  # skip DC channel since dsim puts out zeros for freq=0\n        failure_count = 0\n        # if self.n_chans_selected != self.cam_sensors.get_value('n_chans'):\n        #    _msg = 'Due to system performance the test will sweep a limited number (ie %s) of channels' % (\n        #        self.n_chans_selected)\n        #    self.Note(_msg)\n        #    channel_freqs = self.cam_sensors.ch_center_freqs[start_chan:self.n_chans_selected]\n        # else:\n        channel_freqs = self.cam_sensors.ch_center_freqs[start_chan:no_channels]\n\n        for channel, channel_f0 in enumerate(channel_freqs, start_chan):\n            if channel < print_counts:\n                self.Progress(\n                    \"Getting channel response for freq %s @ %s: %.3f MHz.\"\n                    % (channel, len(channel_freqs), channel_f0 / 1e6)\n                )\n            elif channel == print_counts:\n                self.Progress(\"...\")\n            elif channel > (len(channel_freqs) - print_counts):\n                self.Progress(\n                    \"Getting channel response for freq %s @ %s: %.3f MHz.\"\n                    % (channel, len(channel_freqs), channel_f0 / 1e6)\n                )\n            else:\n                self.logger.info(\n                    \"Getting channel response for freq %s @ %s: %s MHz.\"\n                    % (channel, len(channel_freqs), channel_f0 / 1e6)\n                )\n\n            self.dhost.sine_sources.sin_0.set(frequency=channel_f0, scale=cw_scale)\n            self.dhost.sine_sources.sin_1.set(frequency=0, scale=0)\n            # self.dhost.sine_sources.sin_corr.set(frequency=0, scale=0)\n\n            this_source_freq = self.dhost.sine_sources.sin_0.frequency\n            actual_test_freqs.append(this_source_freq)\n            try:\n                this_freq_dump = self.receiver.get_clean_dump()\n                self.assertIsInstance(this_freq_dump, dict)\n            except AssertionError:\n                self.Error(\"Could not retrieve clean SPEAD accumulation\", exc_info=True)\n                if failure_count >= 5:\n                    _errmsg = \"Giving up the test, failed to capture accumulations after 5 tries.\"\n                    self.Failed(_errmsg)\n                    failure_count = 0\n                    return False\n                failure_count += 1\n            else:\n                this_freq_data = this_freq_dump[\"xeng_raw\"]\n                this_freq_response = normalised_magnitude(this_freq_data[:, test_baseline, :])\n                # List of channels to be plotted\n                chans_to_plot = (n_chans // 10, n_chans // 2, 9 * n_chans // 10)\n                if channel in chans_to_plot:\n                    channel_response_lst.append(this_freq_response)\n\n                max_chan = np.argmax(this_freq_response)\n                max_channels.append(max_chan)\n                # Find responses that are more than -cutoff relative to max\n                new_cutoff = np.max(loggerise(this_freq_response)) + cutoff\n                unwanted_cutoff = this_freq_response[max_chan] / 10 ** (new_cutoff / 100.0)\n                extra_responses = [\n                    i\n                    for i, resp in enumerate(loggerise(this_freq_response))\n                    if i != max_chan and resp >= unwanted_cutoff\n                ]\n\n                plt_title = \"Frequency response at {}\".format(channel)\n                plt_filename = \"{}/{}_channel_{}_resp.png\".format(self.logs_path,\n                    self._testMethodName, channel)\n                if extra_responses:\n                    msg = \"Weirdly found an extra responses on channel %s\" % (channel)\n                    self.Note(msg)\n                    plt_title = \"Extra responses found around {}\".format(channel)\n                    plt_filename = \"{}_extra_responses.png\".format(self._testMethodName)\n                    plots_debug = True\n\n                extra_peaks.append(extra_responses)\n                if plots_debug:\n                    plots_debug = False\n                    new_cutoff = np.max(loggerise(this_freq_response)) - cutoff\n                    aqf_plot_channels(\n                        this_freq_response, plt_filename, plt_title, log_dynamic_range=90,\n                        hlines=new_cutoff\n                    )\n\n        for channel, channel_resp in zip(chans_to_plot, channel_response_lst):\n            plt_filename = \"{}/{}_channel_{}_resp.png\".format(self.logs_path, self._testMethodName, channel)\n            test_freq_mega = channel_freqs[channel] / 1e6\n            plt_title = \"Frequency response at {} @ {:.3f} MHz\".format(channel, test_freq_mega)\n            caption = (\n                \"An overall frequency response at channel {} @ {:.3f}MHz, \"\n                \"when digitiser simulator is configured to generate a continuous wave, \"\n                \"with cw scale: {}. awgn scale: {}, eq gain: {}, fft shift: {}\".format(\n                    channel, test_freq_mega, cw_scale, awgn_scale, gain, fft_shift\n                )\n            )\n\n            new_cutoff = np.max(loggerise(channel_resp)) - cutoff\n            aqf_plot_channels(\n                channel_resp, plt_filename, plt_title, log_dynamic_range=90, caption=caption, hlines=new_cutoff\n            )\n\n        channel_range = range(start_chan, len(max_channels) + start_chan)\n        self.Step(\"Check that the correct channels have the peak response to each frequency\")\n        msg = (\n            \"Confirm that the correct channel(s) (eg expected channel %s vs actual channel %s) \"\n            \"have the peak response to each frequency\" % (channel_range[1], max_channels[1])\n        )\n\n        if max_channels == channel_range:\n            Aqf.passed(msg)\n        else:\n            Aqf.array_almost_equal(max_channels[1:], channel_range[1:], msg)\n\n        msg = \"Confirm that no other channels response more than -%s dB.\\n\" % cutoff\n        if extra_peaks == [[]] * len(max_channels):\n            Aqf.passed(msg)\n        else:\n            self.logger.debug(\"Expected: %s\\n\\nGot: %s\" % (extra_peaks, [[]] * len(max_channels)))\n            self.Failed(msg)\n        if power_logger:\n            power_logger.stop()\n            start_timestamp = power_logger.start_timestamp\n            power_log_file = power_logger.log_file_name\n            power_logger.join()\n            try:\n                heading(\"CBF Power Consumption\")\n                self._process_power_log(start_timestamp, power_log_file)\n            except Exception:\n                self.Error(\"Failed to read/decode the PDU log.\", exc_info=True)\n\n    def _test_spead_verify(self):\n        \"\"\"This test verifies if a cw tone is only applied to a single input 0,\n            figure out if VACC is rooted by 1\n        \"\"\"\n        heading(\"SPEAD Accumulation Verification\")\n        cw_scale = 0.035\n        freq = 300e6\n        self.Step(\n            \"Digitiser simulator configured to generate cw tone with frequency: {}MHz, \"\n            \"scale:{} on input 0\".format(freq / 1e6, cw_scale)\n        )\n        init_dsim_sources(self.dhost)\n        self.logger.info(\"Set cw tone on pole 0\")\n        self.dhost.sine_sources.sin_0.set(scale=cw_scale, frequency=freq)\n        try:\n            self.Step(\"Capture a correlator SPEAD accumulation and, \")\n            dump = self.receiver.get_clean_dump(discard=50)\n            self.assertIsInstance(dump, dict)\n        except AssertionError:\n            self.Error(\"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\",\n                exc_info=True)\n        else:\n            vacc_offset = get_vacc_offset(dump[\"xeng_raw\"])\n            msg = (\n                \"Confirm that the auto-correlation in baseline 0 contains Non-Zeros, \"\n                \"and baseline 1 is Zeros, when cw tone is only outputted on input 0.\"\n            )\n            Aqf.equals(vacc_offset, 0, msg)\n\n            # TODO Plot baseline\n            self.Step(\"Digitiser simulator reset to Zeros, before next test\")\n            self.Step(\n                \"Digitiser simulator configured to generate cw tone with frequency: {}Mhz, \"\n                \"scale:{} on input 1\".format(freq / 1e6, cw_scale)\n            )\n            init_dsim_sources(self.dhost)\n            self.logger.info(\"Set cw tone on pole 1\")\n            self.dhost.sine_sources.sin_1.set(scale=cw_scale, frequency=freq)\n            self.Step(\"Capture a correlator SPEAD accumulation and,\")\n            dump = self.receiver.get_clean_dump(discard=50)\n            vacc_offset = get_vacc_offset(dump[\"xeng_raw\"])\n            msg = (\n                \"Confirm that the auto-correlation in baseline 1 contains non-Zeros, \"\n                \"and baseline 0 is Zeros, when cw tone is only outputted on input 1.\"\n            )\n            Aqf.equals(vacc_offset, 1, msg)\n            init_dsim_sources(self.dhost)\n\n    def _test_product_baselines(self):\n        heading(\"CBF Baseline Correlation Products\")\n        if \"4k\" in self.instrument:\n            # 4K\n            awgn_scale = 0.0645\n            gain = \"113+0j\"\n            fft_shift = 511\n        else:\n            # 32K\n            awgn_scale = 0.063\n            gain = \"344+0j\"\n            fft_shift = 4095\n\n        self.Step(\n            \"Digitiser simulator configured to generate Gaussian noise, \"\n            \"with scale: {}, eq gain: {}, fft shift: {}\".format(awgn_scale, gain, fft_shift)\n        )\n\n        dsim_set_success = set_input_levels(\n            self,\n            awgn_scale=awgn_scale,\n            freq=self.cam_sensors.get_value(\"bandwidth\") / 2.0,\n            fft_shift=fft_shift,\n            gain=gain,\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        try:\n            self.Step(\"Change CBF input labels and confirm via CAM interface.\")\n            reply_, _ = self.katcp_req.input_labels()\n            assert reply_.reply_ok()\n            ori_source_name = reply_.arguments[1:]\n            self.Progress(\"Original source names: {}\".format(\", \".join(ori_source_name)))\n        except Exception:\n            self.Error(\"Failed to retrieve input labels via CAM interface\", exc_info=True)\n        try:\n            local_src_names = self.cam_sensors.custom_input_labels\n            reply, _ = self.katcp_req.input_labels(*local_src_names)\n            assert reply.reply_ok()\n        except Exception:\n            self.Error(\"Could not retrieve new source names via CAM interface:\\n %s\" % (str(reply)))\n        else:\n            source_names = reply.arguments[1:]\n            msg = \"Source names changed to: {}\".format(\", \".join(source_names))\n            Aqf.passed(msg)\n\n        try:\n            if self.cam_sensors.sensors.n_ants.value > 16:\n                _discards = 60\n            else:\n                _discards = 30\n\n            self.Step(\n                \"Capture an initial correlator SPEAD accumulation while discarding {} \"\n                \"accumulations, and retrieve list of all the correlator input labels via \"\n                \"Cam interface.\".format(_discards)\n            )\n            test_dump = self.receiver.get_clean_dump(discard=_discards)\n            # test_dump = self.receiver.get_clean_dump()\n            self.assertIsInstance(test_dump, dict)\n        except AssertionError:\n            errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n        else:\n            # Get bls ordering from get dump\n            self.Step(\n                \"Get list of all possible baselines (including redundant baselines) present \"\n                \"in the correlator output from SPEAD accumulation\"\n            )\n\n            bls_ordering = eval(self.cam_sensors.get_value(\"bls_ordering\"))\n            input_labels = sorted(self.cam_sensors.input_labels)\n            inputs_to_plot = random.shuffle(input_labels)\n            inputs_to_plot = input_labels[:8]\n            baselines_lookup = get_baselines_lookup(self)\n            present_baselines = sorted(baselines_lookup.keys())\n            possible_baselines = set()\n            [possible_baselines.add((li, lj)) for li in input_labels for lj in input_labels]\n\n            test_bl = sorted(list(possible_baselines))\n            self.Step(\n                \"Confirm that each baseline (or its reverse-order counterpart) is present in \"\n                \"the correlator output\"\n            )\n\n            baseline_is_present = {}\n            for test_bl in possible_baselines:\n                baseline_is_present[test_bl] = test_bl in present_baselines or test_bl[::-1] in present_baselines\n            # Select some baselines to plot\n            plot_baselines = (\n                (input_labels[0], input_labels[0]),\n                (input_labels[0], input_labels[1]),\n                (input_labels[0], input_labels[2]),\n                (input_labels[-1], input_labels[-1]),\n                (input_labels[-1], input_labels[-2]),\n            )\n            plot_baseline_inds = []\n            for bl in plot_baselines:\n                if bl in baselines_lookup:\n                    plot_baseline_inds.append(baselines_lookup[bl])\n                else:\n                    plot_baseline_inds.append(baselines_lookup[bl[::-1]])\n\n            plot_baseline_legends = tuple(\n                \"{bl[0]}, {bl[1]}: {ind}\".format(bl=bl, ind=ind)\n                for bl, ind in zip(plot_baselines, plot_baseline_inds)\n            )\n\n            msg = \"Confirm that all baselines are present in correlator output.\"\n            Aqf.is_true(all(baseline_is_present.values()), msg)\n            test_data = test_dump[\"xeng_raw\"]\n            self.Step(\n                \"Expect all baselines and all channels to be \" \"non-zero with Digitiser Simulator set to output AWGN.\"\n            )\n            msg = \"Confirm that no baselines have all-zero visibilities.\"\n            Aqf.is_false(zero_baselines(test_data), msg)\n            msg = \"Confirm that all baseline visibilities are non-zero across all channels\"\n            try:\n                assert nonzero_baselines(test_data) == all_nonzero_baselines(test_data)\n                Aqf.passed(msg)\n            except AssertionError:\n                self.Failed(msg)\n            self.Step(\"Save initial f-engine equalisations, and ensure they are \" \"restored at the end of the test\")\n\n            initial_equalisations = get_and_restore_initial_eqs(self)\n            # Aqf.passed('Stored initial F-engine equalisations: %s' %\n            #            initial_equalisations)\n            self.Progress(\"Stored original F-engine equalisations.\")\n\n            def set_zero_gains():\n                try:\n                    reply, _ = self.katcp_req.gain_all(0)\n                    assert reply.reply_ok()\n                except Exception:\n                    self.Error(\"Failed to set equalisations on all F-engines\", exc_info=True)\n                else:\n                    Aqf.passed(\"All the inputs equalisations have been set to Zero.\")\n\n            def read_zero_gains():\n                try:\n                    reply, _ = self.katcp_req.gain_all()\n                    assert reply.reply_ok()\n                    eq_values = reply.arguments[-1]\n                except Exception:\n                    self.Failed(\"Failed to retrieve gains/equalisations.\")\n                else:\n                    msg = \"Confirm that all the inputs equalisations have been set to 'Zero'.\"\n                    Aqf.equals(eq_values, \"0j\", msg)\n\n            self.Step(\"Set all inputs gains to 'Zero', and confirm that output product \" \"is all-zero\")\n\n            set_zero_gains()\n            read_zero_gains()\n\n            test_data = self.receiver.get_clean_dump(discard=_discards)\n\n            Aqf.is_false(\n                nonzero_baselines(test_data[\"xeng_raw\"]),\n                \"Confirm that all baseline visibilities are 'Zero' after \" \"{} discards.\\n\".format(\n                    _discards),\n            )\n            # -----------------------------------\n            all_inputs = sorted(set(input_labels))\n            zero_inputs = set(input_labels)\n            nonzero_inputs = set()\n\n            def calc_zero_and_nonzero_baselines(nonzero_inputs):\n                nonzeros = set()\n                zeros = set()\n                for inp_i in all_inputs:\n                    for inp_j in all_inputs:\n                        if (inp_i, inp_j) not in present_baselines:\n                            continue\n                        if inp_i in nonzero_inputs and inp_j in nonzero_inputs:\n                            nonzeros.add((inp_i, inp_j))\n                        else:\n                            zeros.add((inp_i, inp_j))\n                return zeros, nonzeros\n\n            bls_msg = (\n                \"Iterate through input combinations, verifying for each that \"\n                \"the correct output appears in the correct baseline product.\\n\"\n            )\n            self.Step(bls_msg)\n            # dataFrame = pd.DataFrame(index=sorted(input_labels),\n            #                          columns=list(sorted(present_baselines)))\n\n            for count, inp in enumerate(input_labels, start=1):\n                if count > 10:\n                    break\n                old_eq = complex(initial_equalisations[inp])\n                self.Step(\n                    \"Iteratively set gain/equalisation correction on relevant \" \"input %s set to %s.\" % (inp, old_eq)\n                )\n                try:\n                    reply, _ = self.katcp_req.gain(inp, old_eq)\n                    assert reply.reply_ok()\n                except AssertionError:\n                    errmsg = \"%s: Failed to set gain/eq of %s for input %s\" % (str(reply), old_eq, inp)\n                    self.Error(errmsg, exc_info=True)\n                else:\n                    msg = \"Gain/Equalisation correction on input %s set to %s.\" % (inp, old_eq)\n                    Aqf.passed(msg)\n                    zero_inputs.remove(inp)\n                    nonzero_inputs.add(inp)\n                    expected_z_bls, expected_nz_bls = calc_zero_and_nonzero_baselines(nonzero_inputs)\n                    try:\n                        self.Step(\n                            \"Retrieving SPEAD accumulation and confirm if gain/equalisation \"\n                            \"correction has been applied.\"\n                        )\n                        test_dump = self.receiver.get_clean_dump(discard=_discards)\n                        # test_dump = self.receiver.get_clean_dump()\n                        self.assertIsInstance(test_dump, dict)\n                    except Exception:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                    else:\n                        test_data = test_dump[\"xeng_raw\"]\n                        # plot baseline channel response\n                        if inp in inputs_to_plot:\n                            plot_data = [\n                                normalised_magnitude(test_data[:, i, :])\n                                # plot_data = [loggerise(test_data[:, i, :])\n                                for i in plot_baseline_inds\n                            ]\n                            plot_filename = \"{}/{}_channel_resp_{}.png\".format(\n                                self.logs_path, self._testMethodName.replace(\" \", \"_\"), inp\n                            )\n\n                            plot_title = \"Baseline Correlation Products on input: %s\" % inp\n\n                            _caption = (\n                                \"Baseline Correlation Products on input:{} {} with the \"\n                                \"following non-zero inputs:\\n {} \\n \"\n                                \"and\\nzero inputs:\\n {}\".format(\n                                    inp, bls_msg, \", \".join(sorted(nonzero_inputs)),\n                                    \", \".join(sorted(zero_inputs))\n                                )\n                            )\n\n                            aqf_plot_channels(\n                                zip(plot_data, plot_baseline_legends),\n                                plot_filename,\n                                plot_title,\n                                log_dynamic_range=None,\n                                log_normalise_to=1,\n                                caption=_caption,\n                                ylimits=(-0.1, np.max(plot_data) + 0.1),\n                            )\n                        actual_nz_bls_indices = all_nonzero_baselines(test_data)\n                        actual_nz_bls = set([tuple(bls_ordering[i]) for i in actual_nz_bls_indices])\n\n                        actual_z_bls_indices = zero_baselines(test_data)\n                        actual_z_bls = set([tuple(bls_ordering[i]) for i in actual_z_bls_indices])\n                        try:\n                            msg = \"Confirm that the expected baseline visibilities are non-zero with \" \"non-zero inputs\"\n                            self.Step(msg)\n                            msg = msg + \" (%s) and,\" % (sorted(nonzero_inputs))\n                            assert actual_nz_bls == expected_nz_bls\n                            Aqf.passed(msg)\n                        except AssertionError:\n                            self.Failed(msg)\n                        try:\n                            msg = \"Confirm that the expected baselines visibilities are 'Zeros'.\\n\"\n                            self.Step(msg)\n                            assert actual_z_bls == expected_z_bls\n                            Aqf.passed(msg)\n                        except AssertionError:\n                            self.Failed(msg)\n\n                        # Sum of all baselines powers expected to be non zeros\n                        # sum_of_bl_powers = (\n                        #     [normalised_magnitude(test_data[:, expected_bl, :])\n                        #      for expected_bl in [baselines_lookup[expected_nz_bl_ind]\n                        #                          for expected_nz_bl_ind in sorted(expected_nz_bls)]])\n                        test_data = None\n                        # dataFrame.loc[inp][sorted(\n                        #     [i for i in expected_nz_bls])[-1]] = np.sum(sum_of_bl_powers)\n\n            # dataFrame.T.to_csv('{}.csv'.format(self._testMethodName), encoding='utf-8')\n\n    def _test_back2back_consistency(self):\n        \"\"\"\n        This test confirms that back-to-back SPEAD accumulations with same frequency input are\n        identical/bit-perfect.\n        \"\"\"\n        heading(\"Spead Accumulation Back-to-Back Consistency\")\n        self.Step(\"Randomly select a channel to test.\")\n        n_chans = self.cam_sensors.get_value(\"n_chans\")\n        test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n        test_baseline = 0  # auto-corr\n        self.Progress(\"Randomly selected test channel %s and bls %s\" % (test_chan, test_baseline))\n        self.Step(\"Calculate a list of frequencies to test\")\n        requested_test_freqs = self.cam_sensors.calc_freq_samples(test_chan, samples_per_chan=9, chans_around=1)\n        expected_fc = self.cam_sensors.ch_center_freqs[test_chan]\n        source_period_in_samples = self.n_chans_selected * 2\n        cw_scale = 0.675\n        self.dhost.sine_sources.sin_0.set(frequency=expected_fc, scale=cw_scale, repeat_n=source_period_in_samples)\n        self.Step(\n            \"Digitiser simulator configured to generate periodic wave \"\n            \"({:.3f}Hz with FFT-length {}) in order for each FFT to be \"\n            \"identical.\".format(expected_fc / 1e6, source_period_in_samples)\n        )\n\n        try:\n            if self.cam_sensors.sensors.n_ants.value > 16:\n                _discards = 20\n            else:\n                _discards = 10\n            this_freq_dump = self.receiver.get_clean_dump(discard=_discards)\n            assert isinstance(this_freq_dump, dict)\n        except AssertionError:\n            errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n            return False\n        else:\n            self.Step(\n                \"Sweep the digitiser simulator over the selected/requested frequencies \" \"within the complete L-band\"\n            )\n            for i, freq in enumerate(requested_test_freqs):\n                Aqf.hop(\n                    \"Getting channel response for freq {}/{} @ {:.3f} MHz.\".format(\n                        i + 1, len(requested_test_freqs), freq / 1e6\n                    )\n                )\n                self.dhost.sine_sources.sin_0.set(frequency=freq, scale=cw_scale, repeat_n=source_period_in_samples)\n                this_source_freq = self.dhost.sine_sources.sin_0.frequency\n                dumps_data = []\n                chan_responses = []\n                self.Step(\n                    \"Getting SPEAD accumulation and confirm that the difference between\"\n                    \" subsequent accumulation is Zero.\"\n                )\n                for dump_no in xrange(3):\n                    if dump_no == 0:\n                        try:\n                            this_freq_dump = self.receiver.get_clean_dump(discard=_discards)\n                            assert isinstance(this_freq_dump, dict)\n                        except AssertionError:\n                            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                            self.Error(errmsg, exc_info=True)\n                            return False\n                        else:\n                            initial_max_freq = np.max(this_freq_dump[\"xeng_raw\"])\n                    else:\n                        try:\n                            this_freq_dump = self.receiver.get_clean_dump(discard=_discards)\n                            assert isinstance(this_freq_dump, dict)\n                        except AssertionError:\n                            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                            self.Error(errmsg, exc_info=True)\n\n                    try:\n                        this_freq_data = this_freq_dump[\"xeng_raw\"]\n                        assert isinstance(this_freq_data, np.ndarray)\n                    except AssertionError:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                        return False\n                    dumps_data.append(this_freq_data)\n                    this_freq_response = normalised_magnitude(this_freq_data[:, test_baseline, :])\n                    chan_responses.append(this_freq_response)\n\n                # Maximum difference between the initial max frequency and the last max freq\n                dumps_comp = np.max(dumps_data[-1]) - initial_max_freq\n                msg = (\n                    \"Confirm that the maximum difference between the subsequent SPEAD accumulations\"\n                    \" with the same frequency input ({}Hz) is 'Zero' on baseline {}.\".format(\n                        this_source_freq, test_baseline\n                    )\n                )\n\n                if not Aqf.equals(dumps_comp, 0, msg):\n                    legends = [\"dump #{}\".format(x) for x in xrange(len(chan_responses))]\n                    plot_filename = \"{}/{}_chan_resp_{}.png\".format(self.logs_path, self._testMethodName, i + 1)\n                    plot_title = \"Frequency Response {} @ {:.3f}MHz\".format(test_chan, this_source_freq / 1e6)\n                    caption = (\n                        \"Comparison of back-to-back SPEAD accumulations with digitiser simulator \"\n                        \"configured to generate periodic wave ({:.3f}Hz with FFT-length {}) \"\n                        \"in order for each FFT to be identical\".format(this_source_freq, source_period_in_samples)\n                    )\n                    aqf_plot_channels(\n                        zip(chan_responses, legends),\n                        plot_filename,\n                        plot_title,\n                        log_dynamic_range=90,\n                        log_normalise_to=1,\n                        normalise=False,\n                        caption=caption,\n                    )\n\n    def _test_freq_scan_consistency(self, threshold=1e-1):\n        \"\"\"This test confirms if the identical frequency scans produce equal results.\"\"\"\n        heading(\"Spead Accumulation Frequency Consistency\")\n        self.Step(\"Randomly select a channel to test.\")\n        n_chans = self.cam_sensors.get_value(\"n_chans\")\n        test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n        expected_fc = self.cam_sensors.ch_center_freqs[test_chan]\n        self.Step(\n            \"Randomly selected Frequency channel {} @ {:.3f}MHz for testing, and calculate a \"\n            \"list of frequencies to test\".format(test_chan, expected_fc / 1e6)\n        )\n        requested_test_freqs = self.cam_sensors.calc_freq_samples(test_chan, samples_per_chan=3, chans_around=1)\n        # Get baseline 0 data, i.e. auto-corr of m000h\n        test_baseline = 0\n        chan_responses = []\n        scans = []\n        initial_max_freq_list = []\n        source_period_in_samples = self.n_chans_selected * 2\n\n        try:\n            test_dump = self.receiver.get_clean_dump(discard=50)\n            assert isinstance(test_dump, dict)\n        except Exception:\n            errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n            return\n        else:\n            cw_scale = 0.675\n            self.Step(\"Digitiser simulator configured to generate continuous wave\")\n            self.Step(\n                \"Sweeping the digitiser simulator over the centre frequencies of at \"\n                \"least all channels that fall within the complete L-band: {} Hz\".format(expected_fc)\n            )\n            for scan_i in xrange(3):\n                scan_dumps = []\n                frequencies = []\n                scans.append(scan_dumps)\n                for i, freq in enumerate(requested_test_freqs):\n                    if scan_i == 0:\n                        Aqf.hop(\n                            \"Getting channel response for freq {} @ {}: {} MHz.\".format(\n                                i + 1, len(requested_test_freqs), freq / 1e6\n                            )\n                        )\n                        self.dhost.sine_sources.sin_0.set(\n                            frequency=freq, scale=cw_scale, repeat_n=source_period_in_samples\n                        )\n                        freq_val = self.dhost.sine_sources.sin_0.frequency\n                        try:\n                            # this_freq_dump = self.receiver.get_clean_dump()\n                            this_freq_dump = self.receiver.get_clean_dump(discard=20)\n                            assert isinstance(this_freq_dump, dict)\n                        except Exception:\n                            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                            self.Error(errmsg, exc_info=True)\n                        else:\n                            initial_max_freq = np.max(this_freq_dump[\"xeng_raw\"])\n                            this_freq_data = this_freq_dump[\"xeng_raw\"]\n                            initial_max_freq_list.append(initial_max_freq)\n                    else:\n                        self.dhost.sine_sources.sin_0.set(\n                            frequency=freq, scale=cw_scale, repeat_n=source_period_in_samples\n                        )\n                        freq_val = self.dhost.sine_sources.sin_0.frequency\n                        try:\n                            # this_freq_dump = self.receiver.get_clean_dump()\n                            this_freq_dump = self.receiver.get_clean_dump(discard=20)\n                            assert isinstance(this_freq_dump, dict)\n                        except Exception:\n                            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                            self.Error(errmsg, exc_info=True)\n                        else:\n                            this_freq_data = this_freq_dump[\"xeng_raw\"]\n\n                    this_freq_response = normalised_magnitude(this_freq_data[:, test_baseline, :])\n                    chan_responses.append(this_freq_response)\n                    scan_dumps.append(this_freq_data)\n                    frequencies.append(freq_val)\n\n            for scan_i in xrange(1, len(scans)):\n                for freq_i, freq_x in zip(xrange(len(scans[0])), frequencies):\n                    s0 = scans[0][freq_i]\n                    s1 = scans[scan_i][freq_i]\n                    norm_fac = initial_max_freq_list[freq_i]\n                    # TODO Convert to a less-verbose comparison for Aqf.\n                    # E.g. test all the frequencies and only save the error cases,\n                    # then have a final Aqf-check so that there is only one step\n                    # (not n_chan) in the report.\n                    max_freq_scan = np.max(np.abs(s1 - s0)) / norm_fac\n\n                    msg = (\n                        \"Confirm that identical frequency ({:.3f} MHz) scans between subsequent \"\n                        \"SPEAD accumulations produce equal results.\".format(freq_x / 1e6)\n                    )\n\n                    if not Aqf.less(np.abs(max_freq_scan), np.abs(np.log10(threshold)), msg):\n                        legends = [\"Freq scan #{}\".format(x) for x in xrange(len(chan_responses))]\n                        caption = (\n                            \"A comparison of frequency sweeping from {:.3f}Mhz to {:.3f}Mhz \"\n                            \"scan channelisation and also, {}\".format(\n                                requested_test_freqs[0] / 1e6, requested_test_freqs[-1] / 1e6, expected_fc, msg\n                            )\n                        )\n\n                        aqf_plot_channels(\n                            zip(chan_responses, legends),\n                            plot_filename=\"{}/{}_chan_resp.png\".format(self.logs_path, self._testMethodName),\n                            caption=caption,\n                        )\n\n    def _test_restart_consistency(self, instrument, no_channels):\n        \"\"\"\n        This test confirms that back-to-back SPEAD accumulations with same frequency input are\n        identical/bit-perfect on CBF restart.\n        \"\"\"\n        self.Step(self._testMethodDoc)\n        threshold = 1.0e1  #\n        test_baseline = 0\n        n_chans = self.cam_sensors.get_value(\"n_chans\")\n        test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n        requested_test_freqs = self.cam_sensors.calc_freq_samples(test_chan, samples_per_chan=3, chans_around=1)\n        expected_fc = self.cam_sensors.ch_center_freqs[test_chan]\n        self.Step(\n            \"Sweeping the digitiser simulator over {:.3f}MHz of the channels that \"\n            \"fall within {} complete L-band\".format(np.max(requested_test_freqs) / 1e6, test_chan)\n        )\n\n        if \"4k\" in self.instrument:\n            # 4K\n            cw_scale = 0.675\n            awgn_scale = 0.05\n            gain = \"11+0j\"\n            fft_shift = 8191\n        else:\n            # 32K\n            cw_scale = 0.375\n            awgn_scale = 0.085\n            gain = \"11+0j\"\n            fft_shift = 32767\n\n        self.Step(\n            \"Digitiser simulator configured to generate a continuous wave, \"\n            \"with cw scale: {}, awgn scale: {}, eq gain: {}, fft shift: {}\".format(\n                cw_scale, awgn_scale, gain, fft_shift\n            )\n        )\n        dsim_set_success = set_input_levels(\n            self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=expected_fc, fft_shift=fft_shift, gain=gain\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        try:\n            this_freq_dump = self.receiver.get_clean_dump()\n        except Queue.Empty:\n            errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n        else:\n            # Plot an overall frequency response at the centre frequency just as\n            # a sanity check\n            init_source_freq = normalised_magnitude(this_freq_dump[\"xeng_raw\"][:, test_baseline, :])\n            filename = \"{}/{}_channel_response.png\".format(self.logs_path, self._testMethodName)\n            title = \"Frequency response at {} @ {:.3f} MHz.\\n\".format(test_chan, expected_fc / 1e6)\n            caption = \"An overall frequency response at the centre frequency.\"\n            aqf_plot_channels(init_source_freq, filename, title, caption=caption)\n            restart_retries = 5\n\n            def _restart_instrument(retries=restart_retries):\n                if not self.corr_fix.stop_x_data():\n                    self.Failed(\"Could not stop x data from capturing.\")\n                with ignored(Exception):\n                    # deprogram_hosts(self)\n                    self.Failed(\"Fix deprogram Hosts\")\n\n                corr_init = False\n                _empty = True\n                with ignored(Queue.Empty):\n                    self.receiver.get_clean_dump()\n                    _empty = False\n\n                Aqf.is_true(_empty, \"Confirm that the SPEAD accumulations have stopped being produced.\")\n\n                self.corr_fix.halt_array\n\n                while retries and not corr_init:\n                    self.Step(\"Re-initialising the {} instrument\".format(instrument))\n                    with ignored(Exception):\n                        corr_init = self.set_instrument()\n\n                    retries -= 1\n                    if retries == 0:\n                        errmsg = \"Could not restart the correlator after %s tries.\" % (retries)\n                        self.Error(errmsg, exc_info=True)\n\n                if corr_init.keys()[0] is not True and retries == 0:\n                    msg = \"Could not restart {} after {} tries.\".format(instrument, retries)\n                    Aqf.end(passed=False, message=msg)\n                else:\n                    startx = self.corr_fix.start_x_data\n                    if not startx:\n                        self.Failed(\"Failed to enable/start output product capturing.\")\n                    host = (self.xhosts + self.fhosts)[random.randrange(len(self.xhosts + self.fhosts))]\n                    msg = (\n                        \"Confirm that the instrument is initialised by checking if a \"\n                        \"random host: {} is programmed and running.\".format(host.host)\n                    )\n                    Aqf.is_true(host, msg)\n\n                    try:\n                        self.assertIsInstance(self.receiver, CorrRx)\n                        freq_dump = self.receiver.get_clean_dump()\n                        assert np.shape(freq_dump[\"xeng_raw\"])[0] == self.n_chans_selected\n                    except Queue.Empty:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                        return False\n                    except AssertionError:\n                        errmsg = (\n                            \"Correlator Receiver could not be instantiated or No of channels \"\n                            \"(%s) in the spead data is inconsistent with the no of\"\n                            \" channels (%s) expected\" % (np.shape(freq_dump[\"xeng_raw\"])[0], self.n_chans_selected)\n                        )\n                        self.Error(errmsg, exc_info=True)\n                        return False\n                    else:\n                        msg = (\n                            \"Confirm that the data product has the same number of frequency \"\n                            \"channels {no_channels} corresponding to the {instrument} \"\n                            \"instrument product\".format(**locals())\n                        )\n                        try:\n                            spead_chans = self.receiver.get_clean_dump()\n                        except Queue.Empty:\n                            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                            self.Error(errmsg, exc_info=True)\n                        else:\n                            Aqf.equals(4096, no_channels, msg)\n                            return True\n\n            initial_max_freq_list = []\n            scans = []\n            channel_responses = []\n            for scan_i in xrange(3):\n                if scan_i:\n                    self.Step(\"#{scan_i}: Initialising {instrument} instrument\".format(**locals()))\n                    intrument_success = _restart_instrument()\n                    if not intrument_success:\n                        msg = \"Failed to restart the correlator successfully.\"\n                        self.Failed(msg)\n                        self.corr_fix.halt_array\n                        time.sleep(10)\n                        self.set_instrument()\n                        return False\n\n                scan_dumps = []\n                scans.append(scan_dumps)\n                for i, freq in enumerate(requested_test_freqs):\n                    if scan_i == 0:\n                        self.dhost.sine_sources.sin_0.set(frequency=freq, scale=0.125)\n                        if self.corr_fix.start_x_data:\n                            Aqf.hop(\n                                \"Getting Frequency SPEAD accumulation #{} with Digitiser simulator \"\n                                \"configured to generate cw at {:.3f}MHz\".format(i, freq / 1e6)\n                            )\n                            try:\n                                this_freq_dump = self.receiver.get_clean_dump()\n                            except Queue.Empty:\n                                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                                self.Error(errmsg, exc_info=True)\n                        initial_max_freq = np.max(this_freq_dump[\"xeng_raw\"])\n                        this_freq_data = this_freq_dump[\"xeng_raw\"]\n                        initial_max_freq_list.append(initial_max_freq)\n                        freq_response = normalised_magnitude(this_freq_data[:, test_baseline, :])\n                    else:\n                        msg = (\n                            \"Getting Frequency SPEAD accumulation #{} with digitiser simulator \"\n                            \"configured to generate cw at {:.3f}MHz\".format(i, freq / 1e6)\n                        )\n                        Aqf.hop(msg)\n                        self.dhost.sine_sources.sin_0.set(frequency=freq, scale=0.125)\n                        try:\n                            this_freq_dump = self.receiver.get_clean_dump()\n                        except Queue.Empty:\n                            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                            self.Error(errmsg, exc_info=True)\n                        else:\n                            this_freq_data = this_freq_dump[\"xeng_raw\"]\n                            freq_response = normalised_magnitude(this_freq_data[:, test_baseline, :])\n                    scan_dumps.append(this_freq_data)\n                    channel_responses.append(freq_response)\n\n            normalised_init_freq = np.array(initial_max_freq_list)\n            for comp in xrange(1, len(normalised_init_freq)):\n                v0 = np.array(normalised_init_freq[comp - 1])\n                v1 = np.array(normalised_init_freq[comp])\n\n            correct_init_freq = np.abs(np.max(v0 - v1))\n\n            diff_scans_dumps = []\n            for comparison in xrange(1, len(scans)):\n                s0 = np.array(scans[comparison - 1])\n                s1 = np.array(scans[comparison])\n                diff_scans_dumps.append(np.max(s0 - s1))\n\n            diff_scans_comp = np.max(np.array(diff_scans_dumps) / correct_init_freq)\n\n            msg = (\n                \"Confirm that CBF restart SPEAD accumulations comparison results \"\n                \"with the same frequency input differ by no more than {:.3f}dB \"\n                \"threshold.\".format(threshold)\n            )\n\n            if not Aqf.less(diff_scans_comp, threshold, msg):\n                legends = [\"Channel Response #{}\".format(x) for x in xrange(len(channel_responses))]\n                plot_filename = \"{}/{}_chan_resp.png\".format(self.logs_path, self._testMethodName)\n                caption = \"Confirm that results are consistent on CBF restart\"\n                plot_title = \"CBF restart consistency channel response {}\".format(test_chan)\n                aqf_plot_channels(zip(channel_responses, legends), plot_filename, plot_title, caption=caption)\n\n    def _test_delay_tracking(self):\n        msg = \"CBF Delay and Phase Compensation Functional VR: -- Delay tracking\"\n        heading(msg)\n        setup_data = self._delays_setup()\n        if setup_data:\n            num_int = setup_data[\"num_int\"]\n            int_time = self.cam_sensors.get_value(\"int_time\")\n            # katcp_port = self.cam_sensors.get_value('katcp_port')\n            no_chans = range(self.n_chans_selected)\n            sampling_period = self.cam_sensors.sample_period\n            test_delays = [0, sampling_period, 1.5 * sampling_period, 1.9 * sampling_period]\n            test_delays_ns = map(lambda delay: delay * 1e9, test_delays)\n            # num_inputs = len(self.cam_sensors.input_labels)\n            delays = [0] * setup_data[\"num_inputs\"]\n            self.Step(\"Delays to be set (iteratively) %s for testing purposes\\n\" % (test_delays))\n\n            def get_expected_phases():\n                expected_phases = []\n                for delay in test_delays:\n                    # phases = self.cam_sensors.ch_center_freqs * 2 * np.pi * delay\n                    phases = self.cam_sensors.ch_center_freqs * 2 * np.pi * delay\n                    phases -= np.max(phases) / 2.0\n                    expected_phases.append(phases)\n                return zip(test_delays_ns, expected_phases)\n\n            def get_actual_phases():\n                actual_phases_list = []\n                # chan_responses = []\n                for count, delay in enumerate(test_delays, 1):\n                    delays[setup_data[\"test_source_ind\"]] = delay\n                    delay_coefficients = [\"{},0:0,0\".format(dv) for dv in delays]\n                    try:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        this_freq_dump = self.receiver.get_clean_dump(discard=0)\n                        self.assertIsInstance(this_freq_dump, dict), errmsg\n                        t_apply = this_freq_dump[\"dump_timestamp\"] + (num_int * int_time)\n                        t_apply_readable = datetime.fromtimestamp(t_apply).strftime(\"%H:%M:%S\")\n                        curr_time = time.time()\n                        curr_time_readable = datetime.fromtimestamp(curr_time).strftime(\"%H:%M:%S\")\n                        self.Step(\"Delay #%s will be applied with the following parameters:\" % count)\n                        msg = (\n                            \"On baseline %s and input %s, Current cmc time: %s (%s)\"\n                            \", Current Dump timestamp: %s (%s), \"\n                            \"Delay(s) will be applied @ %s (%s), Delay to be applied: %s\"\n                            % (\n                                setup_data[\"baseline_index\"],\n                                setup_data[\"test_source\"],\n                                curr_time,\n                                curr_time_readable,\n                                this_freq_dump[\"dump_timestamp\"],\n                                this_freq_dump[\"dump_timestamp_readable\"],\n                                t_apply,\n                                t_apply_readable,\n                                delay,\n                            )\n                        )\n                        self.Progress(msg)\n                        self.Step(\n                            \"Execute delays via CAM interface and calculate the amount of time \"\n                            \"it takes to load the delays\"\n                        )\n                        self.logger.info(\"Setting a delay of %s via cam interface\" % delay)\n                        load_strt_time = time.time()\n                        reply, _informs = self.katcp_req.delays(t_apply, *delay_coefficients)\n                        load_done_time = time.time()\n                        formated_reply = str(reply).replace(\"\\_\", \" \")\n                        errmsg = (\n                            \"CAM Reply: %s: Failed to set delays via CAM interface with \"\n                            \"load-time: %s vs Current cmc time: %s\" % (formated_reply, t_apply, time.time())\n                        )\n                        assert reply.reply_ok(), errmsg\n                        cmd_load_time = round(load_done_time - load_strt_time, 3)\n                        self.Step(\"Delay load command took {} seconds\".format(cmd_load_time))\n                        # _give_up = int(num_int * int_time * 3)\n                        # while True:\n                        #    _give_up -= 1\n                        #    try:\n                        #        self.logger.info('Waiting for the delays to be updated on sensors: '\n                        #                    '%s retry' % _give_up)\n                        #        try:\n                        #            reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value()\n                        #        except:\n                        #            reply, informs = self.katcp_req.sensor_value()\n                        #        assert reply.reply_ok()\n                        #    except Exception:\n                        #        self.Error('Weirdly I couldnt get the sensor values', exc_info=True)\n                        #    else:\n                        #        delays_updated = list(set([int(i.arguments[-1]) for i in informs\n                        #                                if '.cd.delay' in i.arguments[2]]))[0]\n                        #        if delays_updated:\n                        #            self.logger.info('%s delay(s) have been successfully set' % delay)\n                        #            msg = ('Delays set successfully via CAM interface: Reply: %s' %\n                        #                    formated_reply)\n                        #            Aqf.passed(msg)\n                        #            break\n                        #    if _give_up == 0:\n                        #        msg = (\"Could not confirm the delays in the time stipulated, exiting\")\n                        #        self.logger.error(msg)\n                        #        self.Failed(msg)\n                        #        break\n                        #    time.sleep(1)\n\n                        # Tested elsewhere:\n                        # cam_max_load_time = setup_data['cam_max_load_time']\n                        # msg = ('Time it took to load delays {}s is less than {}s with an '\n                        #      'integration time of {:.3f}s'\n                        #      .format(cmd_load_time, cam_max_load_time, int_time))\n                        # Aqf.less(cmd_load_time, cam_max_load_time, msg)\n                    except Exception:\n                        self.Error(errmsg, exc_info=True)\n\n                    try:\n                        _num_discards = num_int + 2\n                        self.Step(\n                            \"Getting SPEAD accumulation(while discarding %s dumps) containing \"\n                            \"the change in delay(s) on input: %s baseline: %s.\"\n                            % (_num_discards, setup_data[\"test_source\"], setup_data[\"baseline_index\"])\n                        )\n                        self.logger.info(\"Getting dump...\")\n                        dump = self.receiver.get_clean_dump(discard=_num_discards)\n                        self.logger.info(\"Done...\")\n                        assert isinstance(dump, dict)\n                        self.Progress(\n                            \"Readable time stamp received on SPEAD accumulation: %s \"\n                            \"after %s number of discards \\n\" % (dump[\"dump_timestamp_readable\"], _num_discards)\n                        )\n                    except Exception:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                    else:\n                        # # this_freq_data = this_freq_dump['xeng_raw']\n                        # # this_freq_response = normalised_magnitude(\n                        # #    this_freq_data[:, setup_data['test_source_ind'], :])\n                        # # chan_responses.append(this_freq_response)\n                        data = complexise(dump[\"xeng_raw\"][:, setup_data[\"baseline_index\"], :])\n                        phases = np.angle(data)\n                        # # actual_channel_responses = zip(test_delays, chan_responses)\n                        # # return zip(actual_phases_list, actual_channel_responses)\n                        actual_phases_list.append(phases)\n                return actual_phases_list\n\n            expected_phases = get_expected_phases()\n            actual_phases = get_actual_phases()\n\n            try:\n                if set([float(0)]) in [set(i) for i in actual_phases[1:]] or not actual_phases:\n                    self.Failed(\n                        \"Delays could not be applied at time_apply: {} \"\n                        \"possibly in the past.\\n\".format(setup_data[\"t_apply\"])\n                    )\n                else:\n                    # actual_phases = [phases for phases, response in actual_data]\n                    # actual_response = [response for phases, response in actual_data]\n                    plot_title = \"CBF Delay Compensation\"\n                    caption = (\n                        \"Actual and expected Unwrapped Correlation Phase [Delay tracking].\\n\"\n                        \"Note: Dashed line indicates expected value and solid line \"\n                        \"indicates actual values received from SPEAD accumulation.\"\n                    )\n                    plot_filename = \"{}/{}_test_delay_tracking.png\".format(self.logs_path, self._testMethodName)\n                    plot_units = \"secs\"\n\n                    aqf_plot_phase_results(\n                        no_chans, actual_phases, expected_phases, plot_filename, plot_title, plot_units, caption\n                    )\n\n                    nc_sel = self.n_chans_selected\n                    expected_phases_ = [phase[:nc_sel] for _rads, phase in expected_phases]\n\n                    degree = 1.0\n                    decimal = len(str(degree).split(\".\")[-1])\n                    try:\n                        for i, delay in enumerate(test_delays):\n                            delta_actual = np.max(actual_phases[i]) - np.min(actual_phases[i])\n                            delta_expected = np.max(expected_phases_[i]) - np.min(expected_phases_[i])\n                            abs_diff = np.rad2deg(np.abs(delta_expected - delta_actual))\n                            # abs_diff = np.abs(delta_expected - delta_actual)\n                            msg = (\n                                \"Confirm that if difference expected({:.5f}) \"\n                                \"and actual({:.5f}) phases are equal at delay {:.5f}ns within \"\n                                \"{} degree.\".format(delta_expected, delta_actual, delay * 1e9, degree)\n                            )\n                            Aqf.almost_equals(delta_expected, delta_actual, degree, msg)\n\n                            Aqf.less(\n                                abs_diff,\n                                degree,\n                                \"Confirm that the maximum difference ({:.3f} degree/\"\n                                \" {:.3f} rad) between expected phase and actual phase between \"\n                                \"integrations is less than {} degree.\\n\".format(abs_diff, np.deg2rad(abs_diff), degree),\n                            )\n                            try:\n                                delta_actual_s = delta_actual - (delta_actual % degree)\n                                delta_expected_s = delta_expected - (delta_expected % degree)\n                                np.testing.assert_almost_equal(delta_actual_s, delta_expected_s, decimal=decimal)\n                            except AssertionError:\n                                msg = (\n                                    \"Difference expected({:.5f}) phases\"\n                                    \" and actual({:.5f}) phases are 'Not almost equal' \"\n                                    \"within {} degree when delay of {}ns is applied.\".format(\n                                        delta_expected, delta_actual, degree, delay * 1e9\n                                    )\n                                )\n                                self.Step(msg)\n\n                                caption = (\n                                    \"The figure above shows, The difference between expected({:.5f}) \"\n                                    \"phases and actual({:.5f}) phases are 'Not almost equal' within {} \"\n                                    \"degree when a delay of {:.5f}s is applied. Therefore CBF-REQ-0128 and\"\n                                    \", CBF-REQ-0187 are not verified.\".format(\n                                        delta_expected, delta_actual, degree, delay\n                                    )\n                                )\n\n                                actual_phases_i = (delta_actual, actual_phases[i])\n                                if len(expected_phases[i]) == 2:\n                                    expected_phases_i = (delta_expected, expected_phases[i][-1])\n                                else:\n                                    expected_phases_i = (delta_expected, expected_phases[i])\n                                aqf_plot_phase_results(\n                                    no_chans,\n                                    actual_phases_i,\n                                    expected_phases_i,\n                                    plot_filename=\"{}/{}_{}_delay_tracking.png\".format(\n                                        self.logs_path, self._testMethodName, i\n                                    ),\n                                    plot_title=(\"Delay offset:\\n\" \"Actual vs Expected Phase Response\"),\n                                    plot_units=plot_units,\n                                    caption=caption,\n                                )\n\n                        for delay, count in zip(test_delays, xrange(1, len(expected_phases))):\n                            msg = (\n                                \"Confirm that when a delay of {} clock \"\n                                \"cycle({:.5f} ns) is introduced there is a phase change \"\n                                \"of {:.3f} degrees as expected to within {} degree.\".format(\n                                    (count + 1) * 0.5, delay * 1e9, np.rad2deg(np.pi) * (count + 1) * 0.5, degree\n                                )\n                            )\n                            try:\n                                Aqf.array_abs_error(\n                                    actual_phases[count][5:-5], expected_phases_[count][5:-5], msg, degree\n                                )\n                            except Exception:\n                                Aqf.array_abs_error(\n                                    actual_phases[count][5:-5],\n                                    expected_phases_[count][5 : -5 + len(actual_phases[count])],\n                                    msg,\n                                    degree,\n                                )\n                    except Exception:\n                        self.Error(\"Error occurred, this shouldnt happen\", exc_info=True)\n                        return\n            except Exception:\n                self.Error(\"Error occurred, this shouldnt happen\", exc_info=True)\n                return\n\n    def _test_sensor_values(self):\n        \"\"\"\n        Report sensor values\n        \"\"\"\n        heading(\"Monitor Sensors: Report Sensor Values\")\n\n        def report_sensor_list(self):\n            self.Step(\n                \"Confirm that the number of sensors available on the primary \" \"and sub array interface is consistent.\"\n            )\n            try:\n                reply, informs = self.katcp_req.sensor_list(timeout=60)\n            except BaseException:\n                errmsg = \"CAM interface connection encountered errors.\"\n                self.Error(errmsg, exc_info=True)\n            else:\n                msg = (\n                    \"Confirm that the number of sensors are equal \"\n                    \"to the number of sensors listed on the running instrument.\\n\"\n                )\n                Aqf.equals(int(reply.arguments[-1]), len(informs), msg)\n\n        def report_time_sync(self):\n            self.Step(\"Confirm that the time synchronous is implemented on primary interface\")\n            try:\n                reply, informs = self.corr_fix.rct.req.sensor_value(\"time.synchronised\")\n            except BaseException:\n                self.Failed(\"CBF report time sync could not be retrieved from primary interface.\")\n            else:\n                Aqf.is_true(reply.reply_ok(), \"CBF report time sync implemented in this release.\")\n\n            msg = \"Confirm that the CBF can report time sync status via CAM interface. \"\n            try:\n                reply, informs = self.corr_fix.rct.req.sensor_value(\"time.synchronised\")\n            except BaseException:\n                self.Error(msg, exc_info=True)\n            else:\n                msg = msg + \"CAM Reply: {}\\n\".format(str(informs[0]))\n                if not reply.reply_ok():\n                    self.Failed(msg)\n                Aqf.passed(msg)\n\n        def report_small_buffer(self):\n            self.Step(\"Confirm that the Transient Buffer ready is implemented.\")\n            try:\n                assert self.katcp_req.transient_buffer_trigger.is_active()\n            except Exception:\n                errmsg = \"CBF Transient buffer ready for triggering\" \"'Not' implemented in this release.\\n\"\n                self.Error(errmsg, exc_info=True)\n            else:\n                Aqf.passed(\"CBF Transient buffer ready for triggering\" \" implemented in this release.\\n\")\n\n        def report_primary_sensors(self):\n            self.Step(\"Confirm that all primary sensors are nominal.\")\n            for sensor in self.corr_fix.rct.sensor.values():\n                msg = \"Primary sensor: {}, current status: {}\".format(sensor.name, sensor.get_status())\n                Aqf.equals(sensor.get_status(), \"nominal\", msg)\n\n        # Confirm the CBF replies with \"!sensor-list ok numSensors\"\n        # where numSensors is the number of sensor-list informs sent.\n        report_sensor_list(self)\n        # Request the time synchronisation status using CAM interface\n        report_time_sync(self)\n        # The CBF shall report the following transient search monitoring data\n        report_small_buffer(self)\n        # Check all sensors statuses if they are nominal\n        report_primary_sensors(self)\n\n    def _test_fft_overflow(self):\n        \"\"\"Sensor PFB error\"\"\"\n        heading(\"Systematic Errors Reporting: FFT Overflow\")\n        # TODO MM, Simplify the test\n        ch_list = self.cam_sensors.ch_center_freqs\n        cw_freq = ch_list[int(self.n_chans_selected / 2)]\n\n        if \"4k\" in self.instrument:\n            cw_scale = 0.7\n            awgn_scale = 0.085\n            gain = \"7+0j\"\n            fft_shift = 8191\n        else:\n            # 32K\n            cw_scale = 0.375\n            awgn_scale = 0.085\n            gain = \"11+0j\"\n            fft_shift = 32767\n\n        self.Step(\n            \"Digitiser simulator configured to generate a continuous wave (cwg0), \"\n            \"with cw scale: {}, cw frequency: {}, awgn scale: {}, eq gain: {}, \"\n            \"fft shift: {}\".format(cw_scale, cw_freq, awgn_scale, gain, fft_shift)\n        )\n\n        dsim_set_success = set_input_levels(\n            self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=cw_freq, fft_shift=fft_shift, gain=gain\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n        try:\n            self.Step(\"Get the current FFT Shift before manipulation.\")\n            reply, informs = self.katcp_req.fft_shift()\n            assert reply.reply_ok()\n            fft_shift = int(reply.arguments[-1])\n            self.Progress(\"Current system FFT Shift: %s\" % fft_shift)\n        except Exception:\n            self.Error(\"Could not get the F-Engine FFT Shift value\", exc_info=True)\n            return\n\n        try:\n            self.Step(\"Confirm all F-engines do not contain PFB errors/warnings\")\n            for i in range(3):\n                try:\n                    reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value(timeout=60)\n                except BaseException:\n                    reply, informs = self.katcp_req.sensor_value(timeout=60)\n                assert reply.reply_ok()\n        except Exception:\n            msg = \"Failed to retrieve sensor values via CAM interface\"\n            self.Error(msg, exc_info=True)\n            return\n        else:\n            pfb_status = list(set([i.arguments[-2] for i in informs if \"pfb.or0-err-cnt\" in i.arguments[2]]))[0]\n            Aqf.equals(pfb_status, \"nominal\", \"Confirm that all F-Engines report nominal PFB status\")\n\n        try:\n            self.Step(\"Set an FFT shift of 0 on all f-engines, and confirm if system integrity is affected\")\n            reply, informs = self.katcp_req.fft_shift(0)\n            assert reply.reply_ok()\n        except AssertionError:\n            msg = \"Could not set FFT shift for all F-Engine hosts\"\n            self.Error(msg, exc_info=True)\n            return\n\n        try:\n            msg = \"Waiting for sensors to trigger.\"\n            Aqf.wait(60, msg)\n\n            self.Step(\"Check if all F-engines contain(s) PFB errors/warnings\")\n            for i in range(3):\n                try:\n                    reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value()\n                except BaseException:\n                    reply, informs = self.katcp_req.sensor_value()\n                assert reply.reply_ok()\n        except Exception:\n            msg = \"Failed to retrieve sensor values via CAM interface\"\n            self.Error(msg, exc_info=True)\n            return\n        else:\n            pfb_status = list(set(\n                [i.arguments[-2] for i in informs if \"pfb.or0-err-cnt\" in i.arguments[2]]\n                ))[0]\n            Aqf.equals(pfb_status, \"warn\", \"Confirm that all F-Engines report warnings/errors PFB status\")\n\n        try:\n            self.Step(\"Restore original FFT Shift values\")\n            reply, informs = self.katcp_req.fft_shift(fft_shift)\n            assert reply.reply_ok()\n            Aqf.passed(\"FFT Shift: %s restored.\" % fft_shift)\n        except Exception:\n            self.Error(\"Could not set the F-Engine FFT Shift value\", exc_info=True)\n            return\n\n    def _test_memory_error(self):\n        pass\n\n    def _test_network_link_error(self):\n        heading(\"Fault Detection: Network Link Errors\")\n\n        def int2ip(n):\n            return socket.inet_ntoa(struct.pack(\"!I\", n))\n\n        def ip2int(ipstr):\n            return struct.unpack(\"!I\", socket.inet_aton(ipstr))[0]\n\n        def get_spead_data():\n            try:\n                self.receiver.get_clean_dump()\n            except Queue.Empty:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Error(errmsg, exc_info=True)\n            else:\n                msg = (\n                    \"Confirm that the SPEAD accumulation is being produced by \"\n                    \"instrument but not verified.\\n\")\n                Aqf.passed(msg)\n\n        # Record the current multicast destination of one of the F-engine data\n        # ethernet ports,\n        def get_host_ip(host):\n            try:\n                int_ip = host.registers.iptx_base.read()[\"data\"].get(\"reg\")\n                assert isinstance(int_ip, int)\n                return int2ip(int_ip)\n            except BaseException:\n                self.Failed(\"Failed to retrieve multicast destination from %s\".format(\n                    host.host.upper()))\n                return\n\n        def get_lru_status(self, host):\n\n            if host in self.fhosts:\n                engine_type = \"feng\"\n            else:\n                engine_type = \"xeng\"\n\n            try:\n                try:\n                    reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value(\n                        \"%s-%s-lru-ok\".format(host.host, engine_type)\n                    )\n                except BaseException:\n                    reply, informs = self.katcp_req.sensor_value(\"%s-%s-lru-ok\".format(host.host,\n                        engine_type))\n            except BaseException:\n                self.Failed(\"Could not get sensor attributes on %s\".format(host.host))\n            else:\n                if reply.reply_ok() and (int(informs[0].arguments[-1]) == 1):\n                    return 1\n                elif reply.reply_ok() and (int(informs[0].arguments[-1]) == 0):\n                    return 0\n                else:\n                    return False\n\n        # configure the same port multicast destination to an unused address,\n        # effectively dropping that data.\n\n        def write_new_ip(host, ip_new, ip_old):\n            try:\n                ip_new = ip2int(ip_new)\n                host.registers.iptx_base.write(**{\"reg\": int(ip_new)})\n                changed_ip = host.registers.iptx_base.read()[\"data\"].get(\"reg\")\n                assert isinstance(changed_ip, int)\n                changed_ip = int2ip(changed_ip)\n            except BaseException:\n                self.Failed(\"Failed to write new multicast destination on %s\" % host.host)\n            else:\n                Aqf.passed(\n                    \"Confirm that the multicast destination address for %s has been changed \"\n                    \"from %s to %s.\" % (host.host, ip_old, changed_ip)\n                )\n\n        def report_lru_status(self, host, get_lru_status):\n            Aqf.wait(30, \"Wait until the sensors have been updated with new changes\")\n            if get_lru_status(self, host) == 1:\n                Aqf.passed(\n                    \"Confirm that the X-engine %s LRU sensor is OKAY and \"\n                    \"that the X-eng is receiving feasible data.\" % (host.host)\n                )\n            elif get_lru_status(self, host) == 0:\n                Aqf.passed(\n                    \"Confirm that the X-engine %s LRU sensor is reporting a \"\n                    \"failure and that the X-eng is not receiving feasible \"\n                    \"data.\" % (host.host)\n                )\n            else:\n                self.Failed(\"Failed to read %s sensor\" % (host.host))\n\n        fhost = self.fhosts[random.randrange(len(self.fhosts))]\n        # xhost = self.xhosts[random.randrange(len(self.xhosts))]\n        ip_new = \"239.101.2.250\"\n\n        self.Step(\n            \"Randomly selected %s host that is being used to produce the test \"\n            \"data product on which to trigger the link error.\" % (fhost.host)\n        )\n        current_ip = get_host_ip(fhost)\n        if not current_ip:\n            self.Failed(\"Failed to retrieve multicast destination address of %s\" % fhost.host)\n        elif current_ip != ip_new:\n            Aqf.passed(\"Current multicast destination address for %s: %s.\" % (fhost.host,\n                current_ip))\n        else:\n            self.Failed(\"Multicast destination address of %s\" % (fhost.host))\n\n        self.Note(\"Debug code\")\n        # report_lru_status(self, xhost, get_lru_status)\n        # get_spead_data(self)\n\n        # write_new_ip(fhost, ip_new, current_ip)\n        # time.sleep(30 / 2)\n        # report_lru_status(self, xhost, get_lru_status)\n        # get_spead_data(self)\n\n        # self.Step('Restoring the multicast destination from %s to the original %s' % (\n        #     human_readable_ip(ip_new), human_readable_ip(current_ip)))\n\n        # write_new_ip(fhost, current_ip, ip_new, get_host_ip, human_readable_ip)\n        # report_lru_status(self, xhost, get_lru_status)\n        # get_spead_data(self)\n        #\n\n    def _test_host_sensors_status(self):\n        heading(\"Monitor Sensors: Processing Node's Sensor Status\")\n\n        self.Step(\n            \"This test confirms that each processing node's sensor (Temp, Voltage, Current, \"\n            \"Fan) has not FAILED, Reports only errors.\"\n        )\n        try:\n            for i in range(2):\n                try:\n                    reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value()\n                except BaseException:\n                    reply, informs = self.katcp_req.sensor_value()\n                assert reply.reply_ok()\n        except AssertionError:\n            errmsg = \"Failed to retrieve sensors via CAM interface\"\n            self.Error(errmsg, exc_info=True)\n            return\n        else:\n            for i in informs:\n                if i.arguments[2].startswith(\"xhost\") or i.arguments[2].startswith(\"fhost\"):\n                    if i.arguments[-2].lower() != \"nominal\":\n                        self.Note(\" contains a \".join(i.arguments[2:-1]))\n\n    def _test_vacc(self, test_chan, chan_index=None, acc_time=0.998):\n        \"\"\"Test vector accumulator\"\"\"\n        # Choose a test frequency around the centre of the band.\n        test_freq = self.cam_sensors.get_value(\"bandwidth\") / 2.0\n\n        test_input = self.cam_sensors.input_labels[0]\n        eq_scaling = 30\n        acc_times = [acc_time / 2, acc_time]\n        # acc_times = [acc_time/2, acc_time, acc_time*2]\n        n_chans = self.cam_sensors.get_value(\"n_chans\")\n        try:\n            internal_accumulations = int(self.cam_sensors.get_value(\"xeng_acc_len\"))\n        except Exception:\n            errmsg = \"Failed to retrieve X-engine accumulation length: %s.\" % str(e)\n            self.Error(errmsg, exc_info=True)\n        try:\n            initial_dump = self.receiver.get_clean_dump()\n            assert isinstance(initial_dump, dict)\n        except Exception:\n            errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n            return\n\n        delta_acc_t = self.cam_sensors.fft_period * internal_accumulations\n        test_acc_lens = [np.ceil(t / delta_acc_t) for t in acc_times]\n        test_freq_channel = abs(\n            np.argmin(np.abs(self.cam_sensors.ch_center_freqs[:chan_index] - test_freq)) - test_chan\n        )\n        self.Step(\"Selected test input {} and test frequency channel {}\".format(test_input, test_freq_channel))\n        eqs = np.zeros(n_chans, dtype=np.complex)\n        eqs[test_freq_channel] = eq_scaling\n        get_and_restore_initial_eqs(self)\n        try:\n            reply, _informs = self.katcp_req.gain(test_input, *list(eqs))\n            assert reply.reply_ok()\n            Aqf.hop(\"Gain successfully set on input %s via CAM interface.\" % test_input)\n        except Exception:\n            errmsg = \"Gains/Eq could not be set on input %s via CAM interface\" % test_input\n            self.Error(errmsg, exc_info=True)\n\n        self.Step(\n            \"Configured Digitiser simulator output(cw0 @ {:.3f}MHz) to be periodic in \"\n            \"FFT-length: {} in order for each FFT to be identical\".format(test_freq / 1e6, n_chans * 2)\n        )\n\n        cw_scale = 0.125\n        # The re-quantiser outputs signed int (8bit), but the snapshot code\n        # normalises it to floats between -1:1. Since we want to calculate the\n        # output of the vacc which sums integers, denormalise the snapshot\n        # output back to ints.\n        # q_denorm = 128\n        # quantiser_spectrum = get_quant_snapshot(self, test_input) * q_denorm\n        try:\n            # Make dsim output periodic in FFT-length so that each FFT is identical\n            self.dhost.sine_sources.sin_0.set(frequency=test_freq, scale=cw_scale, repeat_n=n_chans * 2)\n            self.dhost.sine_sources.sin_1.set(frequency=test_freq, scale=cw_scale, repeat_n=n_chans * 2)\n            assert self.dhost.sine_sources.sin_0.repeat == n_chans * 2\n        except AssertionError:\n            errmsg = \"Failed to make the DEng output periodic in FFT-length so that each FFT is identical\"\n            self.Error(errmsg, exc_info=True)\n        try:\n            reply, informs = self.katcp_req.quantiser_snapshot(test_input)\n            assert reply.reply_ok()\n            informs = informs[0]\n        except Exception:\n            errmsg = (\n                \"Failed to retrieve quantiser snapshot of input %s via \"\n                \"CAM Interface: \\nReply %s\" % (test_input, str(reply).replace(\"_\", \" \"),))\n            self.Error(errmsg, exc_info=True)\n            return\n        else:\n            quantiser_spectrum = np.array(eval(informs.arguments[-1]))\n            if chan_index:\n                quantiser_spectrum = quantiser_spectrum[:chan_index]\n            # Check that the spectrum is not zero in the test channel\n            # Aqf.is_true(quantiser_spectrum[test_freq_channel] != 0,\n            # 'Check that the spectrum is not zero in the test channel')\n            # Check that the spectrum is zero except in the test channel\n            Aqf.is_true(\n                np.all(quantiser_spectrum[0:test_freq_channel] == 0),\n                (\"Confirm that the spectrum is zero except in the test channel:\"\n                 \" [0:test_freq_channel]\"),\n            )\n            Aqf.is_true(\n                np.all(quantiser_spectrum[test_freq_channel + 1 :] == 0),\n                (\"Confirm that the spectrum is zero except in the test channel:\"\n                 \" [test_freq_channel+1:]\"),\n            )\n            self.Step(\n                \"FFT Window [{} samples] = {:.3f} micro seconds, Internal Accumulations = {}, \"\n                \"One VACC accumulation = {}s\".format(\n                    n_chans * 2, self.cam_sensors.fft_period * 1e6, internal_accumulations, delta_acc_t\n                )\n            )\n\n            chan_response = []\n            for vacc_accumulations, acc_time in zip(test_acc_lens, acc_times):\n                try:\n                    reply = self.katcp_req.accumulation_length(acc_time, timeout=60)\n                    assert reply.succeeded\n                except Exception:\n                    self.Failed(\n                        \"Failed to set accumulation length of {} after maximum vacc \"\n                        \"sync attempts.\".format(vacc_accumulations)\n                    )\n                else:\n                    internal_acc = 2 * internal_accumulations * n_chans\n                    accum_len = int(np.ceil((acc_time * self.cam_sensors.get_value(\"sample\")) / internal_acc))\n                    Aqf.almost_equals(\n                        vacc_accumulations,\n                        accum_len,\n                        1,\n                        \"Confirm that vacc length was set successfully with\"\n                        \" {}, which equates to an accumulation time of {:.6f}s\".format(\n                            vacc_accumulations, vacc_accumulations * delta_acc_t\n                        ),\n                    )\n                    no_accs = internal_accumulations * vacc_accumulations\n                    expected_response = np.abs(quantiser_spectrum) ** 2 * no_accs\n                    try:\n                        dump = self.receiver.get_clean_dump()\n                        assert isinstance(dump, dict)\n                    except Exception:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                    else:\n                        actual_response = complexise(dump[\"xeng_raw\"][:, 0, :])\n                        actual_response_ = loggerise(dump[\"xeng_raw\"][:, 0, :])\n                        actual_response_mag = normalised_magnitude(dump[\"xeng_raw\"][:, 0, :])\n                        chan_response.append(actual_response_mag)\n                        # Check that the accumulator response is equal to the expected response\n                        caption = (\n                            \"Accumulators actual response is equal to the expected response for {} \"\n                            \"accumulation length with a periodic cw tone every {} samples\"\n                            \" at frequency of {:.3f} MHz with scale {}.\".format(\n                                test_acc_lens, n_chans * 2, test_freq / 1e6, cw_scale\n                            )\n                        )\n\n                        plot_filename = \"{}/{}_chan_resp_{}_vacc.png\".format(\n                            self.logs_path, self._testMethodName, int(vacc_accumulations)\n                        )\n                        plot_title = \"Vector Accumulation Length: channel %s\" % test_freq_channel\n                        msg = (\n                            \"Confirm that the accumulator actual response is \"\n                            \"equal to the expected response for {} accumulation length\".format(vacc_accumulations)\n                        )\n\n                        if not Aqf.array_abs_error(\n                            expected_response[:chan_index], actual_response_mag[:chan_index], msg\n                        ):\n                            aqf_plot_channels(\n                                actual_response_mag,\n                                plot_filename,\n                                plot_title,\n                                log_normalise_to=0,\n                                normalise=0,\n                                caption=caption,\n                            )\n\n    def _test_product_switch(self, instrument):\n        self.Step(\n            \"Confirm that the SPEAD accumulations are being produced when Digitiser simulator is \"\n            \"configured to output correlated noise\"\n        )\n        self.dhost.noise_sources.noise_corr.set(scale=0.25)\n        with ignored(Queue.Empty):\n            self.receiver.get_clean_dump()\n\n        self.Step(\"Capture stopped, deprogramming hosts by halting the katcp connection.\")\n        self.corr_fix.stop_x_data()\n        self.corr_fix.halt_array\n\n        no_channels = self.n_chans_selected\n        self.Step(\"Re-initialising {instrument} instrument\".format(**locals()))\n        corr_init = False\n        retries = 5\n        start_time = time.time()\n        self.Step(\"Correlator initialisation timer-started: %s\" % start_time)\n        while retries and not corr_init:\n            try:\n                self.set_instrument()\n                self.corr_fix.start_x_data\n                corr_init = True\n                retries -= 1\n                if corr_init:\n                    end_time = time.time()\n                    msg = \"Correlator initialisation (%s) timer end: %s\" % (instrument, end_time)\n                    self.Step(msg)\n                    self.logger.info(msg + \" within %s retries\" % (retries))\n            except BaseException:\n                retries -= 1\n                if retries == 0:\n                    errmsg = \"Could not restart the correlator after %s tries.\" % (retries)\n                    self.Error(errmsg, exc_info=True)\n\n        if corr_init:\n            host = self.xhosts[random.randrange(len(self.xhosts))]\n            Aqf.is_true(\n                host.is_running(),\n                \"Confirm that the instrument is initialised by checking if \" \"%s is programmed.\" % host.host,\n            )\n            self.set_instrument()\n            try:\n                Aqf.hop(\n                    \"Capturing SPEAD Accumulation after re-initialisation to confirm \"\n                    \"that the instrument activated is valid.\"\n                )\n                self.assertIsInstance(self.receiver, CorrRx)\n                re_dump = self.receiver.get_clean_dump()\n            except Queue.Empty:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Error(errmsg, exc_info=True)\n            except AttributeError:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Receiver could not \" \"be instantiated\"\n                self.Error(errmsg, exc_info=True)\n            else:\n                msg = \"Confirm that the SPEAD accumulations are being produced after instrument \" \"re-initialisation.\"\n                Aqf.is_true(re_dump, msg)\n\n                msg = (\n                    \"Confirm that the data product has the number of frequency channels %s \"\n                    \"corresponding to the %s instrument product\" % (no_channels, instrument)\n                )\n                Aqf.equals(4096, self.cam_sensors.get_value(\"no_chans\"), msg)\n\n                final_time = end_time - start_time - float(self.corr_fix.halt_wait_time)\n                minute = 60.0\n                msg = \"Confirm that instrument switching to %s \" \"time is less than one minute\" % instrument\n                Aqf.less(final_time, minute, msg)\n\n    def _test_delay_rate(self):\n        msg = \"CBF Delay and Phase Compensation Functional VR: -- Delay Rate\"\n        heading(msg)\n        setup_data = self._delays_setup()\n        if setup_data:\n            dump_counts = 5\n            # delay_rate = ((setup_data['sample_period'] / self.cam_sensors.get_value('int_time']) *\n            # np.random.rand() * (dump_counts - 3))\n            # delay_rate = 3.98195128768e-09\n            # _rate = get_delay_bounds(self.corr_fix.correlator).get('min_delay_rate')\n            delay_rate = 0.7 * (self.cam_sensors.sample_period / self.cam_sensors.get_value(\"int_time\"))\n            delay_value = 0\n            fringe_offset = 0\n            fringe_rate = 0\n            load_time = setup_data[\"t_apply\"]\n            delay_rates = [0] * setup_data[\"num_inputs\"]\n            delay_rates[setup_data[\"test_source_ind\"]] = delay_rate\n            delay_coefficients = [\"0,{}:0,0\".format(fr) for fr in delay_rates]\n            self.Step(\"Calculate the parameters to be used for setting Fringe(s)/Delay(s).\")\n            self.Progress(\n                \"Delay Rate: %s, Delay Value: %s, Fringe Offset: %s, Fringe Rate: %s \"\n                % (delay_rate, delay_value, fringe_offset, fringe_rate)\n            )\n\n            try:\n                actual_data = self._get_actual_data(setup_data, dump_counts, delay_coefficients)\n                actual_phases = [phases for phases, response in actual_data]\n            except TypeError:\n                errmsg = \"Could not retrieve actual delay rate data. Aborting test\"\n                self.Error(errmsg, exc_info=True)\n                return\n            else:\n                expected_phases = self._get_expected_data(setup_data, dump_counts, delay_coefficients, actual_phases)\n\n                no_chans = range(self.n_chans_selected)\n                plot_units = \"ns/s\"\n                plot_title = \"Randomly generated delay rate {} {}\".format(delay_rate * 1e9, plot_units)\n                plot_filename = \"{}/{}_delay_rate.png\".format(self.logs_path, self._testMethodName)\n                caption = (\n                    \"Actual vs Expected Unwrapped Correlation Phase [Delay Rate].\\n\"\n                    \"Note: Dashed line indicates expected value and solid line indicates \"\n                    \"actual values received from SPEAD accumulation.\"\n                )\n\n                msg = \"Observe the change in the phase slope, and confirm the phase change is as \" \"expected.\"\n                self.Step(msg)\n                actual_phases_ = np.unwrap(actual_phases)\n                degree = 1.0\n                radians = (degree / 360) * np.pi * 2\n                decimal = len(str(degree).split(\".\")[-1])\n                expected_phases_ = np.unwrap([phase for label, phase in expected_phases])\n                expected_phases_ = expected_phases_[:, 0 : self.n_chans_selected]\n                for i in xrange(0, len(expected_phases_) - 1):\n                    delta_expected = np.abs(np.max(expected_phases_[i + 1] - expected_phases_[i]))\n                    delta_actual = np.abs(np.max(actual_phases_[i + 1] - actual_phases_[i]))\n                    # abs_diff = np.rad2deg(np.abs(delta_expected - delta_actual))\n                    abs_diff = np.abs(delta_expected - delta_actual)\n                    msg = (\n                        \"Confirm that if difference (radians) between expected({:.3f}) \"\n                        \"phases and actual({:.3f}) phases are 'Almost Equal' \"\n                        \"within {} degree when delay rate of {} is applied.\".format(\n                            delta_expected, delta_actual, degree, delay_rate\n                        )\n                    )\n                    Aqf.almost_equals(delta_expected, delta_actual, radians, msg)\n\n                    msg = (\n                        \"Confirm that the maximum difference ({:.3f} \"\n                        \"degree/{:.3f} rad) between expected phase and actual phase \"\n                        \"between integrations is less than {} degree.\".format(np.rad2deg(abs_diff), abs_diff, degree)\n                    )\n                    Aqf.less(abs_diff, radians, msg)\n\n                    try:\n                        abs_error = np.max(actual_phases_[i] - expected_phases_[i])\n                    except ValueError:\n                        abs_error = np.max(actual_phases_[i] - expected_phases_[i][: len(actual_phases_[i])])\n                    msg = (\n                        \"Confirm that the absolute maximum difference ({:.3f} \"\n                        \"degree/{:.3f} rad) between expected phase and actual phase \"\n                        \"is less than {} degree.\".format(np.rad2deg(abs_error), abs_error, degree)\n                    )\n                    Aqf.less(abs_error, radians, msg)\n\n                    try:\n                        delta_actual_s = delta_actual - (delta_actual % degree)\n                        delta_expected_s = delta_expected - (delta_expected % degree)\n                        np.testing.assert_almost_equal(delta_actual_s, delta_expected_s, decimal=decimal)\n\n                    except AssertionError:\n                        self.Step(\n                            \"Difference  between expected({:.3f}) \"\n                            \"phases and actual({:.3f}) phases are \"\n                            \"'Not almost equal' within {} degree when delay rate \"\n                            \"of {} is applied.\".format(delta_expected, delta_actual, degree, delay_rate)\n                        )\n                        caption = (\n                            \"Difference  expected({:.3f}) and actual({:.3f})\"\n                            \" phases are not equal within {} degree when delay rate of {} \"\n                            \"is applied.\".format(delta_expected, delta_actual, degree, delay_rate)\n                        )\n\n                        actual_phases_i = (delta_actual, actual_phases[i])\n                        if len(expected_phases[i]) == 2:\n                            expected_phases_i = (delta_expected, expected_phases[i][-1])\n                        else:\n                            expected_phases_i = (delta_expected, expected_phases[i])\n                        aqf_plot_phase_results(\n                            no_chans,\n                            actual_phases_i,\n                            expected_phases_i,\n                            plot_filename=\"{}/{}_{}_delay_rate.png\".format(self.logs_path, self._testMethodName, i),\n                            plot_title=\"Delay Rate:\\nActual vs Expected Phase Response\",\n                            plot_units=plot_units,\n                            caption=caption,\n                        )\n\n                aqf_plot_phase_results(\n                    no_chans,\n                    actual_phases,\n                    expected_phases,\n                    plot_filename,\n                    plot_title,\n                    plot_units,\n                    caption,\n                    dump_counts,\n                )\n\n    def _test_fringe_rate(self):\n        msg = \"CBF Delay and Phase Compensation Functional VR: -- Fringe rate\"\n        heading(msg)\n        setup_data = self._delays_setup()\n        if setup_data:\n            dump_counts = 5\n            _rand_gen = self.cam_sensors.get_value(\"int_time\") * np.random.rand() * dump_counts\n            fringe_rate = (np.pi / 8.0) / _rand_gen\n            delay_value = 0\n            delay_rate = 0\n            fringe_offset = 0\n            load_time = setup_data[\"t_apply\"]\n            fringe_rates = [0] * setup_data[\"num_inputs\"]\n            fringe_rates[setup_data[\"test_source_ind\"]] = fringe_rate\n            delay_coefficients = [\"0,0:0,{}\".format(fr) for fr in fringe_rates]\n\n            self.Step(\"Calculate the parameters to be used for setting Fringe(s)/Delay(s).\")\n            self.Progress(\n                \"Delay Rate: %s, Delay Value: %s, Fringe Offset: %s, Fringe Rate: %s \"\n                % (delay_rate, delay_value, fringe_offset, fringe_rate)\n            )\n            try:\n                actual_data = self._get_actual_data(setup_data, dump_counts, delay_coefficients)\n                actual_phases = [phases for phases, response in actual_data]\n\n            except TypeError:\n                errmsg = \"Could not retrieve actual delay rate data. Aborting test: Exception: {}\".format(e)\n                self.Error(errmsg, exc_info=True)\n                return\n            else:\n                expected_phases = self._get_expected_data(setup_data, dump_counts, delay_coefficients, actual_phases)\n\n                no_chans = range(self.n_chans_selected)\n                plot_units = \"rads/sec\"\n                plot_title = \"Randomly generated fringe rate {} {}\".format(fringe_rate, plot_units)\n                plot_filename = \"{}/{}_fringe_rate.png\".format(self.logs_path, self._testMethodName)\n                caption = (\n                    \"Actual vs Expected Unwrapped Correlation Phase [Fringe Rate].\\n\"\n                    \"Note: Dashed line indicates expected value and solid line \"\n                    \"indicates actual values received from SPEAD accumulation.\"\n                )\n\n                degree = 1.0\n                radians = (degree / 360) * np.pi * 2\n                decimal = len(str(degree).split(\".\")[-1])\n                actual_phases_ = np.unwrap(actual_phases)\n                expected_phases_ = np.unwrap([phase for label, phase in expected_phases])\n                msg = \"Observe the change in the phase slope, and confirm the phase change is as \" \"expected.\"\n                self.Step(msg)\n                for i in xrange(0, len(expected_phases_) - 1):\n                    try:\n                        delta_expected = np.max(expected_phases_[i + 1] - expected_phases_[i])\n                        delta_actual = np.max(actual_phases_[i + 1] - actual_phases_[i])\n                    except IndexError:\n                        errmsg = \"Failed: Index is out of bounds\"\n                        self.Error(errmsg, exc_info=True)\n                    else:\n                        abs_diff = np.abs(delta_expected - delta_actual)\n                        # abs_diff = np.rad2deg(np.abs(delta_expected - delta_actual))\n                        msg = (\n                            \"Confirm that the difference between expected({:.3f}) \"\n                            \"phases and actual({:.3f}) phases are 'Almost Equal' within \"\n                            \"{} degree when fringe rate of {} is applied.\".format(\n                                delta_expected, delta_actual, degree, fringe_rate\n                            )\n                        )\n                        Aqf.almost_equals(delta_expected, delta_actual, radians, msg)\n\n                        msg = (\n                            \"Confirm that the maximum difference ({:.3f} \"\n                            \"deg / {:.3f} rad) between expected phase and actual phase \"\n                            \"between integrations is less than {} degree\\n\".format(\n                                np.rad2deg(abs_diff), abs_diff, degree\n                            )\n                        )\n                        Aqf.less(abs_diff, radians, msg)\n\n                        try:\n                            delta_actual_s = delta_actual - (delta_actual % degree)\n                            delta_expected_s = delta_expected - (delta_expected % degree)\n                            np.testing.assert_almost_equal(delta_actual_s, delta_expected_s, decimal=decimal)\n                        except AssertionError:\n                            self.Step(\n                                \"Difference between expected({:.3f}) phases and actual({:.3f}) \"\n                                \"phases are 'Not almost equal' within {} degree when fringe rate \"\n                                \"of {} is applied.\".format(delta_expected, delta_actual, degree, fringe_rate)\n                            )\n\n                            caption = (\n                                \"Difference expected({:.3f}) and \"\n                                \"actual({:.3f}) phases are not equal within {} degree when \"\n                                \"fringe rate of {} is applied.\".format(\n                                    delta_expected, delta_actual, degree, fringe_rate\n                                )\n                            )\n\n                            actual_phases_i = (delta_actual, actual_phases[i])\n                            if len(expected_phases[i]) == 2:\n                                expected_phases_i = (delta_expected, expected_phases[i][-1])\n                            else:\n                                expected_phases_i = (delta_expected, expected_phases[i])\n\n                            aqf_plot_phase_results(\n                                no_chans,\n                                actual_phases_i,\n                                expected_phases_i,\n                                plot_filename=\"{}/{}_fringe_rate_{}.png\".format(\n                                    self.logs_path, self._testMethodName, i\n                                ),\n                                plot_title=\"Fringe Rate: Actual vs Expected Phase Response\",\n                                plot_units=plot_units,\n                                caption=caption,\n                            )\n\n                aqf_plot_phase_results(\n                    no_chans, actual_phases, expected_phases, plot_filename, plot_title, plot_units, caption\n                )\n\n    def _test_fringe_offset(self):\n        msg = \"CBF Delay and Phase Compensation Functional VR: Fringe offset\"\n        heading(msg)\n        setup_data = self._delays_setup()\n        if setup_data:\n            dump_counts = 5\n            fringe_offset = (np.pi / 2.0) * np.random.rand() * dump_counts\n            # fringe_offset = 1.22796022444\n            delay_value = 0\n            delay_rate = 0\n            fringe_rate = 0\n            load_time = setup_data[\"t_apply\"]\n            fringe_offsets = [0] * setup_data[\"num_inputs\"]\n            fringe_offsets[setup_data[\"test_source_ind\"]] = fringe_offset\n            delay_coefficients = [\"0,0:{},0\".format(fo) for fo in fringe_offsets]\n\n            self.Step(\"Calculate the parameters to be used for setting Fringe(s)/Delay(s).\")\n            self.Progress(\n                \"Delay Rate: %s, Delay Value: %s, Fringe Offset: %s, Fringe Rate: %s \"\n                % (delay_rate, delay_value, fringe_offset, fringe_rate))\n\n            try:\n                actual_data = self._get_actual_data(setup_data, dump_counts, delay_coefficients)\n                actual_phases = [phases for phases, response in actual_data]\n            except TypeError:\n                errmsg = \"Could not retrieve actual delay rate data. Aborting test\"\n                self.Error(errmsg, exc_info=True)\n                return\n            else:\n                expected_phases = self._get_expected_data(setup_data, dump_counts, delay_coefficients, actual_phases)\n                no_chans = range(self.n_chans_selected)\n                plot_units = \"rads\"\n                plot_title = \"Randomly generated fringe offset {:.3f} {}\".format(fringe_offset, plot_units)\n                plot_filename = \"{}/{}_fringe_offset.png\".format(self.logs_path, self._testMethodName)\n                caption = (\n                    \"Actual vs Expected Unwrapped Correlation Phase [Fringe Offset].\\n\"\n                    \"Note: Dashed line indicates expected value and solid line \"\n                    \"indicates actual values received from SPEAD accumulation. \"\n                    \"Values are rounded off to 3 decimals places\"\n                )\n\n                # Ignoring first dump because the delays might not be set for full\n                # integration.\n                degree = 1.0\n                decimal = len(str(degree).split(\".\")[-1])\n                actual_phases_ = np.unwrap(actual_phases)\n                expected_phases_ = np.unwrap([phase for label, phase in expected_phases])\n                msg = \"Observe the change in the phase slope, and confirm the phase change is as \" \"expected.\"\n                self.Step(msg)\n                for i in xrange(1, len(expected_phases) - 1):\n                    delta_expected = np.abs(np.max(expected_phases_[i]))\n                    delta_actual = np.abs(np.max(actual_phases_[i]))\n                    # abs_diff = np.abs(delta_expected - delta_actual)\n                    abs_diff = np.rad2deg(np.abs(delta_expected - delta_actual))\n                    msg = (\n                        \"Confirm that the difference between expected({:.3f})\"\n                        \" phases and actual({:.3f}) phases are 'Almost Equal' \"\n                        \"within {:.3f} degree when fringe offset of {:.3f} is \"\n                        \"applied.\".format(delta_expected, delta_actual, degree, fringe_offset)\n                    )\n\n                    Aqf.almost_equals(delta_expected, delta_actual, degree, msg)\n\n                    Aqf.less(\n                        abs_diff,\n                        degree,\n                        \"Confirm that the maximum difference({:.3f} \"\n                        \"degrees/{:.3f}rads) between expected phase and actual phase \"\n                        \"between integrations is less than {:.3f} degree\\n\".format(\n                            abs_diff, np.deg2rad(abs_diff), degree\n                        ),\n                    )\n                    try:\n                        delta_actual_s = delta_actual - (delta_actual % degree)\n                        delta_expected_s = delta_expected - (delta_expected % degree)\n                        np.testing.assert_almost_equal(delta_actual_s, delta_expected_s, decimal=decimal)\n\n                    except AssertionError:\n                        self.Step(\n                            \"Difference between expected({:.5f}) phases \"\n                            \"and actual({:.5f}) phases are 'Not almost equal' \"\n                            \"within {} degree when fringe offset of {} is applied.\".format(\n                                delta_expected, delta_actual, degree, fringe_offset\n                            )\n                        )\n\n                        caption = (\n                            \"Difference expected({:.3f}) and actual({:.3f}) \"\n                            \"phases are not equal within {:.3f} degree when fringe offset \"\n                            \"of {:.3f} {} is applied.\".format(\n                                delta_expected, delta_actual, degree, fringe_offset, plot_units\n                            )\n                        )\n\n                        actual_phases_i = (delta_actual, actual_phases[i])\n                        if len(expected_phases[i]) == 2:\n                            expected_phases_i = (delta_expected, expected_phases[i][-1])\n                        else:\n                            expected_phases_i = (delta_expected, expected_phases[i])\n                        aqf_plot_phase_results(\n                            no_chans,\n                            actual_phases_i,\n                            expected_phases_i,\n                            plot_filename=\"{}/{}_{}_fringe_offset.png\".format(self.logs_path,\n                                self._testMethodName, i),\n                            plot_title=(\"Fringe Offset:\\nActual vs Expected Phase Response\"),\n                            plot_units=plot_units,\n                            caption=caption,\n                        )\n\n                aqf_plot_phase_results(\n                    no_chans, actual_phases, expected_phases, plot_filename, plot_title, plot_units, caption\n                )\n\n    def _test_delay_inputs(self):\n        \"\"\"\n        CBF Delay Compensation/LO Fringe stopping polynomial:\n        Delay applied to the correct input\n        \"\"\"\n        msg = \"CBF Delay and Phase Compensation Functional VR: Delays applied to the correct input\"\n        heading(msg)\n        setup_data = self._delays_setup()\n        if setup_data:\n            self.Step(\n                \"The test will sweep through four(4) randomly selected baselines, select and \"\n                \"set a delay value, Confirm if the delay set is as expected.\"\n            )\n            input_labels = self.cam_sensors.input_labels\n            random.shuffle(input_labels)\n            input_labels = input_labels[4:]\n            for delayed_input in input_labels:\n                test_delay_val = random.randrange(self.cam_sensors.sample_period, step=0.83e-10, int=float)\n                # test_delay_val = self.cam_sensors.sample_period  # Pi\n                expected_phases = self.cam_sensors.ch_center_freqs * 2 * np.pi * test_delay_val\n                expected_phases -= np.max(expected_phases) / 2.0\n                self.Step(\"Clear all coarse and fine delays for all inputs before testing input %s.\" % delayed_input)\n                delays_cleared = True  # clear_all_delays(self)\n                if not delays_cleared:\n                    self.Failed(\"Delays were not completely cleared, data might be corrupted.\\n\")\n                else:\n                    Aqf.passed(\"Cleared all previously applied delays prior to test.\\n\")\n                    delays = [0] * setup_data[\"num_inputs\"]\n                    # Get index for input to delay\n                    test_source_idx = input_labels.index(delayed_input)\n                    self.Step(\"Selected input to test: {}\".format(delayed_input))\n                    delays[test_source_idx] = test_delay_val\n                    self.Step(\"Randomly selected delay value ({}) relevant to sampling period\".format(test_delay_val))\n                    delay_coefficients = [\"{},0:0,0\".format(dv) for dv in delays]\n                    int_time = setup_data[\"int_time\"]\n                    num_int = setup_data[\"num_int\"]\n                    try:\n                        this_freq_dump = self.receiver.get_clean_dump()\n                        t_apply = this_freq_dump[\"dump_timestamp\"] + (num_int * int_time)\n                        t_apply_readable = this_freq_dump[\"dump_timestamp_readable\"]\n                        self.Step(\"Delays will be applied with the following parameters:\")\n                        self.Progress(\"Current cmc time: %s (%s)\" % (time.time(), time.strftime(\"%H:%M:%S\")))\n                        self.Progress(\n                            \"Current Dump timestamp: %s (%s)\"\n                            % (this_freq_dump[\"dump_timestamp\"], this_freq_dump[\"dump_timestamp_readable\"])\n                        )\n                        self.Progress(\"Time delays will be applied: %s (%s)\" % (t_apply, t_apply_readable))\n                        self.Progress(\"Delay coefficients: %s\" % delay_coefficients)\n                        reply, _informs = self.katcp_req.delays(t_apply, *delay_coefficients)\n                        assert reply.reply_ok()\n                    except Exception:\n                        errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n                        self.Failed(errmsg)\n                        return\n                    else:\n                        Aqf.is_true(reply.reply_ok(), str(reply).replace(\"\\_\", \" \"))\n                        Aqf.passed(\"Delays where successfully applied on input: {}\".format(delayed_input))\n                    try:\n                        self.Step(\n                            \"Getting SPEAD accumulation (while discarding subsequent dumps) containing \"\n                            \"the change in delay(s) on input: %s.\" % (test_source_idx)\n                        )\n                        dump = self.receiver.get_clean_dump(discard=35)\n                    except Exception:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                    else:\n                        sorted_bls = get_baselines_lookup(self, this_freq_dump, sorted_lookup=True)\n                        degree = 1.0\n                        self.Step(\"Maximum expected delay: %s\" % np.max(expected_phases))\n                        for b_line in sorted_bls:\n                            b_line_val = b_line[1]\n                            b_line_dump = dump[\"xeng_raw\"][:, b_line_val, :]\n                            b_line_phase = np.angle(complexise(b_line_dump))\n                            # np.deg2rad(1) = 0.017 ie error should be withing 2 decimals\n                            b_line_phase_max = round(np.max(b_line_phase), 2)\n                            if (delayed_input in b_line[0]) and b_line[0] != (delayed_input, delayed_input):\n                                msg = \"Confirm that the baseline(s) {} expected delay is within 1 \" \"degree.\".format(\n                                    b_line[0]\n                                )\n                                Aqf.array_abs_error(\n                                    np.abs(b_line_phase[5:-5]), np.abs(expected_phases[5:-5]), msg, degree\n                                )\n                            else:\n                                # TODO Readdress this failure and calculate\n                                if b_line_phase_max != 0.0:\n                                    desc = (\n                                        \"Checking baseline {}, index: {}, phase offset found, \"\n                                        \"maximum error value = {} rads\".format(b_line[0], b_line_val, b_line_phase_max)\n                                    )\n                                    self.Failed(desc)\n\n    def _test_min_max_delays(self):\n        delays_cleared = clear_all_delays(self)\n        setup_data = self._delays_setup()\n\n        num_int = setup_data[\"num_int\"]\n        int_time = self.cam_sensors.get_value(\"int_time\")\n        if setup_data:\n            self.Step(\"Clear all coarse and fine delays for all inputs before test commences.\")\n            if not delays_cleared:\n                self.Failed(\"Delays were not completely cleared, data might be corrupted.\\n\")\n            else:\n                dump_counts = 5\n                delay_bounds = get_delay_bounds(self.correlator)\n                for _name, _values in sorted(delay_bounds.iteritems()):\n                    _new_name = _name.title().replace(\"_\", \" \")\n                    self.Step(\"Calculate the parameters to be used for setting %s.\" % _new_name)\n                    delay_coefficients = 0\n                    dump = self.receiver.get_clean_dump()\n                    t_apply = dump[\"dump_timestamp\"] + num_int * int_time\n                    setup_data[\"t_apply\"] = t_apply\n                    no_inputs = [0] * setup_data[\"num_inputs\"]\n                    input_source = setup_data[\"test_source\"]\n                    no_inputs[setup_data[\"test_source_ind\"]] = _values * dump_counts\n                    if \"delay_value\" in _name:\n                        delay_coefficients = [\"{},0:0,0\".format(dv) for dv in no_inputs]\n                    if \"delay_rate\" in _name:\n                        delay_coefficients = [\"0,{}:0,0\".format(dr) for dr in no_inputs]\n                    if \"phase_offset\" in _name:\n                        delay_coefficients = [\"0,0:{},0\".format(fo) for fo in no_inputs]\n                    else:\n                        delay_coefficients = [\"0,0:0,{}\".format(fr) for fr in no_inputs]\n\n                    self.Progress(\n                        \"%s of %s will be set on input %s. Note: All other parameters \"\n                        \"will be set to zero\" % (_name.title(), _values, input_source)\n                    )\n                    try:\n                        actual_data = self._get_actual_data(setup_data, dump_counts, delay_coefficients)\n                    except TypeError:\n                        self.Error(\"Failed to set the delays/fringes\", exc_info=True)\n                    else:\n                        self.Step(\"Confirm that the %s where successfully set\" % _new_name)\n                        reply, informs = self.katcp_req.delays()\n                        msg = (\n                            \"%s where successfully set via CAM interface.\"\n                            \"\\n\\t\\t\\t    Reply: %s\\n\\n\" % (_new_name, reply,))\n                        Aqf.is_true(reply.reply_ok(), msg)\n\n    def _test_delays_control(self):\n        delays_cleared = clear_all_delays(self)\n        setup_data = self._delays_setup()\n\n        num_int = setup_data[\"num_int\"]\n        int_time = self.cam_sensors.get_value(\"int_time\")\n        self.Step(\"Disable Delays and/or Phases for all inputs.\")\n        if not delays_cleared:\n            self.Failed(\"Delays were not completely cleared, data might be corrupted.\\n\")\n        else:\n            Aqf.passed(\"Confirm that the user can disable Delays and/or Phase changes via CAM interface.\")\n        dump = self.receiver.get_clean_dump()\n        t_apply = dump[\"dump_timestamp\"] + num_int * int_time\n        no_inputs = [0] * setup_data[\"num_inputs\"]\n        input_source = setup_data[\"test_source\"]\n        no_inputs[setup_data[\"test_source_ind\"]] = self.cam_sensors.sample_period * 2\n        delay_coefficients = [\"{},0:0,0\".format(dv) for dv in no_inputs]\n        try:\n            self.Step(\n                \"Request and enable Delays and/or Phases Corrections on input (%s) \"\n                \"via CAM interface.\" % input_source\n            )\n            load_strt_time = time.time()\n            reply_, _informs = self.katcp_req.delays(t_apply, *delay_coefficients, timeout=30)\n            load_done_time = time.time()\n            msg = \"Delay/Fringe(s) set via CAM interface reply : %s\" % str(reply_)\n            assert reply_.reply_ok()\n            cmd_load_time = round(load_done_time - load_strt_time, 3)\n            Aqf.is_true(reply_.reply_ok(), msg)\n            self.Step(\"Fringe/Delay load command took {} seconds\".format(cmd_load_time))\n            # _give_up = int(num_int * int_time * 3)\n            # while True:\n            #    _give_up -= 1\n            #    try:\n            #        self.logger.info('Waiting for the delays to be updated')\n            #        try:\n            #            reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value()\n            #        except:\n            #            reply, informs = self.katcp_req.sensor_value()\n            #        assert reply.reply_ok()\n            #    except Exception:\n            #        self.Error('Weirdly I couldnt get the sensor values', exc_info=True)\n            #    else:\n            #        delays_updated = list(set([int(i.arguments[-1]) for i in informs\n            #                                if '.cd.delay' in i.arguments[2]]))[0]\n            #        if delays_updated:\n            #            self.logger.info('Delays have been successfully set')\n            #            break\n            #    if _give_up == 0:\n            #        self.logger.error(\"Could not confirm the delays in the time stipulated, exiting\")\n            #        break\n            #    time.sleep(1)\n\n        except Exception:\n            errmsg = (\n                \"%s: Failed to set delays via CAM interface with load-time: %s, \"\n                \"Delay coefficients: %s\" % (str(reply), setup_data[\"t_apply\"], delay_coefficients,))\n            self.Error(errmsg, exc_info=True)\n            return\n        else:\n            cam_max_load_time = setup_data[\"cam_max_load_time\"]\n            msg = \"Time it took to load delay/fringe(s) %s is less than %ss\" % (cmd_load_time,\n                cam_max_load_time)\n            Aqf.less(cmd_load_time, cam_max_load_time, msg)\n\n    def _test_report_config(self):\n        \"\"\"CBF Report configuration\"\"\"\n        test_config = self.corr_fix._test_config_file\n\n        def git_revision_short_hash(mod_name=None, dir_name=None):\n            return (\n                subprocess.check_output(\n                    [\"git\", \"--git-dir=%s/.git\" % dir_name, \"--work-tree=%s\" % mod_name,\n                    \"rev-parse\", \"--short\", \"HEAD\"]\n                ).strip()\n                if mod_name and dir_name\n                else None\n            )\n\n        def get_skarab_config(_timeout=30):\n            from casperfpga import utils as fpgautils\n\n            self.Step(\"List of all processing nodes\")\n            self.Progress(\"D-Engine :{}\".format(self.dhost.host))\n            try:\n                fhosts, xhosts = self.fhosts, self.xhosts\n            except AttributeError:\n                fhosts = [self.corr_fix.corr_config[\"fengine\"][\"hosts\"]]\n                xhosts = [self.corr_fix.corr_config[\"xengine\"][\"hosts\"]]\n\n            self.Progress(\"List of F-Engines :{}\".format(\", \".join(fhosts)))\n            self.Progress(\"List of X-Engines :{}\\n\".format(\", \".join(xhosts)))\n            self._hosts = list(\n                np.concatenate(\n                    [i.get(\"hosts\", None).split(\",\")\n                    for i in self.corr_fix.corr_config.values() if i.get(\"hosts\")]\n                )\n            )\n            skarabs = FPGA_Connect(self._hosts)\n            if skarabs:\n                version_info = fpgautils.threaded_fpga_operation(\n                    skarabs,\n                    timeout=_timeout,\n                    target_function=(lambda fpga: fpga.transport.get_skarab_version_info(), [], {}),\n                )\n                # ToDo (MM) Get a list of all skarabs available including ip's and\n                # leaf the host is connected to.\n                # subprocess.check_output(['bash', 'scripts/find-skarabs-arp.sh'])\n                for _host, _versions in version_info.iteritems():\n                    self.Step(\"%s [R3000-0000] Software/Hardware Version Information\" % _host)\n                    self.Progress(\"IP Address: %s\" % (socket.gethostbyname(_host)))\n                    for _name, _version in _versions.iteritems():\n                        try:\n                            assert isinstance(_version, str)\n                            _name = _name.title().replace(\"_\", \" \")\n                            if _name.startswith(\"Microblaze Hardware\"):\n                                self.Progress(\"%s [M1200-0070]: %s\\n\" % (_name, _version))\n                            elif _name.startswith(\"Microblaze Software\"):\n                                self.Progress(\"%s [M1200-0071]: %s\" % (_name, _version))\n                            elif _name.startswith(\"Spartan\"):\n                                self.Progress(\"%s [M1200-0069]: %s\" % (_name, _version))\n                        except BaseException:\n                            pass\n\n        def get_package_versions():\n            corr2_name = corr2.__name__\n            corr2_version = corr2.__version__\n            corr2_pn = \"M1200-0046\"\n            try:\n                assert \"devel\" in corr2_version\n                corr2_version = \"\".join([i for i in corr2_version.split(\".\") if len(i) == 7])\n                corr2_link = \"https://github.com/ska-sa/%s/commit/%s\" % (corr2_name, corr2_version)\n            except Exception:\n                corr2_link = \"Not Version Controlled at this time.\"\n\n            casper_name = casperfpga.__name__\n            casper_version = casperfpga.__version__\n            casper_pn = \"M1200-0055\"\n            try:\n                assert \"dev\" in casper_version\n                casper_version = \"\".join([i for i in casper_version.split(\".\") if len(i) == 7])\n                casper_link = \"https://github.com/ska-sa/%s/commit/%s\" % (casper_name, casper_version)\n            except Exception:\n                casper_link = \"Not Version Controlled at this time.\"\n\n            katcp_name = katcp.__name__\n            katcp_version = katcp.__version__\n            katcp_pn = \"M1200-0053\"\n            try:\n                assert \"dev\" in katcp_version\n                katcp_version = \"\".join([i for i in katcp_version.split(\".\") if len(i) == 7])\n                assert len(katcp_version) == 7\n                katcp_link = \"https://github.com/ska-sa/%s-python/commit/%s\" % (katcp_name, katcp_version)\n            except Exception:\n                katcp_link = \"https://github.com/ska-sa/%s/releases/tag/v%s\" % (katcp_name, katcp_version)\n\n            spead2_name = spead2.__name__\n            spead2_version = spead2.__version__\n            spead2_pn = \"M1200-0056\"\n            try:\n                assert \"dev\" in spead2_version\n                assert len(spead2_version) == 7\n                spead2_version = \"\".join([i for i in spead2_version.split(\".\") if len(i) == 7])\n                spead2_link = \"https://github.com/ska-sa/%s/commit/%s\" % (spead2_name, spead2_version)\n            except Exception:\n                spead2_link = \"https://github.com/ska-sa/%s/releases/tag/v%s\" % (spead2_name, spead2_version)\n\n            try:\n                bitstream_dir = self.corr_fix.configd.get(\"xengine\").get(\"bitstream\")\n                mkat_dir, _ = os.path.split(os.path.split(os.path.dirname(os.path.realpath(bitstream_dir)))[0])\n                _, mkat_name = os.path.split(mkat_dir)\n                assert mkat_name\n                mkat_version = git_revision_short_hash(dir_name=mkat_dir, mod_name=mkat_name)\n                assert len(mkat_version) == 7\n                mkat_link = \"https://github.com/ska-sa/%s/commit/%s\" % (mkat_name, mkat_version)\n            except Exception:\n                mkat_name = \"mkat_fpga\"\n                mkat_link = \"Not Version Controlled at this time.\"\n                mkat_version = \"Not Version Controlled at this time.\"\n\n            try:\n                test_dir, test_name = os.path.split(os.path.dirname(os.path.realpath(__file__)))\n                testing_version = git_revision_short_hash(dir_name=test_dir, mod_name=test_name)\n                assert len(testing_version) == 7\n                testing_link = \"https://github.com/ska-sa/%s/commit/%s\" % (test_name, testing_version)\n            except AssertionError:\n                testing_link = \"Not Version Controlled at this time.\"\n\n            try:\n                with open(\"/etc/cmc.conf\") as f:\n                    cmc_conf = f.readlines()\n                templates_loc = [i.strip().split(\"=\") for i in cmc_conf if i.startswith(\"CORR_TEMPLATE\")][0][-1]\n                # template_name = template_name.replace('_', ' ').title()\n                config_dir = os.path.split(templates_loc)[0]\n                config_dir_name = os.path.split(config_dir)[-1]\n                config_version = git_revision_short_hash(dir_name=config_dir, mod_name=config_dir_name)\n                config_pn = \"M1200-0063\"\n                assert len(config_version) == 7\n                config_link = \"https://github.com/ska-sa/%s/commit/%s\" % (config_dir_name, config_version)\n            except Exception:\n                config_dir_name = \"mkat_config_templates\"\n                config_version = \"Not Version Controlled\"\n                config_link = \"Not Version Controlled\"\n\n            return {\n                corr2_name: [corr2_version, corr2_link, corr2_pn],\n                casper_name: [casper_version, casper_link, casper_pn],\n                katcp_name: [katcp_version, katcp_link, katcp_pn],\n                spead2_name: [spead2_version, spead2_link, spead2_pn],\n                mkat_name: [mkat_version, mkat_link, \"None\"],\n                test_name: [testing_version, testing_link, \"None\"],\n                config_dir_name: [config_version, config_link, \"None\"],\n            }\n\n        def get_gateware_info():\n            try:\n                reply, informs = self.katcp_req.version_list()\n                assert reply.reply_ok()\n            except AssertionError:\n                self.Failed(\"Could not retrieve CBF Gate-ware Version Information\")\n            else:\n                for inform in informs:\n                    if [s for s in inform.arguments if \"xengine-firmware\" in s]:\n                        _hash = inform.arguments[-1].split(\" \")\n                        _hash = \"\".join([i.replace(\"[\", \"\").replace(\"]\", \"\") for i in _hash if 40 < len(i) < 42])\n                        self.Progress(\"%s: %s\" % (inform.arguments[0], _hash))\n                        self.Progress(\"X/B-ENGINE (CBF) : M1200-0067\")\n                    elif [s for s in inform.arguments if \"fengine-firmware\" in s]:\n                        _hash = inform.arguments[-1].split(\" \")\n                        _hash = \"\".join([i.replace(\"[\", \"\").replace(\"]\", \"\") for i in _hash if 40 < len(i) < 42])\n                        self.Progress(\"%s: %s\" % (inform.arguments[0], _hash))\n                        self.Progress(\"F-ENGINE (CBF) : M1200-0064\")\n                    else:\n                        self.Progress(\": \".join(inform.arguments))\n                self.Progress(\"CMC KATCP_C : M1200-0047\")\n                self.Progress(\"CMC CBF SCRIPTS : M1200-0048\")\n                self.Progress(\"CORRELATOR MASTER CONTROLLER (CMC) : M1200-0012\")\n\n        heading(\"CBF CMC Operating System.\")\n        self.Progress(\"CBF OS: %s | CMC OS P/N: M1200-0045\" % \" \".join(os.uname()))\n\n        heading(\"CBF Software Packages Version Information.\")\n        self.Progress(\"CORRELATOR BEAMFORMER GATEWARE (CBF) : M1200-0041\")\n        get_gateware_info()\n\n        heading(\"CBF Git Version Information.\")\n        self.Progress(\"CORRELATOR BEAMFORMER SOFTWARE : M1200-0036\")\n        packages_info = get_package_versions()\n        for name, repo_dir in packages_info.iteritems():\n            try:\n                if name and (len(repo_dir[0]) == 7):\n                    self.Progress(\n                        \"Repo: %s | Part Number: %s | Git Commit: %s | GitHub: %s\"\n                        % (name, repo_dir[2], repo_dir[0], repo_dir[1])\n                    )\n                else:\n                    self.Progress(\"Repo: %s | Git Tag: %s | GitHub: %s\" % (name, repo_dir[0], repo_dir[1]))\n            except Exception:\n                pass\n\n        heading(\"CBF Processing Node Version Information\")\n\n        get_skarab_config()\n\n    def _test_data_product(self, _baseline=False, _tiedarray=False):\n        \"\"\"CBF Imaging Data Product Set\"\"\"\n        # Put some correlated noise on both outputs\n        if \"4k\" in self.instrument:\n            # 4K\n            awgn_scale = 0.0645\n            gain = \"113+0j\"\n            fft_shift = 511\n        else:\n            # 32K\n            awgn_scale = 0.063\n            gain = \"344+0j\"\n            fft_shift = 4095\n\n        self.Step(\"Configure a digitiser simulator to generate correlated noise.\")\n        self.Progress(\n            \"Digitiser simulator configured to generate Gaussian noise with scale: {}, \"\n            \"gain: {} and fft shift: {}.\".format(awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(self, awgn_scale=awgn_scale, fft_shift=fft_shift, gain=gain)\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        if _baseline:\n            self.Step(\"Configure the CBF to generate Baseline-Correlation-Products(If available).\")\n            try:\n                self.Progress(\n                    \"Retrieving initial SPEAD accumulation, in-order to confirm the number of \"\n                    \"channels in the SPEAD data.\"\n                )\n                test_dump = self.receiver.get_clean_dump()\n                assert isinstance(test_dump, dict)\n            except Exception:\n                errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n                self.Error(errmsg, exc_info=True)\n                return\n            else:\n                exp_channels = test_dump[\"xeng_raw\"].shape[0]\n                no_channels = self.cam_sensors.get_value(\"n_chans\")\n                # Get baseline 0 data, i.e. auto-corr of m000h\n                test_baseline = 0\n                test_bls = eval(self.cam_sensors.get_value(\"bls_ordering\"))[test_baseline]\n                Aqf.equals(\n                    exp_channels,\n                    no_channels,\n                    \"Confirm that the baseline-correlation-products has the same number of \"\n                    \"frequency channels ({}) corresponding to the {} \"\n                    \"instrument currently running,\".format(no_channels, self.instrument),\n                )\n                Aqf.passed(\n                    \"and confirm that imaging data product set has been \"\n                    \"implemented for instrument: {}.\".format(self.instrument)\n                )\n\n                response = normalised_magnitude(test_dump[\"xeng_raw\"][:, test_baseline, :])\n                plot_filename = \"{}/{}_channel_response_.png\".format(self.logs_path, self._testMethodName)\n\n                caption = (\n                    \"An overall frequency response at {} baseline, \"\n                    \"when digitiser simulator is configured to generate Gaussian noise, \"\n                    \"with scale: {}, eq gain: {} and fft shift: {}\".format(test_bls, awgn_scale, gain, fft_shift)\n                )\n                aqf_plot_channels(response, plot_filename, log_dynamic_range=90, caption=caption)\n\n        if _tiedarray:\n            try:\n                self.logger.info(\"Checking if Docker is running!!!\")\n                output = subprocess.check_output([\"docker\", \"run\", \"hello-world\"])\n                self.logger.info(output)\n            except subprocess.CalledProcessError:\n                errmsg = \"Cannot connect to the Docker daemon. Is the docker daemon running on this host?\"\n                self.Failed(errmsg)\n                return False\n\n            try:\n                # Set custom source names\n                local_src_names = self.cam_sensors.custom_input_labels\n                reply, informs = self.katcp_req.input_labels(*local_src_names)\n                assert reply.reply_ok()\n                labels = reply.arguments[1:]\n                beams = [\"tied-array-channelised-voltage.0x\", \"tied-array-channelised-voltage.0y\"]\n                running_instrument = self.instrument\n                assert running_instrument is not False\n                msg = \"Running instrument currently does not have beamforming capabilities.\"\n                assert not running_instrument.endswith(\"32k\"), msg\n                self.Step(\"Discontinue any capturing of %s and %s, if active.\" % (beams[0], beams[1]))\n                reply, informs = self.katcp_req.capture_stop(beams[0])\n                assert reply.reply_ok(), str(reply)\n                reply, informs = self.katcp_req.capture_stop(beams[1])\n                assert reply.reply_ok(), str(reply)\n\n                # Get instrument parameters\n                bw = self.cam_sensors.get_value(\"bandwidth\")\n                nr_ch = self.cam_sensors.get_value(\"n_chans\")\n                ants = self.cam_sensors.get_value(\"n_ants\")\n                ch_list = self.cam_sensors.ch_center_freqs\n                ch_bw = ch_list[1]\n                dsim_factor = float(self.conf_file[\"instrument_params\"][\"sample_freq\"]) / self.cam_sensors.get_value(\n                    \"scale_factor_timestamp\"\n                )\n                substreams = self.cam_sensors.get_value(\"n_xengs\")\n            except AssertionError:\n                errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n                self.Error(errmsg, exc_info=True)\n                return False\n            except Exception:\n                self.Error(\"Error occurred\", exc_info=True)\n                return False\n\n            self.Progress(\"Bandwidth = {}Hz\".format(bw * dsim_factor))\n            self.Progress(\"Number of channels = {}\".format(nr_ch))\n            self.Progress(\"Channel spacing = {}Hz\".format(ch_bw * dsim_factor))\n\n            beam = beams[0]\n            try:\n                beam_name = beam.replace(\"-\", \"_\").replace(\".\", \"_\")\n                beam_ip, beam_port = self.cam_sensors.get_value(beam_name + \"_destination\").split(\":\")\n                beam_ip = beam_ip.split(\"+\")[0]\n                start_beam_ip = beam_ip\n                n_substrms_to_cap_m = int(self.conf_file[\"beamformer\"][\"substreams_to_capture\"])\n                start_substream = int(self.conf_file[\"beamformer\"][\"start_substream_idx\"])\n                if start_substream + n_substrms_to_cap_m > substreams:\n                    errmsg = (\n                        \"Substream start + substreams to process \"\n                        \"is more than substreams available: {}. \"\n                        \"Fix in test configuration file\".format(substeams)\n                    )\n                    self.Failed(errmsg)\n                    return False\n                ticks_between_spectra = self.cam_sensors.get_value(\n                    \"antenna_channelised_voltage_n_samples_between_spectra\"\n                )\n                assert isinstance(ticks_between_spectra, int)\n                spectra_per_heap = self.cam_sensors.get_value(beam_name + \"_spectra_per_heap\")\n                assert isinstance(spectra_per_heap, int)\n                ch_per_substream = self.cam_sensors.get_value(beam_name + \"_n_chans_per_substream\")\n                assert isinstance(ch_per_substream, int)\n            except AssertionError:\n                errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n                self.Error(errmsg, exc_info=True)\n                return False\n            except Exception:\n                self.Error(\"Error occurred\", exc_info=True)\n                return False\n\n            # Compute the start IP address according to substream start index\n            beam_ip = int2ip(ip2int(beam_ip) + start_substream)\n            # Compute spectrum parameters\n            strt_ch_idx = start_substream * ch_per_substream\n            strt_freq = ch_list[strt_ch_idx] * dsim_factor\n            self.Step(\"Start a KAT SDP docker ingest node for beam captures\")\n            docker_status = start_katsdpingest_docker(\n                self,\n                beam_ip,\n                beam_port,\n                n_substrms_to_cap_m,\n                nr_ch,\n                ticks_between_spectra,\n                ch_per_substream,\n                spectra_per_heap,\n            )\n            if docker_status:\n                self.Progress(\n                    \"KAT SDP Ingest Node started. Capturing {} substream/s \"\n                    \"starting at {}\".format(n_substrms_to_cap_m, beam_ip)\n                )\n            else:\n                self.Failed(\"KAT SDP Ingest Node failed to start\")\n\n            self.Step(\"Set beamformer quantiser gain for selected beam to 1\")\n            set_beam_quant_gain(self, beam, 1)\n\n            beam_dict = {}\n            beam_pol = beam[-1]\n            for label in labels:\n                if label.find(beam_pol) != -1:\n                    beam_dict[label] = 0.0\n\n            self.Progress(\"Only one antenna gain is set to 1, the reset are set to zero\")\n            weight = 1.0\n            beam_dict = populate_beam_dict(self, 1, weight, beam_dict)\n            try:\n                bf_raw, cap_ts, bf_ts, in_wgts = capture_beam_data(self, beam, beam_dict)\n            except TypeError:\n                errmsg = (\n                    \"Failed to capture beam data: Confirm that Docker container is \"\n                    \"running and also confirm the igmp version = 2 \"\n                )\n                self.Error(errmsg, exc_info=True)\n                return False\n\n            try:\n                nc = 10000\n                cap = [0] * nc\n                for i in range(0, nc):\n                    cap[i] = np.array(complexise(bf_raw[:, i, :]))\n                cap_mag = np.abs(cap)\n                cap_avg = cap_mag.sum(axis=0) / nc\n                # Confirm that the beam channel bandwidth corresponds to the channel bandwidth\n                # determined from the baseline capture\n                # baseline_ch_bw = bw * dsim_clk_factor / response.shape[0]\n\n                # hardcoded the bandwidth value due to a custom dsim frequency used in the config file\n                # Square the voltage data. This is a hack as aqf_plot expects squared\n                # power data\n                aqf_plot_channels(\n                    np.square(cap_avg),\n                    plot_filename=\"{}/{}_beam_response_{}.png\".format(self.logs_path, self._testMethodName, beam),\n                    plot_title=(\n                        \"Beam = {}, Spectrum Start Frequency = {} MHz\\n\"\n                        \"Number of Channels Captured = {}\\n\"\n                        \"Integrated over {} captures\".format(\n                            beam, strt_freq / 1e6, n_substrms_to_cap_m * ch_per_substream, nc\n                        )\n                    ),\n                    log_dynamic_range=90,\n                    log_normalise_to=1,\n                    caption=(\"Tied Array Beamformer data captured during Baseline Correlation Product test.\"),\n                    plot_type=\"bf\",\n                )\n            except Exception:\n                self.Failed(\"Failed to plot the diagram\")\n\n        if _baseline and _tiedarray:\n            captured_bw = bw * self.n_chans_selected / float(nr_ch)\n            baseline_ch_bw = captured_bw / test_dump[\"xeng_raw\"].shape[0]\n            beam_ch_bw = bw / len(cap_mag[0])\n            msg = (\n                \"Confirm that the baseline-correlation-product channel width\"\n                \" {}Hz is the same as the tied-array-channelised-voltage channel width \"\n                \"{}Hz\".format(baseline_ch_bw, beam_ch_bw)\n            )\n            Aqf.almost_equals(baseline_ch_bw, beam_ch_bw, 1e-3, msg)\n\n    def _test_time_sync(self):\n        self.Step(\"Request NTP pool address used.\")\n        try:\n            host_ip = \"192.168.194.2\"\n            ntp_offset = ntplib.NTPClient().request(host_ip, version=3).offset\n        except ntplib.NTPException:\n            host_ip = \"192.168.1.21\"\n            ntp_offset = ntplib.NTPClient().request(host_ip, version=3).offset\n        req_sync_time = 5e-3\n        msg = (\n            \"Confirm that the CBF synchronised time is within {}s of \"\n            \"UTC time as provided via PTP (NTP server: {}) on the CBF-TRF \"\n            \"interface.\".format(req_sync_time, host_ip)\n        )\n        Aqf.less(ntp_offset, req_sync_time, msg)\n\n    def _test_gain_correction(self):\n        \"\"\"CBF Gain Correction\"\"\"\n        if \"4k\" in self.instrument:\n            # 4K\n            awgn_scale = 0.0645\n            # gain = 113\n            gain = 30\n            fft_shift = 511\n        else:\n            # 32K\n            awgn_scale = 0.063\n            gain = 344\n            fft_shift = 4095\n\n        self.Step(\"Configure a digitiser simulator to generate correlated noise.\")\n        self.Progress(\n            \"Digitiser simulator configured to generate Gaussian noise, \"\n            \"with scale: %s, eq gain: %s, fft shift: %s\" % (awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(self, awgn_scale=awgn_scale, cw_scale=0.0, fft_shift=fft_shift, gain=gain)\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitiser simulator levels\")\n            return False\n\n        # Set per channel gain vectors for chosen input.\n        source = random.randrange(len(self.cam_sensors.input_labels))\n        test_input = random.choice(self.cam_sensors.input_labels)\n        self.Step(\"Randomly selected input to test: %s\" % (test_input))\n        n_chans = self.cam_sensors.get_value(\"n_chans\")\n        rand_ch = random.choice(range(n_chans)[: self.n_chans_selected])\n        gain_vector = [gain] * n_chans\n        base_gain = gain\n        try:\n            reply, informs = self.katcp_req.gain(test_input, base_gain)\n            assert reply.reply_ok()\n        except Exception:\n            self.Failed(\"Gain correction on %s could not be set to %s.: \" \"KATCP Reply: %s\" % (test_input, gain, reply))\n            return False\n\n        _discards = 5\n        try:\n            initial_dump = self.receiver.get_clean_dump(discard=_discards)\n            self.assertIsInstance(initial_dump, dict)\n            assert np.any(initial_dump[\"xeng_raw\"])\n        except Exception:\n            errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n            return\n        else:\n            # Get auto correlation index of the selected input\n            bls_order = eval(self.cam_sensors.get_value(\"bls_ordering\"))\n            for idx, val in enumerate(bls_order):\n                if val[0] == test_input and val[1] == test_input:\n                    auto_corr_idx = idx\n            initial_resp = np.abs(complexise(initial_dump[\"xeng_raw\"][:, auto_corr_idx, :]))\n            initial_resp = 10 * np.log10(initial_resp)\n            prev_resp = initial_resp\n            chan_resp = []\n            legends = []\n            found = False\n            fnd_less_one = False\n            count = 0\n            self.Step(\n                \"Note: Gains are relative to reference channels, and are increased \"\n                \"iteratively until output power is increased by more than 6dB.\"\n            )\n            # Reset gain vectors for all channels\n            try:\n                reply, informs = self.katcp_req.gain(test_input, *gain_vector, timeout=60)\n                assert reply.reply_ok()\n            except Exception:\n                self.Failed(\n                    \"Gain correction on %s could not be set to %s.: \" \"KATCP Reply: %s\" % (test_input, gain, reply)\n                )\n                return False\n            while not found:\n                if not fnd_less_one:\n                    target = 1\n                    gain_inc = 5\n                else:\n                    target = 6\n                    gain_inc = 200\n                gain = gain + gain_inc\n                gain_vector[rand_ch] = gain\n                try:\n                    reply, _ = self.katcp_req.gain(test_input, *gain_vector)\n                    assert reply.reply_ok()\n                    reply, _ = self.katcp_req.gain(test_input)\n                    assert reply.reply_ok()\n                except AssertionError:\n                    self.Failed(\n                        \"Gain correction on %s could not be set to %s.: \" \"KATCP Reply: %s\" % (test_input, gain, reply)\n                    )\n                else:\n                    msg = \"Gain correction on input %s, channel %s set to %s.\" % (\n                        test_input,\n                        rand_ch,\n                        reply.arguments[rand_ch + 1],\n                    )\n                    Aqf.passed(msg)\n                    try:\n                        dump = self.receiver.get_clean_dump(discard=_discards)\n                        self.assertIsInstance(dump, dict)\n                    except AssertionError:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Error(errmsg, exc_info=True)\n                    else:\n                        response = np.abs(complexise(dump[\"xeng_raw\"][:, auto_corr_idx, :]))\n                        response = 10 * np.log10(response)\n                        self.Progress(\"Maximum value found in channel {}\".format(np.argmax(response)))\n                        # resp_diff = response[rand_ch] - initial_resp[rand_ch]\n                        resp_diff = response[rand_ch] - prev_resp[rand_ch]\n                        prev_resp = response\n                        if resp_diff < target:\n                            msg = (\n                                \"Output power increased by less than 1 dB \"\n                                \"(actual = {:.2f} dB) with a gain \"\n                                \"increment of {}.\".format(resp_diff, complex(gain_inc))\n                            )\n                            Aqf.passed(msg)\n                            fnd_less_one = True\n                            chan_resp.append(response)\n                            legends.append(\"Gain set to %s\" % (complex(gain)))\n                        elif fnd_less_one and (resp_diff > target):\n                            msg = (\n                                \"Output power increased by more than 6 dB \"\n                                \"(actual = {:.2f} dB) with a gain \"\n                                \"increment of {}.\".format(resp_diff, complex(gain_inc))\n                            )\n                            Aqf.passed(msg)\n                            found = True\n                            chan_resp.append(response)\n                            legends.append(\"Gain set to %s\" % (complex(gain)))\n                        else:\n                            pass\n                count += 1\n                if count == 7:\n                    self.Failed(\"Gains to change output power by less than 1 and more than 6 dB \" \"could not be found.\")\n                    found = True\n\n            if chan_resp != []:\n                zipped_data = zip(chan_resp, legends)\n                zipped_data.reverse()\n                aqf_plot_channels(\n                    zipped_data,\n                    plot_filename=\"{}/{}_chan_resp.png\".format(self.logs_path, self._testMethodName),\n                    plot_title=\"Channel Response Gain Correction for channel %s\" % (rand_ch),\n                    log_dynamic_range=90,\n                    log_normalise_to=1,\n                    caption=\"Gain Correction channel response, gain varied for channel %s, \"\n                    \"all remaining channels are set to %s\" % (rand_ch, complex(base_gain)),\n                )\n            else:\n                self.Failed(\"Could not retrieve channel response with gain/eq corrections.\")\n\n    def _test_beamforming(self):\n        \"\"\"\n        Apply weights and capture beamformer data, Verify that weights are correctly applied.\n        \"\"\"\n        # Main test code\n        # TODO AR\n        # Neccessarry to compare output products with capture-list output products?\n\n        try:\n            output = subprocess.check_output([\"docker\", \"run\", \"hello-world\"])\n            self.logger.info(output)\n        except subprocess.CalledProcessError:\n            errmsg = \"Cannot connect to the Docker daemon. Is the docker daemon running on this host?\"\n            self.Failed(errmsg)\n            return False\n\n        try:\n            # Set custom source names\n            local_src_names = self.cam_sensors.custom_input_labels\n            reply, informs = self.katcp_req.input_labels(*local_src_names)\n            assert reply.reply_ok()\n            labels = reply.arguments[1:]\n            beams = [\"tied-array-channelised-voltage.0x\", \"tied-array-channelised-voltage.0y\"]\n            # running_instrument = self.corr_fix.get_running_instrument()\n            # assert running_instrument is not False\n            # msg = 'Running instrument currently does not have beamforming capabilities.'\n            # assert running_instrument.endswith('4k'), msg\n            self.Step(\"Discontinue any capturing of %s and %s, if active.\" % (beams[0], beams[1]))\n            reply, informs = self.katcp_req.capture_stop(beams[0])\n            assert reply.reply_ok(), str(reply)\n            reply, informs = self.katcp_req.capture_stop(beams[1])\n            assert reply.reply_ok(), str(reply)\n\n            # Get instrument parameters\n            bw = self.cam_sensors.get_value(\"bandwidth\")\n            nr_ch = self.cam_sensors.get_value(\"n_chans\")\n            ants = self.cam_sensors.get_value(\"n_ants\")\n            ch_list = self.cam_sensors.ch_center_freqs\n            ch_bw = ch_list[1]\n            dsim_factor = float(self.conf_file[\"instrument_params\"][\"sample_freq\"]) / self.cam_sensors.get_value(\n                \"scale_factor_timestamp\"\n            )\n            substreams = self.cam_sensors.get_value(\"n_xengs\")\n            # For substream alignment test only print out 5 results\n            align_print_modulo = int(substreams / 4)\n        except AssertionError:\n            errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            self.Error(\"Error Occurred\", exc_info=True)\n            return False\n\n        self.Progress(\"Bandwidth = {}Hz\".format(bw * dsim_factor))\n        self.Progress(\"Number of channels = {}\".format(nr_ch))\n        self.Progress(\"Channel spacing = {}Hz\".format(ch_bw * dsim_factor))\n\n        beam = beams[0]\n        try:\n            beam_name = beam.replace(\"-\", \"_\").replace(\".\", \"_\")\n            beam_ip, beam_port = self.cam_sensors.get_value(beam_name + \"_destination\").split(\":\")\n            beam_ip = beam_ip.split(\"+\")[0]\n            start_beam_ip = beam_ip\n            n_substrms_to_cap_m = int(self.conf_file[\"beamformer\"][\"substreams_to_capture\"])\n            start_substream = int(self.conf_file[\"beamformer\"][\"start_substream_idx\"])\n            if start_substream + n_substrms_to_cap_m > substreams:\n                errmsg = (\n                    \"Substream start + substreams to process \"\n                    \"is more than substreams available: {}. \"\n                    \"Fix in test configuration file\".format(substeams)\n                )\n                self.Failed(errmsg)\n                return False\n            ticks_between_spectra = self.cam_sensors.get_value(\"antenna_channelised_voltage_n_samples_between_spectra\")\n            assert isinstance(ticks_between_spectra, int)\n            spectra_per_heap = self.cam_sensors.get_value(beam_name + \"_spectra_per_heap\")\n            assert isinstance(spectra_per_heap, int)\n            ch_per_substream = self.cam_sensors.get_value(beam_name + \"_n_chans_per_substream\")\n            assert isinstance(ch_per_substream, int)\n        except AssertionError:\n            errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            self.Error(\"Error Occurred\", exc_info=True)\n            return False\n\n        # Compute the start IP address according to substream start index\n        beam_ip = int2ip(ip2int(beam_ip) + start_substream)\n        # Compute spectrum parameters\n        strt_ch_idx = start_substream * ch_per_substream\n        strt_freq = ch_list[strt_ch_idx] * dsim_factor\n        self.Step(\"Start a KAT SDP docker ingest node for beam captures\")\n        docker_status = start_katsdpingest_docker(\n            self,\n            beam_ip,\n            beam_port,\n            n_substrms_to_cap_m,\n            nr_ch,\n            ticks_between_spectra,\n            ch_per_substream,\n            spectra_per_heap,\n        )\n        if docker_status:\n            self.Progress(\n                \"KAT SDP Ingest Node started. Capturing {} substream/s \"\n                \"starting at {}\".format(n_substrms_to_cap_m, beam_ip)\n            )\n        else:\n            self.Failed(\"KAT SDP Ingest Node failed to start\")\n\n        # Create a katcp client to connect to katcpingest\n        if os.uname()[1] == \"cmc2\":\n            ingst_nd = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node_cmc2\"]\n        elif os.uname()[1] == \"cmc3\":\n            ingst_nd = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node_cmc3\"]\n        else:\n            ingst_nd = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node\"]\n        ingst_nd_p = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node_port\"]\n        _timeout = 10\n        try:\n            import katcp\n\n            ingest_kcp_client = katcp.BlockingClient(ingst_nd, ingst_nd_p)\n            ingest_kcp_client.setDaemon(True)\n            ingest_kcp_client.start()\n            self.addCleanup(ingest_kcp_client.stop)\n            is_connected = ingest_kcp_client.wait_connected(_timeout)\n            if not is_connected:\n                errmsg = \"Could not connect to %s:%s, timed out.\" % (ingst_nd, ingst_nd_p)\n                ingest_kcp_client.stop()\n                raise RuntimeError(errmsg)\n        except Exception:\n            self.Error(\"error occurred\", exc_info=True)\n\n        def substreams_to_capture(lbeam, lbeam_ip, lsubstrms_to_cap, lbeam_port):\n            \"\"\" Set ingest node capture substreams \"\"\"\n            try:\n                self.logger.info(\n                    \"Setting ingest node to capture beam, substreams: {}, {}+{}:{}\".format(\n                        lbeam, lbeam_ip, lsubstrms_to_cap - 1, lbeam_port\n                    )\n                )\n                reply, informs = ingest_kcp_client.blocking_request(\n                    katcp.Message.request(\n                        \"substreams-to-capture\", \"{}+{}:{}\".format(lbeam_ip, lsubstrms_to_cap - 1, lbeam_port)\n                    ),\n                    timeout=_timeout,\n                )\n                assert reply.reply_ok()\n            except Exception:\n                errmsg = \"Failed to issues ingest node capture-init: {}\".format(str(reply))\n                self.Error(errmsg, exc_info=True)\n\n        for beam in beams:\n            beam_name = beam.replace(\"-\", \"_\").replace(\".\", \"_\")\n            beam_ip, beam_port = self.cam_sensors.get_value(beam_name + \"_destination\").split(\":\")\n            beam_ip = beam_ip.split(\"+\")[0]\n            start_beam_ip = beam_ip\n            n_substrms_to_cap = n_substrms_to_cap_m\n            # Compute the start IP address according to substream start index\n            beam_ip = int2ip(ip2int(beam_ip) + start_substream)\n            substreams_to_capture(beam, beam_ip, n_substrms_to_cap, beam_port)\n            Aqf.hop(\"\")\n            Aqf.hop(\"\")\n            self.Step(\"Testing beam: {}\".format(beam))\n\n            def get_beam_data(\n                beam,\n                beam_dict=None,\n                inp_ref_lvl=0,\n                beam_quant_gain=1,\n                act_wgts=None,\n                exp_cw_ch=-1,\n                s_ch_idx=0,\n                s_substream=start_substream,\n                subs_to_cap=n_substrms_to_cap,\n                max_cap_retries=5,\n                conf_data_type=False,\n                avg_only=False,\n                data_only=False,\n            ):\n                \"\"\"\n                    beam - beam name\n                    beam_dict - Required beam weights dict. If this is none weights will not\n                                be set, but act_wgts must be supplied for calculations\n                    inp_ref_lvl - Input reference level for calculations, will be obtained\n                                  if value is 0\n                    beam_quant_gain - beam quant gain (level adjust after beamforming)\n                    act_wgts = Dict containing actual set weights for beam, needed if beam_dict\n                               not supplied as they will not be returned if this is the case.\n                    exp_cw_ch - Expect a cw in this channel, ignore if -1\n                    s_ch_idx - start channel of the captured substream, used to calculate real\n                               frequencies.\n                    s_substream = Start substream\n                    subs_to_cap = Number of stubstreams in the capture\n                    max_cap_retries = max number of retries if data cap failed\n                    conf_data_type= If true print the beam data type\n                    avg_only = only return a list of averaged beam power. list lenght is the number\n                                of captured channels.\n                    data_only = only return a matrix of beam power.\n                                of captured channels.\n                \"\"\"\n\n                # Determine slice of valid data in bf_raw\n                bf_raw_str = s_substream * ch_per_substream\n                bf_raw_end = bf_raw_str + ch_per_substream * subs_to_cap\n\n                # Capture beam data, retry if more than 20% of heaps dropped or empty data\n                retries = 0\n                while retries < max_cap_retries:\n                    if retries == max_cap_retries - 1:\n                        self.Failed(\"Error capturing beam data.\")\n                        return False\n                    retries += 1\n                    try:\n                        bf_raw, bf_flags, bf_ts, in_wgts = capture_beam_data(self, beam, beam_dict, ingest_kcp_client)\n                        # Set beamdict to None in case the capture needs to be retried.\n                        # The beam weights have already been set.\n                        beam_dict = None\n                        if (len(in_wgts) == 0) and (isinstance(act_wgts, dict)):\n                            in_wgts = act_wgts.copy()\n                    except Exception:\n                        self.Failed(\n                            \"Confirm that the Docker container is running and also confirm the \"\n                            \"igmp version = 2\"\n                        )\n                        return False\n\n                    data_type = bf_raw.dtype.name\n                    # Cut selected partitions out of bf_flags\n                    flags = bf_flags[s_substream : s_substream + subs_to_cap]\n                    # self.Step('Finding missed heaps for all partitions.')\n                    if flags.size == 0:\n                        self.logger.warning(\"Beam data empty. Capture failed. Retrying...\")\n                    else:\n                        missed_err = False\n                        for part in flags:\n                            missed_heaps = np.where(part > 0)[0]\n                            missed_perc = missed_heaps.size / part.size\n                            perc = 0.60\n                            if missed_perc > perc:\n                                self.Progress(\"Missed heap percentage = {}%%\".format(missed_perc * 100))\n                                self.Progress(\"Missed heaps = {}\".format(missed_heaps))\n                                self.Progress(\"Beam captured missed more than %s%% heaps. Retrying...\" % (perc * 100))\n                                missed_err = True\n                                # break\n                        # Good capture, break out of loop\n                        if not missed_err:\n                            break\n\n                # Print missed heaps\n                idx = s_substream\n                for part in flags:\n                    missed_heaps = np.where(part > 0)[0]\n                    if missed_heaps.size > 0:\n                        self.logger.info(\"Missed heaps for substream {} at heap indexes {}\".format(idx, missed_heaps))\n                    idx += 1\n                # Combine all missed heap flags. These heaps will be discarded\n                flags = np.sum(flags, axis=0)\n                # cap = [0] * num_caps\n                # cap = [0] * len(bf_raw.shape[1])\n                cap = []\n                cap_idx = 0\n                raw_idx = 0\n                try:\n                    for heap_flag in flags:\n                        if heap_flag == 0:\n                            for raw_idx in range(raw_idx, raw_idx + spectra_per_heap):\n                                cap.append(np.array(complexise(bf_raw[bf_raw_str:bf_raw_end, raw_idx, :])))\n                                cap_idx += 1\n                            raw_idx += 1\n                        else:\n                            if raw_idx == 0:\n                                raw_idx = spectra_per_heap\n                            else:\n                                raw_idx = raw_idx + spectra_per_heap\n                except Exception:\n                    errmsg = \"Failed to capture beam data\"\n                    self.Error(errmsg, exc_info=True)\n\n                if conf_data_type:\n                    self.Step(\"Confirm that the data type of the beamforming data for one channel.\")\n                    msg = \"Beamformer data type is {}, example value for one channel: {}\".format(\n                        data_type, cap[0][0])\n                    Aqf.equals(data_type, \"int8\", msg)\n\n                cap_mag = np.abs(cap)\n                if data_only:\n                    return cap_mag, in_wgts\n                cap_avg = cap_mag.sum(axis=0) / cap_idx\n                cap_db = 20 * np.log10(cap_avg)\n                cap_db_mean = np.mean(cap_db)\n                if avg_only:\n                    return cap_avg, in_wgts\n                # NOT WORKING\n                # labels = ''\n                # lbls = self.parameters(self)\n                # for lbl in lbls:\n                #    bm = beam[-1]\n                #    if lbl.find(bm) != -1:\n                #        wght = self.correlator.bops.get_beam_weights(beam, lbl)\n                # print lbl, wght\n                #        labels += (lbl+\"={} \").format(wght)\n                labels = \"\"\n                label_values = in_wgts.values()\n                if label_values[1:] == label_values[:-1]:\n                    labels += \"All inputs = {}\\n\".format(label_values[0])\n                else:\n                    tmp = {}\n                    for key, val in in_wgts.items():\n                        if val not in tmp.values():\n                            tmp[key] = val\n                        else:\n                            for k, v in tmp.items():\n                                if val == v:\n                                    tmp.pop(k)\n                            tmp[\"Multiple Inputs\"] = val\n                    for key in tmp:\n                        labels += (key + \" = {}\\n\").format(tmp[key])\n                labels += \"Mean = {:0.2f}dB\\n\".format(cap_db_mean)\n\n                failed = False\n                if inp_ref_lvl == 0:\n                    # Get the voltage level for one antenna. Gain for one input\n                    # should be set to 1, the rest should be 0\n                    inp_ref_lvl = np.mean(cap_avg)\n                    self.Step(\"Input ref level: {}\".format(inp_ref_lvl))\n                    self.Step(\n                        \"Reference level measured by setting the \"\n                        \"gain for one antenna to 1 and the rest to 0. \"\n                        \"Reference level = {:.3f}dB\".format(20 * np.log10(inp_ref_lvl))\n                    )\n                    self.Step(\n                        \"Reference level averaged over {} channels. \"\n                        \"Channel averages determined over {} \"\n                        \"samples.\".format(n_substrms_to_cap * ch_per_substream, cap_idx)\n                    )\n                    expected = 0\n                else:\n                    delta = 0.2\n                    expected = np.sum([inp_ref_lvl * in_wgts[key] for key in in_wgts]) * beam_quant_gain\n                    expected = 20 * np.log10(expected)\n\n                    if exp_cw_ch != -1:\n                        local_substream = s_ch_idx / ch_per_substream\n                        # Find cw in expected channel, all other channels must be at expected level\n                        max_val_ch = np.argmax(cap_db)\n                        max_val = np.max(cap_db)\n                        if max_val_ch == (exp_cw_ch - s_ch_idx):\n                            msg = (\n                                \"CW at {:.3f}MHz found in channel {}, magnitude = {:.1f}dB, \"\n                                \"spectrum mean = {:.1f}dB\".format(\n                                    ch_list[exp_cw_ch] / 1e6, exp_cw_ch, max_val, cap_db_mean\n                                )\n                            )\n                            self.logger.info(msg)\n                            if local_substream % align_print_modulo == 0:\n                                Aqf.passed(msg)\n                        else:\n                            failed = True\n                            self.Failed(\n                                \"CW at {:.3f}MHz not found in channel {}. \"\n                                \"Maximum value of {}dB found in channel {}. \"\n                                \"Mean spectrum value = {}dB\".format(\n                                    ch_list[exp_cw_ch] / 1e6, exp_cw_ch, max_val,\n                                    max_val_ch + s_ch_idx, cap_db_mean\n                                )\n                            )\n\n                        spikes = np.where(cap_db > expected + delta)[0]\n                        if len(spikes == 1):\n                            msg = \"No spikes found in sub spectrum.\"\n                            self.logger.info(msg)\n                            if local_substream % align_print_modulo == 0:\n                                Aqf.passed(msg)\n                        else:\n                            failed = True\n                            self.Failed(\"Spikes found at: {}\".format(spikes))\n                    else:\n                        self.Step(\n                            \"Expected value is calculated by taking the reference input level \"\n                            \"and multiplying by the channel weights and quantiser gain.\"\n                        )\n                        labels += \"Expected = {:.2f}dB\\n\".format(expected)\n                        msg = (\n                            \"Confirm that the expected voltage level ({:.3f}dB) is within \"\n                            \"{}dB of the measured mean value ({:.3f}dB)\".format(\n                                expected, delta, cap_db_mean)\n                        )\n                        Aqf.almost_equals(cap_db_mean, expected, delta, msg)\n                return cap_avg, labels, inp_ref_lvl, expected, cap_idx, in_wgts, failed\n\n            # Setting DSIM to generate noise\n            if \"4k\" in self.instrument:\n                # 4K\n                awgn_scale = 0.0645\n                cw_scale = 0.0\n                gain = \"113+0j\"\n                fft_shift = 511\n            else:\n                # 32K\n                awgn_scale = 0.063\n                cw_scale = 0.0\n                gain = \"344+0j\"\n                fft_shift = 4095\n\n            self.Progress(\n                \"Digitiser simulator configured to generate Gaussian noise: \"\n                \"Noise scale: {}, eq gain: {}, fft shift: {}\".format(awgn_scale, gain, fft_shift)\n            )\n            dsim_set_success = set_input_levels(\n                self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=0, fft_shift=fft_shift, gain=gain\n            )\n            if not dsim_set_success:\n                self.Failed(\"Failed to configure digitise simulator levels\")\n                return False\n\n            # Only one antenna gain is set to 1, this will be used as the reference\n            # input level\n            # Set beamformer quantiser gain for selected beam to 1 quant gain reversed TODO: Fix\n            bq_gain = set_beam_quant_gain(self, beam, 1)\n            # Generating a dictionary to contain beam weights\n            beam_dict = {}\n            act_wgts = {}\n            beam_pol = beam[-1]\n            for label in labels:\n                if label.find(beam_pol) != -1:\n                    beam_dict[label] = 0.0\n            if len(beam_dict) == 0:\n                self.Failed(\"Beam dictionary not created, beam labels or beam name incorrect\")\n                return False\n            ants = self.cam_sensors.get_value(\"n_ants\")\n            ref_input = np.random.randint(ants)\n            # Find reference input label\n            for key in beam_dict:\n                if int(filter(str.isdigit, key)) == ref_input:\n                    ref_input_label = key\n                    break\n            self.Step(\"{} used as a randomised reference input for this test\".format(ref_input_label))\n            weight = 1.0\n            beam_dict = populate_beam_dict_idx(self, ref_input, weight, beam_dict)\n            beam_data = []\n            beam_lbls = []\n            self.Step(\"Testing individual beam weights.\")\n            try:\n                # Calculate reference level by not specifying ref level\n                # Use weights from previous test\n                d, l, rl, exp0, nc, act_wgts, dummy = get_beam_data(beam, beam_dict=beam_dict, conf_data_type=True)\n            except Exception:\n                errmsg = \"Failed to retrieve beamformer data\"\n                self.Failed(errmsg)\n                return False\n            beam_data.append(d)\n            beam_lbls.append(l)\n\n            # Characterise beam weight application:\n            self.Step(\"Characterising beam weight application.\")\n            self.Step(\"Step weight for one input and plot the mean value for all channels against expected value.\")\n            self.Step(\"Expected value calculated by multiplying reference value with weight.\")\n            weight = 0.1\n            mean_vals = []\n            exp_mean_vals = []\n            weight_lbls = []\n            # Create a list of weights to send\n            weight_list = [0] * ants\n\n            retry_cnt = 0\n            while weight <= 4:\n                weight_list[ref_input] = round(weight, 1)\n\n                # Set weight for reference input, the rest are all zero\n                # TODO: check that this actually checks that the correct weight has been set\n                self.logger.info(\n                    \"Confirm that antenna input ({}) weight has been set to the desired weight.\".format(ref_input_label)\n                )\n                try:\n                    reply, informs = self.katcp_req.beam_weights(beam, *weight_list, timeout=60)\n                    assert reply.reply_ok()\n                    actual_weight = float(reply.arguments[1 + ref_input])\n                    retry_cnt = 0\n                except AssertionError:\n                    retry_cnt += 1\n                    self.Failed(\"Beam weight not successfully set: {}\".format(reply))\n                    if retry_cnt == 5:\n                        self.Failed(\"Beam weight could not be set after 5 retries... Exiting test.\")\n                        return False\n                    continue\n                except Exception:\n                    retry_cnt += 1\n                    errmsg = \"Test failed\"\n                    self.Error(errmsg, exc_info=True)\n                    if retry_cnt == 5:\n                        self.Failed(\"Beam weight could not be set after 5 retries... Exiting test.\")\n                        return False\n                    continue\n                else:\n                    Aqf.passed(\"Antenna input {} weight set to {}\".format(key, actual_weight))\n\n                # Get mean beam data\n                try:\n                    cap_data, act_wgts = get_beam_data(beam, avg_only=True)\n                    cap_mean = np.mean(cap_data)\n                    exp_mean = rl * actual_weight\n                    mean_vals.append(cap_mean)\n                    exp_mean_vals.append(exp_mean)\n                    weight_lbls.append(weight)\n                    self.Progress(\n                        \"Captured mean value = {:.2f}, Calculated mean value \"\n                        \"(using reference value) = {:.2f}\".format(cap_mean, exp_mean)\n                    )\n                except Exception:\n                    errmsg = \"Failed to retrieve beamformer data\"\n                    self.Failed(errmsg)\n                    return\n                if round(weight, 1) < 1:\n                    weight += 0.1\n                else:\n                    weight += 0.5\n            # Square the voltage data. This is a hack as aqf_plot expects squared\n            # power data\n            aqf_plot_channels(\n                (\n                    (\n                        mean_vals,\n                        \"Captured mean beam output.\\nStepping one input weight,\\nwith remaining weights set to 0.\",\n                    ),\n                    (\n                        exp_mean_vals,\n                        \"Value calculated from reference,\\nwhere reference measured at\\nan input weight of 1.\",\n                    ),\n                ),\n                plot_filename=\"{}/{}_weight_application_{}.png\".format(self.logs_path, self._testMethodName, beam),\n                plot_title=(\"Beam = {}\\n\" \"Expected vs Actual Mean Beam Output for Input Weight.\".format(beam)),\n                log_dynamic_range=None,  # 90, log_normalise_to=1,\n                ylabel=\"Mean Beam Output\",\n                xlabel=\"{} Weight\".format(ref_input_label),\n                xvals=weight_lbls,\n            )\n\n            # Test weight application across all antennas\n            self.Step(\"Testing weight application across all antennas.\")\n            weight = 0.4 / ants\n            beam_dict = populate_beam_dict(self, -1, weight, beam_dict)\n            try:\n                d, l, rl, exp1, nc, act_wgts, dummy = get_beam_data(beam, beam_dict, rl)\n            except Exception:\n                errmsg = \"Failed to retrieve beamformer data:\"\n                self.Failed(errmsg)\n                return\n            beam_data.append(d)\n            beam_lbls.append(l)\n            weight = 1.0 / ants\n            beam_dict = populate_beam_dict(self, -1, weight, beam_dict)\n            try:\n                d, l, rl, exp0, nc, act_wgts, dummy = get_beam_data(beam, beam_dict, rl)\n            except Exception:\n                errmsg = \"Failed to retrieve beamformer data\"\n                self.Failed(errmsg)\n                return\n            beam_data.append(d)\n            beam_lbls.append(l)\n            # Square the voltage data. This is a hack as aqf_plot expects squared\n            # power data\n            aqf_plot_channels(\n                zip(np.square(beam_data), beam_lbls),\n                plot_filename=\"{}/{}_chan_resp_{}.png\".format(self.logs_path, self._testMethodName, beam),\n                plot_title=(\n                    \"Beam = {}\\nSpectrum Start Frequency = {} MHz\\n\"\n                    \"Number of Channels Captured = {}\"\n                    \"\\nIntegrated over {} captures\".format(\n                        beam, strt_freq / 1e6, n_substrms_to_cap * ch_per_substream, nc\n                    )\n                ),\n                log_dynamic_range=90,\n                log_normalise_to=1,\n                caption=\"Captured beamformer data\",\n                hlines=[exp0, exp1],\n                plot_type=\"bf\",\n                hline_strt_idx=1,\n            )\n\n            self.Step(\"Testing quantiser gain adjustment.\")\n            # Level adjust after beamforming gain has already been set to 1\n            beam_data = []\n            beam_lbls = []\n            try:\n                # Recalculate reference level by not specifying ref level\n                # Use weights from previous test\n                d, l, rl, exp0, nc, act_wgts, dummy = get_beam_data(beam, beam_quant_gain=bq_gain, act_wgts=act_wgts)\n            except Exception:\n                errmsg = \"Failed to retrieve beamformer data:\"\n                self.Failed(errmsg)\n                return\n            beam_data.append(d)\n            l += \"Level adjust gain={}\".format(bq_gain)\n            beam_lbls.append(l)\n\n            # Set level adjust after beamforming gain to 0.5\n            bq_gain = set_beam_quant_gain(self, beam, 0.5)\n            try:\n                d, l, rl, exp1, nc, act_wgts, dummy = get_beam_data(\n                    beam, inp_ref_lvl=rl, beam_quant_gain=bq_gain, act_wgts=act_wgts\n                )\n            except Exception:\n                errmsg = \"Failed to retrieve beamformer data:\"\n                self.Failed(errmsg)\n                return\n            beam_data.append(d)\n            l += \"Level adjust gain={}\".format(bq_gain)\n            beam_lbls.append(l)\n\n            # Square the voltage data. This is a hack as aqf_plot expects squared\n            # power data\n            aqf_plot_channels(\n                zip(np.square(beam_data), beam_lbls),\n                plot_filename=\"{}/{}_level_adjust_after_bf_{}.png\".format(self.logs_path, self._testMethodName, beam),\n                plot_title=(\n                    \"Beam = {}\\nSpectrum Start Frequency = {} MHz\\n\"\n                    \"Number of Channels Captured = {}\"\n                    \"\\nIntegrated over {} captures\".format(\n                        beam, strt_freq / 1e6, n_substrms_to_cap * ch_per_substream, nc\n                    )\n                ),\n                log_dynamic_range=90,\n                log_normalise_to=1,\n                caption=\"Captured beamformer data with level adjust after beam-forming gain set.\",\n                hlines=exp1,\n                plot_type=\"bf\",\n                hline_strt_idx=1,\n            )\n\n            self.Step(\"Checking beamformer substream alignment by injecting a CW in each substream.\")\n            self.Step(\n                \"Stepping through {} substreams and checking that the CW is in the correct \"\n                \"position.\".format(substreams)\n            )\n            # Reset quantiser gain\n            bq_gain = set_beam_quant_gain(self, beam, 1)\n            if \"4k\" in self.instrument:\n                # 4K\n                awgn_scale = 0.0645\n                cw_scale = 0.01\n                gain = \"113+0j\"\n                fft_shift = 511\n            else:\n                # 32K\n                awgn_scale = 0.063\n                cw_scale = 0.01\n                gain = \"344+0j\"\n                fft_shift = 4095\n\n            self.Progress(\n                \"Digitiser simulator configured to generate a stepping \"\n                \"Constant Wave and Gaussian noise, \"\n                \"CW scale: {}, Noise scale: {}, eq gain: {}, fft shift: {}\".format(\n                    cw_scale, awgn_scale, gain, fft_shift\n                )\n            )\n            self.Step(\"This test will take a long time... check log for progress.\")\n            self.Step(\n                \"Only 5 results will be printed, all {} substreams will be tested. \"\n                \"All errors will be displayed\".format(substreams)\n            )\n            aligned_failed = False\n            for substream in range(substreams):\n                # Get substream start channel index\n                strt_ch_idx = substream * ch_per_substream\n                n_substrms_to_cap = 1\n                # Compute the start IP address according to substream\n                beam_ip = int2ip(ip2int(start_beam_ip) + substream)\n                substreams_to_capture(beam, beam_ip, n_substrms_to_cap, beam_port)\n                msg = \"Capturing 1 substream at {}\".format(beam_ip)\n                self.logger.info(msg)\n                if substream % align_print_modulo == 0:\n                    Aqf.passed(msg)\n\n                # Step dsim CW\n                dsim_set_success = False\n                cw_ch = strt_ch_idx + int(ch_per_substream / 4)\n                freq = ch_list[cw_ch]\n                dsim_set_success = set_input_levels(\n                    self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=freq, fft_shift=fft_shift, gain=gain\n                )\n                if not dsim_set_success:\n                    self.Failed(\"Failed to configure digitise simulator levels\")\n                    return False\n\n                try:\n                    d, l, rl, exp0, nc, act_wgts, failed = get_beam_data(\n                        beam,\n                        inp_ref_lvl=rl,\n                        act_wgts=act_wgts,\n                        exp_cw_ch=cw_ch,\n                        s_ch_idx=strt_ch_idx,\n                        s_substream=substream,\n                        subs_to_cap=n_substrms_to_cap,\n                    )\n                    if failed:\n                        aligned_failed = True\n                except Exception:\n                    errmsg = \"Failed to retrieve beamformer data\"\n                    self.Failed(errmsg)\n                    return False\n            if aligned_failed:\n                self.Failed(\"Beamformer substream alignment test failed.\")\n            else:\n                Aqf.passed(\"All beamformer substreams correctly aligned.\")\n\n        # Close any KAT SDP ingest nodes\n        try:\n            if ingest_kcp_client:\n                ingest_kcp_client.stop()\n        except BaseException:\n            pass\n        stop_katsdpingest_docker(self)\n\n    def _test_beamforming_timeseries(self, beam_idx=0):\n        \"\"\"\n        Perform a time series analysis of the beamforming data\n        \"\"\"\n        # Main test code\n\n        try:\n            output = subprocess.check_output([\"docker\", \"run\", \"hello-world\"])\n            self.logger.info(output)\n        except subprocess.CalledProcessError:\n            errmsg = \"Cannot connect to the Docker daemon. Is the docker daemon running on this host?\"\n            self.Failed(errmsg)\n            return False\n\n        try:\n            # TODO: custom source names not working?\n            # Set custom source names\n            # local_src_names = self.cam_sensors.custom_input_labels\n            # reply, informs = self.corr_fix.katcp_rct.req.input_labels(*local_src_names)\n            # assert reply.reply_ok()\n            # labels = reply.arguments[1:]\n            labels = self.cam_sensors.input_labels\n            beams = [\"tied-array-channelised-voltage.0x\", \"tied-array-channelised-voltage.0y\"]\n            running_instrument = self.instrument\n            assert running_instrument is not False\n            msg = \"Running instrument currently does not have beamforming capabilities.\"\n            assert not running_instrument.endswith(\"32k\"), msg\n            self.Step(\"Discontinue any capturing of %s and %s, if active.\" % (beams[0], beams[1]))\n            reply, informs = self.katcp_req.capture_stop(beams[0], timeout=60)\n            assert reply.reply_ok(), str(reply)\n            reply, informs = self.katcp_req.capture_stop(beams[1], timeout=60)\n            assert reply.reply_ok(), str(reply)\n\n            # Get instrument parameters\n            bw = self.cam_sensors.get_value(\"bandwidth\")\n            nr_ch = self.cam_sensors.get_value(\"n_chans\")\n            ants = self.cam_sensors.get_value(\"n_ants\")\n            ch_list = self.cam_sensors.ch_center_freqs\n            ch_bw = ch_list[1]\n            dsim_factor = float(self.conf_file[\"instrument_params\"][\"sample_freq\"]) / self.cam_sensors.get_value(\n                \"scale_factor_timestamp\"\n            )\n            substreams = self.cam_sensors.get_value(\"n_xengs\")\n        except AssertionError:\n            errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            self.Error(\"Error Occurred\", exc_info=True)\n            return False\n\n        self.Progress(\"Bandwidth = {}Hz\".format(bw * dsim_factor))\n        self.Progress(\"Number of channels = {}\".format(nr_ch))\n        self.Progress(\"Channel spacing = {}Hz\".format(ch_bw * dsim_factor))\n\n        beam = beams[beam_idx]\n        try:\n            beam_name = beam.replace(\"-\", \"_\").replace(\".\", \"_\")\n            beam_ip, beam_port = self.cam_sensors.get_value(beam_name + \"_destination\").split(\":\")\n            beam_ip = beam_ip.split(\"+\")[0]\n            start_beam_ip = beam_ip\n            n_substrms_to_cap_m = int(self.conf_file[\"beamformer\"][\"substreams_to_capture\"])\n            start_substream = int(self.conf_file[\"beamformer\"][\"start_substream_idx\"])\n            if start_substream + n_substrms_to_cap_m > substreams:\n                errmsg = (\n                    \"Substream start + substreams to process \"\n                    \"is more than substreams available: {}. \"\n                    \"Fix in test configuration file\".format(substeams)\n                )\n                self.Failed(errmsg)\n                return False\n            ticks_between_spectra = self.cam_sensors.get_value(\"antenna_channelised_voltage_n_samples_between_spectra\")\n            assert isinstance(ticks_between_spectra, int)\n            spectra_per_heap = self.cam_sensors.get_value(beam_name + \"_spectra_per_heap\")\n            assert isinstance(spectra_per_heap, int)\n            ch_per_substream = self.cam_sensors.get_value(beam_name + \"_n_chans_per_substream\")\n            assert isinstance(ch_per_substream, int)\n        except AssertionError:\n            errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            self.Error(\"Error Occurred\", exc_info=True)\n            return False\n\n        # Compute the start IP address according to substream start index\n        beam_ip = int2ip(ip2int(beam_ip) + start_substream)\n        # Compute spectrum parameters\n        strt_ch_idx = start_substream * ch_per_substream\n        strt_freq = ch_list[strt_ch_idx] * dsim_factor\n        self.Step(\"Start a KAT SDP docker ingest node for beam captures\")\n        docker_status = start_katsdpingest_docker(\n            self,\n            beam_ip,\n            beam_port,\n            n_substrms_to_cap_m,\n            nr_ch,\n            ticks_between_spectra,\n            ch_per_substream,\n            spectra_per_heap,\n        )\n        if docker_status:\n            self.Progress(\n                \"KAT SDP Ingest Node started. Capturing {} substream/s \"\n                \"starting at {}\".format(n_substrms_to_cap_m, beam_ip)\n            )\n        else:\n            self.Failed(\"KAT SDP Ingest Node failed to start\")\n\n        # Determine CW frequency\n        center_bin_offset = float(self.conf_file[\"beamformer\"][\"center_bin_offset\"])\n        center_bin_offset_freq = ch_bw * center_bin_offset\n        cw_ch = strt_ch_idx + int(ch_per_substream / 4)\n\n        # Setting DSIM to generate off center bin CW time sequence\n        if \"4k\" in self.instrument:\n            # 4K\n            _capture_time = 0.1\n            awgn_scale = 0.085\n            cw_scale = 0.9\n            gain = 7\n            fft_shift = 8191\n        elif \"1k\" in self.instrument:\n            #\n            _capture_time = 2\n            awgn_scale = 0.085\n            cw_scale = 0.9\n            gain = \"30+0j\"\n            fft_shift = 1023\n            cw_ch = 65\n        else:\n            # 32K\n            _capture_time = 0.1\n            awgn_scale = 0.063\n            cw_scale = 0.01\n            gain = \"344+0j\"\n            fft_shift = 4095\n\n        freq = ch_list[cw_ch] + center_bin_offset_freq\n\n        self.Step(\n            \"Generating time analysis plots of beam for channel {} containing a \"\n            \"CW offset from center of a bin.\".format(cw_ch)\n        )\n        self.Progress(\n            \"Digitiser simulator configured to generate a \"\n            \"Constant Wave at {} Hz offset from the center \"\n            \"of a bin by {} Hz.\".format(freq, center_bin_offset_freq)\n        )\n        self.Progress(\n            \"CW scale: {}, Noise scale: {}, eq gain: {}, fft shift: {}\".format(cw_scale, awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(\n            self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=freq, fft_shift=fft_shift, gain=gain\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        beam_quant_gain = 1.0 / ants\n        self.Step(\"Set beamformer quantiser gain for selected beam to {}\".format(beam_quant_gain))\n        set_beam_quant_gain(self, beam, beam_quant_gain)\n\n        beam_dict = {}\n        beam_pol = beam[-1]\n        for label in labels:\n            if label.find(beam_pol) != -1:\n                beam_dict[label] = 0.0\n\n        # TODO: Currently setting weights is broken\n        # self.Progress(\"Only one antenna gain is set to 1, the reset are set to zero\")\n        ref_input = np.random.randint(ants)\n        ref_input = 1\n        # Find reference input label\n        for key in beam_dict:\n            if int(filter(str.isdigit, key)) == ref_input:\n                ref_input_label = key\n                break\n        self.Step(\"{} used as a randomised reference input for this test\".format(ref_input_label))\n        weight = 1.0\n        # beam_dict = populate_beam_dict_idx(self, ref_input, weight, beam_dict)\n        beam_dict = populate_beam_dict(self, -1, weight, beam_dict)\n        try:\n            # Currently setting weights is broken\n            bf_raw, bf_flags, bf_ts, in_wgts = capture_beam_data(self, beam, beam_dict, capture_time=_capture_time)\n            # bf_raw, bf_flags, bf_ts, in_wgts = capture_beam_data(self, beam, capture_time=0.1)\n            # Close any KAT SDP ingest nodes\n            stop_katsdpingest_docker(self)\n        except TypeError:\n            errmsg = (\n                \"Failed to capture beam data: %s\\n\\n Confirm that Docker container is \"\n                \"running and also confirm the igmp version = 2 \" % str(e)\n            )\n            self.Error(errmsg, exc_info=True)\n            return False\n\n        flags = bf_flags[start_substream : start_substream + n_substrms_to_cap_m]\n        # self.Step('Finding missed heaps for all partitions.')\n        if flags.size == 0:\n            self.logger.warning(\"Beam data empty. Capture failed. Retrying...\")\n            self.Failed(\"Beam data empty. Capture failed. Retrying...\")\n        else:\n            missed_err = False\n            for part in flags:\n                missed_heaps = np.where(part > 0)[0]\n                missed_perc = missed_heaps.size / part.size\n                perc = 0.50\n                if missed_perc > perc:\n                    self.Progress(\"Missed heap percentage = {}%%\".format(missed_perc * 100))\n                    self.Progress(\"Missed heaps = {}\".format(missed_heaps))\n                    self.logger.warning(\"Beam captured missed more than %s%% heaps. Retrying...\" % (perc * 100))\n                    self.Failed(\"Beam captured missed more than %s%% heaps. Retrying...\" % (perc * 100))\n            # Print missed heaps\n            idx = start_substream\n            for part in flags:\n                missed_heaps = np.where(part > 0)[0]\n                if missed_heaps.size > 0:\n                    self.logger.info(\"Missed heaps for substream {} at heap indexes {}\".format(idx, missed_heaps))\n                idx += 1\n            # Combine all missed heap flags. These heaps will be discarded\n            flags = np.sum(flags, axis=0)\n            # Find longest run of uninterrupted data\n            # Create an array that is 1 where flags is 0, and pad each end with an extra 0.\n            iszero = np.concatenate(([0], np.equal(flags, 0).view(np.int8), [0]))\n            absdiff = np.abs(np.diff(iszero))\n            # Runs start and end where absdiff is 1.\n            ranges = np.where(absdiff == 1)[0].reshape(-1, 2)\n            # Find max run\n            max_run = ranges[np.argmax(np.diff(ranges))]\n            bf_raw_strt = max_run[0] * spectra_per_heap\n            bf_raw_stop = max_run[1] * spectra_per_heap\n            bf_raw = bf_raw[:, bf_raw_strt:bf_raw_stop, :]\n            bf_ts = bf_ts[bf_raw_strt:bf_raw_stop]\n\n            np.save(\"skarab_bf_data_plus.np\", bf_raw)\n            # return True\n            from bf_time_analysis import analyse_beam_data\n\n            analyse_beam_data(\n                bf_raw,\n                dsim_settings=[freq, cw_scale, awgn_scale],\n                cbf_settings=[fft_shift, gain],\n                do_save=True,\n                spectra_use=\"all\",\n                chans_to_use=n_substrms_to_cap_m * ch_per_substream,\n                xlim=[20, 21],\n                dsim_factor=1.0,\n                ref_input_label=ref_input_label,\n                bandwidth=bw,\n            )\n\n            # aqf_plot_channels(beam_data[0:50, cw_ch-strt_ch_idx],\n            #                  plot_filename='{}/{}_beam_cw_offset_from_centerbin_{}.png'.format(self.logs_path,\n            #                    self._testMethodName, beam),\n            #                  plot_title=('Beam = {}\\n'\n            #                    'Input = CW offset by {} Hz from the center of bin {}'\n            #                    .format(beam, center_bin_offset_freq, cw_ch)),\n            #                  log_dynamic_range=None, #90, log_normalise_to=1,\n            #                  ylabel='Beam Output',\n            #                  xlabel='Samples')\n\n    def _test_group_delay(self, beam_idx=0):\n        \"\"\"\n\n        Parameters\n        ----------\n        manual : Manually set the offset from the future_dump point.\n        manual_offset : Offset in adc sample clocks.\n        future_dump : Dump in which impulse is expected\n\n\n        Returns\n        -------\n        \"\"\"\n\n        try:\n            output = subprocess.check_output([\"docker\", \"run\", \"hello-world\"])\n            self.logger.info(output)\n        except subprocess.CalledProcessError:\n            errmsg = \"Cannot connect to the Docker daemon. Is the docker daemon running on this host?\"\n            self.Failed(errmsg)\n            return False\n\n        try:\n            # Set custom source names\n            # local_src_names = self.cam_sensors.custom_input_labels\n            # reply, informs = self.corr_fix.katcp_rct.req.input_labels(*local_src_names)\n            # assert reply.reply_ok()\n            # labels = reply.arguments[1:]\n            labels = self.cam_sensors.input_labels\n            beams = [\"tied-array-channelised-voltage.0x\", \"tied-array-channelised-voltage.0y\"]\n            running_instrument = self.instrument\n            assert running_instrument is not False\n            # msg = 'Running instrument currently does not have beamforming capabilities.'\n            # assert running_instrument.endswith('1k'), msg\n            self.Step(\"Discontinue any capturing of %s and %s, if active.\" % (beams[0], beams[1]))\n            reply, informs = self.corr_fix.katcp_rct.req.capture_stop(beams[0])\n            assert reply.reply_ok(), str(reply)\n            reply, informs = self.corr_fix.katcp_rct.req.capture_stop(beams[1])\n            assert reply.reply_ok(), str(reply)\n            sync_time = self.cam_sensors.get_value(\"sync_time\")\n\n            # Get instrument parameters\n            bw = self.cam_sensors.get_value(\"bandwidth\")\n            nr_ch = self.cam_sensors.get_value(\"n_chans\")\n            ants = self.cam_sensors.get_value(\"n_ants\")\n            ch_list = self.cam_sensors.ch_center_freqs\n            ch_bw = ch_list[1]\n            scale_factor_timestamp = self.cam_sensors.get_value(\"scale_factor_timestamp\")\n            dsim_factor = float(self.conf_file[\"instrument_params\"][\"sample_freq\"]) / scale_factor_timestamp\n            substreams = self.cam_sensors.get_value(\"n_xengs\")\n        except AssertionError:\n            errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            errmsg = \"Exception\"\n            self.Error(errmsg, exc_info=True)\n            return False\n\n        self.Progress(\"Bandwidth = {}Hz\".format(bw * dsim_factor))\n        self.Progress(\"Number of channels = {}\".format(nr_ch))\n        self.Progress(\"Channel spacing = {}Hz\".format(ch_bw * dsim_factor))\n\n        beam = beams[beam_idx]\n        try:\n            beam_name = beam.replace(\"-\", \"_\").replace(\".\", \"_\")\n            beam_ip, beam_port = self.cam_sensors.get_value(beam_name + \"_destination\").split(\":\")\n            beam_ip = beam_ip.split(\"+\")[0]\n            start_beam_ip = beam_ip\n            n_substrms_to_cap_m = int(self.conf_file[\"beamformer\"][\"substreams_to_capture\"])\n            start_substream = int(self.conf_file[\"beamformer\"][\"start_substream_idx\"])\n            if start_substream + n_substrms_to_cap_m > substreams:\n                errmsg = (\n                    \"Substream start + substreams to process \"\n                    \"is more than substreams available: {}. \"\n                    \"Fix in test configuration file\".format(substeams)\n                )\n                self.Failed(errmsg)\n                return False\n            ticks_between_spectra = self.cam_sensors.get_value(\"antenna_channelised_voltage_n_samples_between_spectra\")\n            assert isinstance(ticks_between_spectra, int)\n            spectra_per_heap = self.cam_sensors.get_value(beam_name + \"_spectra_per_heap\")\n            assert isinstance(spectra_per_heap, int)\n            ch_per_substream = self.cam_sensors.get_value(beam_name + \"_n_chans_per_substream\")\n            assert isinstance(ch_per_substream, int)\n        except AssertionError:\n            errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            errmsg = \"Exception\"\n            self.Error(errmsg, exc_info=True)\n            return False\n\n        # Compute the start IP address according to substream start index\n        beam_ip = int2ip(ip2int(beam_ip) + start_substream)\n        # Compute spectrum parameters\n        strt_ch_idx = start_substream * ch_per_substream\n        strt_freq = ch_list[strt_ch_idx] * dsim_factor\n        self.Step(\"Start a KAT SDP docker ingest node for beam captures\")\n        docker_status = start_katsdpingest_docker(\n            self,\n            beam_ip,\n            beam_port,\n            n_substrms_to_cap_m,\n            nr_ch,\n            ticks_between_spectra,\n            ch_per_substream,\n            spectra_per_heap,\n        )\n        if docker_status:\n            self.Progress(\n                \"KAT SDP Ingest Node started. Capturing {} substream/s \"\n                \"starting at {}\".format(n_substrms_to_cap_m, beam_ip)\n            )\n        else:\n            self.Failed(\"KAT SDP Ingest Node failed to start\")\n        # Create a katcp client to connect to katcpingest\n        if os.uname()[1] == \"cmc2\":\n            ingst_nd = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node_cmc2\"]\n        elif os.uname()[1] == \"cmc3\":\n            ingst_nd = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node_cmc3\"]\n        else:\n            ingst_nd = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node\"]\n        ingst_nd_p = self.corr_fix._test_config_file[\"beamformer\"][\"ingest_node_port\"]\n        _timeout = 10\n        try:\n            import katcp\n\n            ingest_kcp_client = katcp.BlockingClient(ingst_nd, ingst_nd_p)\n            ingest_kcp_client.setDaemon(True)\n            ingest_kcp_client.start()\n            self.addCleanup(ingest_kcp_client.stop)\n            is_connected = ingest_kcp_client.wait_connected(_timeout)\n            if not is_connected:\n                errmsg = \"Could not connect to %s:%s, timed out.\" % (ingst_nd, ingst_nd_p)\n                ingest_kcp_client.stop()\n                raise RuntimeError(errmsg)\n        except Exception:\n            self.Error(\"Could not connect to katcp client\", exc_info=True)\n\n        beam_quant_gain = 1.0 / ants\n        # self.Step(\"Set beamformer quantiser gain for selected beam to {}\".format(beam_quant_gain))\n        # set_beam_quant_gain(self, beam, beam_quant_gain)\n\n        beam_dict = {}\n        beam_pol = beam[-1]\n        for label in labels:\n            if label.find(beam_pol) != -1:\n                beam_dict[label] = 0.0\n\n        # Currently setting weights is broken\n        # self.Progress(\"Only one antenna gain is set to 1, the reset are set to zero\")\n        ref_input = np.random.randint(ants)\n        ref_input = 1\n        # Find reference input label\n        for key in beam_dict:\n            if int(filter(str.isdigit, key)) == ref_input:\n                ref_input_label = key\n                break\n        self.Step(\"{} used as a randomised reference input for this test\".format(ref_input_label))\n        weight = 1.0\n        beam_dict = populate_beam_dict_idx(self, ref_input, weight, beam_dict)\n        # To Do: set beam weights\n\n        def get_beam_data():\n            try:\n                bf_raw, bf_flags, bf_ts, in_wgts = capture_beam_data(\n                    self, beam, ingest_kcp_client=ingest_kcp_client, stop_only=True\n                )\n            except Exception:\n                errmsg = (\n                    \"Failed to capture beam data: %s\\n\\n Confirm that Docker container is \"\n                    \"running and also confirm the igmp version = 2 \" % str(e)\n                )\n                self.Error(errmsg, exc_info=True)\n                return False\n\n            flags = bf_flags[start_substream : start_substream + n_substrms_to_cap_m]\n            # self.Step('Finding missed heaps for all partitions.')\n            if flags.size == 0:\n                self.logger.warning(\"Beam data empty. Capture failed.\")\n                return None, None\n            else:\n                for part in flags:\n                    missed_heaps = np.where(part > 0)[0]\n                    missed_perc = missed_heaps.size / part.size\n                    perc = 0.50\n                    if missed_perc > perc:\n                        self.Progress(\"Missed heap percentage = {}%%\".format(missed_perc * 100))\n                        self.Progress(\"Missed heaps = {}\".format(missed_heaps))\n                        self.Failed(\"Beam captured missed more than %s%% heaps. Retrying...\" % (perc * 100))\n                        return None, None\n            # Print missed heaps\n            idx = start_substream\n            for part in flags:\n                missed_heaps = np.where(part > 0)[0]\n                if missed_heaps.size > 0:\n                    self.logger.info(\"Missed heaps for substream {} at heap indexes {}\".format(idx, missed_heaps))\n                idx += 1\n            # Combine all missed heap flags. These heaps will be discarded\n            flags = np.sum(flags, axis=0)\n            # Find longest run of uninterrupted data\n            # Create an array that is 1 where flags is 0, and pad each end with an extra 0.\n            iszero = np.concatenate(([0], np.equal(flags, 0).view(np.int8), [0]))\n            absdiff = np.abs(np.diff(iszero))\n            # Runs start and end where absdiff is 1.\n            ranges = np.where(absdiff == 1)[0].reshape(-1, 2)\n            # Find max run\n            max_run = ranges[np.argmax(np.diff(ranges))]\n            bf_raw_strt = max_run[0] * spectra_per_heap\n            bf_raw_stop = max_run[1] * spectra_per_heap\n            bf_raw = bf_raw[:, bf_raw_strt:bf_raw_stop, :]\n            bf_ts = bf_ts[bf_raw_strt:bf_raw_stop]\n            return bf_raw, bf_ts\n\n        def load_dsim_impulse(load_timestamp, offset=0):\n            self.dhost.registers.src_sel_cntrl.write(src_sel_0=2)\n            self.dhost.registers.src_sel_cntrl.write(src_sel_1=0)\n            self.dhost.registers.impulse_delay_correction.write(reg=16)\n            load_timestamp = load_timestamp + offset\n            # lt_abs_t = datetime.fromtimestamp(\n            #    sync_time + load_timestamp / scale_factor_timestamp)\n            # curr_t = datetime.fromtimestamp(time.time())\n            # self.Progress('Current time      = {}:{}.{}'.format(curr_t.minute,\n            #                                            curr_t.second,\n            #                                            curr_t.microsecond))\n            # self.Progress('Impulse load time = {}:{}.{}'.format(lt_abs_t.minute,\n            #                                            lt_abs_t.second,\n            #                                            lt_abs_t.microsecond))\n            # if ((abs(curr_t.minute - lt_abs_t.minute) > 1) and\n            #    (abs(curr_t.second - lt_abs_t.second) > 1)):\n            #    self.Failed('Timestamp drift too big. Resynchronise digitiser simulator.')\n            # Digitiser simulator local clock factor of 8 slower\n            # (FPGA clock = sample clock / 8).\n            load_timestamp = load_timestamp / 8.0\n            if not load_timestamp.is_integer():\n                self.Failed(\"Timestamp received in accumulation not divisible\" \" by 8: {:.15f}\".format(\n                    load_timestamp))\n            load_timestamp = int(load_timestamp)\n            reg_size = 32\n            load_ts_lsw = load_timestamp & (pow(2, reg_size) - 1)\n            load_ts_msw = load_timestamp >> reg_size\n\n            # dsim_loc_lsw = self.dhost.registers.local_time_lsw.read()['data']['reg']\n            # dsim_loc_msw = self.dhost.registers.local_time_msw.read()['data']['reg']\n            # dsim_loc_time = dsim_loc_msw * pow(2,reg_size) + dsim_loc_lsw\n            # print 'timestamp difference: {}'.format((load_timestamp - dsim_loc_time)*8/dump['scale_factor_timestamp'])\n            self.dhost.registers.impulse_load_time_lsw.write(reg=load_ts_lsw)\n            self.dhost.registers.impulse_load_time_msw.write(reg=load_ts_msw)\n\n        def get_dsim_mcount(spectra_ref_mcount):\n            # Get the current mcount and shift it to the start of a spectra\n            dsim_loc_lsw = self.dhost.registers.local_time_lsw.read()[\"data\"][\"reg\"]\n            dsim_loc_msw = self.dhost.registers.local_time_msw.read()[\"data\"][\"reg\"]\n            reg_size = 32\n            dsim_loc_time = dsim_loc_msw * pow(2, reg_size) + dsim_loc_lsw\n            if not (spectra_ref_mcount / 8.0).is_integer():\n                self.Failed(\"Spectra reference mcount is not divisible\" \" by 8: {:.15f}\".format(\n                    spectra_ref_mcount))\n            dsim_loc_time = dsim_loc_time * 8\n            # Shift current dsim time to the edge of a spectra\n            dsim_spectra_time = dsim_loc_time - (\n                dsim_loc_time - spectra_ref_mcount) % ticks_between_spectra\n            return dsim_spectra_time\n\n        dsim_set_success = set_input_levels(self, awgn_scale=0.0, cw_scale=0.0, freq=0, fft_shift=0, gain=\"32767+0j\")\n        self.dhost.outputs.out_1.scale_output(0)\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        out_func = []\n        num_pulse_caps = 500\n        # num_pulse_int = 2\n        # pulse_step must be divisible by 8\n        pulse_step = 16\n        points_around_trg = 16\n        chan_str = 0\n        chan_stp = 511\n        load_lead_time = 0.01\n        load_lead_mcount = 8 * int(load_lead_time * scale_factor_timestamp / 8)\n        for pulse_cap in range(num_pulse_caps):\n            beam_retries = 5\n            while beam_retries > 0:\n                # mcount_list = []\n                beam_retries -= 1\n                # Get an mcount at the start of a spectrum\n                _ = capture_beam_data(self, beam, ingest_kcp_client=ingest_kcp_client, start_only=True)\n                time.sleep(0.005)\n                bf_raw, bf_ts = get_beam_data()\n                if np.all(bf_raw) is None or np.all(bf_ts) is None:\n                    break\n                spectra_ref_mcount = bf_ts[-1]\n                # Start beam capture\n                _ = capture_beam_data(self, beam, ingest_kcp_client=ingest_kcp_client, start_only=True)\n                # Get current mcount\n                # for pulse_int in range(num_pulse_int):\n                curr_mcount = get_dsim_mcount(spectra_ref_mcount)\n                future_mcount = load_lead_mcount + curr_mcount + pulse_step * pulse_cap\n                load_dsim_impulse(future_mcount)\n                # mcount_list.append(future_mcount)\n                # while get_dsim_mcount(spectra_ref_mcount) < future_mcount:\n                time.sleep(load_lead_time)\n                bf_raw, bf_ts = get_beam_data()\n                if np.all(bf_raw) is not None and np.all(bf_ts) is not None:\n                    break\n            # beam_retries = 5\n            # while beam_retries > 0:\n            #    beam_retries -= 1\n            #    _ = capture_beam_data(self, beam, ingest_kcp_client=ingest_kcp_client, start_only=True)\n            #    time.sleep(0.01)\n            #    bf_raw, bf_ts = get_beam_data()\n            #    if np.all(bf_raw) != None and np.all(bf_ts) != None:\n            #        curr_mcount = bf_ts[-1]\n            #        future_mcount = 0.5 * scale_factor_timestamp + curr_mcount + pulse_step*pulse_cap\n            #        future_mcount = 8*int(future_mcount/8)\n            #        load_dsim_impulse(future_mcount)\n            #        _ = capture_beam_data(self, beam, ingest_kcp_client=ingest_kcp_client, start_only=True)\n            #        time.sleep(0.2)\n            #        bf_raw, bf_ts = get_beam_data()\n            #    if np.all(bf_raw) != None and np.all(bf_ts) != None:\n            #        break\n            else:\n                self.Failed(\"Beam data capture failed.\")\n                break\n            # num_found = 0\n            # captured_list = []\n            # for trgt_mcount in mcount_list[:-1]:\n            try:\n                assert future_mcount\n            except Exception:\n                return False\n            trgt_spectra_idx = np.where(bf_ts > future_mcount)[0]\n            if trgt_spectra_idx.size == 0:\n                self.logger.warning(\n                    \"Target spectra timestamp too late by {} seconds\".format(\n                        (future_mcount - bf_ts[-1]) / scale_factor_timestamp\n                    )\n                )\n            elif trgt_spectra_idx.size == bf_ts.size:\n                self.logger.warning(\n                    \"Target spectra timestamp too early by {} seconds\".format(\n                        (bf_ts[0] - future_mcount) / scale_factor_timestamp\n                    )\n                )\n            else:\n                trgt_spectra_idx = trgt_spectra_idx[0] - 1\n                # num_found += 1\n                self.Progress(\n                    \"Target specra found at index {} of beam capture \"\n                    \"containing {} spectra\".format(trgt_spectra_idx, bf_ts.shape[0])\n                )\n                # trgt_cap_list = []\n                for i in range(trgt_spectra_idx - points_around_trg, trgt_spectra_idx + 1):\n                    spectra_mean_val = np.sum(np.abs(complexise(bf_raw[chan_str:chan_stp, i, :]))) / (\n                        chan_stp - chan_str\n                    )\n                    spectra_ts = bf_ts[i]\n                    ts_delta = int(spectra_ts) - future_mcount\n                    # trgt_cap_list.append([ts_delta,spectra_mean_val])\n                    out_func.append([ts_delta, spectra_mean_val])\n                # captured_list.append(trgt_cap_list)\n                # print ('{}:{}'.format(ts_delta,spectra_mean_val))\n            # import IPython;IPython.embed()\n        else:\n            # Remove any values which don't make sense, these happend when a capture missed the target mcount\n            rem_index = np.where((np.sum(out_func, axis=1)) > 30000)\n            out_func = np.delete(out_func, rem_index, axis=0)\n            x = [x[0] for x in out_func]\n            y = [y[1] for y in out_func]\n            plt.scatter(x, y)\n            plt.show()\n            # import IPython;IPython.embed()\n\n        # Close any KAT SDP ingest nodes\n        try:\n            if ingest_kcp_client:\n                ingest_kcp_client.stop()\n        except BaseException:\n            pass\n        stop_katsdpingest_docker(self)\n\n        # Check ADC snapshot for pulse\n        # self.correlator.est_synch_epoch()\n        # sync_time = self.cam_sensors.get_value('sync_time')\n        # bf_raw, bf_ts = get_beam_data()\n        # curr_mcount = bf_ts[-1]\n        # future_mcount = 1 * scale_factor_timestamp + curr_mcount\n        # load_dsim_impulse(future_mcount)\n        # unix_time = sync_time + (future_mcount/scale_factor_timestamp)\n        # error_mcount = self.correlator.mcnt_from_time(unix_time) - future_mcount\n        # unix_time = sync_time + (future_mcount-error_mcount-4000)/scale_factor_timestamp\n        # a = self.correlator.fops.get_adc_snapshot(unix_time=unix_time)[labels[1]].data\n        # print time.time()\n        # print unix_time\n        # print self.correlator.mcnt_from_time(unix_time) - future_mcount\n        # print np.argmax(a)\n\n    def _bf_efficiency(self):\n\n        local_src_names = self.cam_sensors.custom_input_labels\n        try:\n            reply, informs = self.katcp_req.capture_stop(\"beam_0x\", timeout=60)\n            reply, informs = self.katcp_req.capture_stop(\"beam_0y\", timeout=60)\n            reply, informs = self.katcp_req.capture_stop(\"c856M4k\", timeout=60)\n            reply, informs = self.katcp_req.input_labels(*local_src_names)\n            if reply.reply_ok():\n                labels = reply.arguments[1:]\n            else:\n                raise Exception\n        except Exception:\n            self.Failed(e)\n            return\n        bw = self.cam_sensors.get_value(\"bandwidth\")\n        ch_list = self.cam_sensors.ch_center_freqs\n        nr_ch = self.n_chans_selected\n\n        # Start of test. Setting required partitions and center frequency\n        partitions = 1\n        part_size = bw / 16\n        target_cfreq = bw + bw * 0.5\n        target_pb = partitions * part_size\n        ch_bw = bw / nr_ch\n        beams = (\"beam_0x\", \"beam_0y\")\n        beam = beams[1]\n\n        # Set beamformer quantiser gain for selected beam to 1\n        set_beam_quant_gain(self, beam, 1)\n\n        if \"4k\" in self.instrument:\n            # 4K\n            awgn_scale = 0.032\n            gain = \"226+0j\"\n            fft_shift = 511\n        else:\n            # 32K\n            awgn_scale = 0.063\n            gain = \"344+0j\"\n            fft_shift = 4095\n\n        self.Step(\n            \"Digitiser simulator configured to generate Gaussian noise, \"\n            \"with scale: {}, eq gain: {}, fft shift: {}\".format(awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(self, awgn_scale=awgn_scale, cw_scale=0.0, fft_shift=fft_shift, gain=gain)\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        beam_pol = beam[-1]\n        for label in labels:\n            if label.find(beam_pol) != -1:\n                inp = label\n                break\n        try:\n            reply, informs = self.katcp_req.quantiser_snapshot(inp, timeout=60)\n        except Exception:\n            self.Failed(\"Failed to grab quantiser snapshot.\")\n        quant_snap = [eval(v) for v in (reply.arguments[1:][1:])]\n        try:\n            reply, informs = self.katcp_req.adc_snapshot(inp, timeout=60)\n        except Exception:\n            self.Failed(\"Failed to grab adc snapshot.\")\n        fpga = self.correlator.fhosts[0]\n        adc_data = fpga.get_adc_snapshots()[\"p0\"].data\n        p_std = np.std(adc_data)\n        p_levels = p_std * 512\n        aqf_plot_histogram(\n            adc_data,\n            plot_filename=\"{}/{}_adc_hist_{}.png\".format(self.logs_path, self._testMethodName, inp),\n            plot_title=(\n                \"ADC Histogram for input {}\\nNoise Profile: \"\n                \"Std Dev: {:.3f} equates to {:.1f} levels \"\n                \"toggling.\".format(inp, p_std, p_levels)\n            ),\n            caption=\"ADC input histogram for beamformer efficiency test, \"\n            \"with the digitiser simulator noise scale at {}, \"\n            \"quantiser gain at {} and fft shift at {}.\".format(awgn_scale, gain, fft_shift),\n            bins=256,\n            ranges=(-1, 1),\n        )\n        p_std = np.std(quant_snap)\n        aqf_plot_histogram(\n            np.abs(quant_snap),\n            plot_filename=\"{}/{}_quant_hist_{}.png\".format(self.logs_path, self._testMethodName, inp),\n            plot_title=(\"Quantiser Histogram for input {}\\n \" \"Standard Deviation: {:.3f}\".format(inp, p_std)),\n            caption=\"Quantiser histogram for beamformer efficiency test, \"\n            \"with the digitiser simulator noise scale at {}, \"\n            \"quantiser gain at {} and fft shift at {}.\".format(awgn_scale, gain, fft_shift),\n            bins=64,\n            ranges=(0, 1.5),\n        )\n\n        beam_dict = {}\n        beam_pol = beam[-1]\n        for label in labels:\n            if label.find(beam_pol) != -1:\n                beam_dict[label] = 0.0\n\n        # Only one antenna gain is set to 1, this will be used as the reference\n        # input level\n        weight = 1.0\n        beam_dict = populate_beam_dict(self, 1, weight, beam_dict)\n        try:\n            bf_raw, cap_ts, bf_ts, in_wgts, pb, cf = capture_beam_data(\n                self, beam, beam_dict, target_pb, target_cfreq, capture_time=0.3\n            )\n        except TypeError:\n            errmsg = \"Failed to capture beam data:\"\n            self.Failed(errmsg)\n            self.logger.info(errmsg)\n            return\n        Aqf.hop(\"Packaging beamformer data.\")\n        num_caps = np.shape(bf_raw)[1]\n        cap = [0] * num_caps\n        cap_idx = 0\n        for i in range(0, num_caps):\n            if cap_ts[cap_idx] == bf_ts[i]:\n                cap[cap_idx] = complexise(bf_raw[:, i, :])\n                cap_idx += 1\n        del bf_raw\n        cap = np.asarray(cap[:cap_idx])\n        # Output of beamformer is a voltage, get the power\n        cap = np.power(np.abs(cap), 2)\n        nr_ch = len(cap)\n        self.Step(\"Calculating time series mean.\")\n        ch_mean = cap.mean(axis=0)\n        self.Step(\"Calculating time series standard deviation\")\n        ch_std = cap.std(axis=0, ddof=1)\n        ch_bw = self.cam_sensors.delta_f\n        acc_time = self.cam_sensors.fft_period\n        sqrt_bw_at = np.sqrt(ch_bw * acc_time)\n        self.Step(\"Calculating channel efficiency.\")\n        eff = 1 / ((ch_std / ch_mean) * sqrt_bw_at)\n        self.Step(\"Beamformer mean efficiency for {} channels = {:.2f}%\".format(nr_ch, 100 * eff.mean()))\n        plt_filename = \"{}/{}_beamformer_efficiency.png\".format(self.logs_path, self._testMethodName)\n        plt_title = \"Beamformer Efficiency per Channel\\n \" \"Mean Efficiency = {:.2f}%\".format(100 * eff.mean())\n        caption = (\n            \"Beamformer efficiency per channel calculated over {} samples \"\n            \"with a channel bandwidth of {:.2f}Hz and a FFT window length \"\n            \"of {:.3f} micro seconds per sample.\".format(cap_idx, ch_bw, acc_time * 1000000.0)\n        )\n        aqf_plot_channels(\n            eff * 100,\n            plt_filename,\n            plt_title,\n            caption=caption,\n            log_dynamic_range=None,\n            hlines=95,\n            ylimits=(90, 105),\n            plot_type=\"eff\",\n        )\n\n    def _timestamp_accuracy(self, manual=False, manual_offset=0, future_dump=3):\n        \"\"\"\n\n        Parameters\n        ----------\n        manual : Manually set the offset from the future_dump point.\n        manual_offset : Offset in adc sample clocks.\n        future_dump : Dump in which impulse is expected\n\n        Returns\n        -------\n\n        \"\"\"\n\n        def load_dsim_impulse(load_timestamp, offset=0):\n            self.dhost.registers.src_sel_cntrl.write(src_sel_0=2)\n            self.dhost.registers.src_sel_cntrl.write(src_sel_1=0)\n            self.dhost.registers.impulse_delay_correction.write(reg=16)\n            load_timestamp = load_timestamp + offset\n            lt_abs_t = datetime.datetime.fromtimestamp(sync_time + load_timestamp / scale_factor_timestamp)\n            print \"Impulse load time = {}:{}.{}\".format(lt_abs_t.minute, lt_abs_t.second, lt_abs_t.microsecond)\n            print \"Number of dumps in future = {:.10f}\".format((load_timestamp - dump_ts) / dump_ticks)\n            # Digitiser simulator local clock factor of 8 slower\n            # (FPGA clock = sample clock / 8).\n            load_timestamp = load_timestamp / 8\n            if not load_timestamp.is_integer():\n                self.Failed(\"Timestamp received in accumulation not divisible\" \" by 8: {:.15f}\".format(load_timestamp))\n            load_timestamp = int(load_timestamp)\n            reg_size = 32\n            load_ts_lsw = load_timestamp & (pow(2, reg_size) - 1)\n            load_ts_msw = load_timestamp >> reg_size\n\n            # dsim_loc_lsw = self.dhost.registers.local_time_lsw.read()['data']['reg']\n            # dsim_loc_msw = self.dhost.registers.local_time_msw.read()['data']['reg']\n            # dsim_loc_time = dsim_loc_msw * pow(2,reg_size) + dsim_loc_lsw\n            # print 'timestamp difference: {}'.format((load_timestamp - dsim_loc_time)*8/dump['scale_factor_timestamp'])\n            self.dhost.registers.impulse_load_time_lsw.write(reg=load_ts_lsw)\n            self.dhost.registers.impulse_load_time_msw.write(reg=load_ts_msw)\n\n        # try:\n        #     reply, informs = self.katcp_req.accumulation_length(1, timeout=60)\n        #     if not reply.reply_ok():\n        #         raise Exception\n        # except:\n        #     errmsg = 'Failed to set accumulation time withing {}s'.format(\n        #         reply)\n        #     self.Error(errmsg, exc_info=True)\n        #     self.Failed(errmsg)\n        #     return False\n\n        dsim_set_success = set_input_levels(\n            self.corr_fix, self.dhost, awgn_scale=0.0, cw_scale=0.0, freq=100000000, fft_shift=0, gain=\"32767+0j\"\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        self.dhost.outputs.out_1.scale_output(0)\n        dump = self.receiver.get_clean_dump()\n        baseline_lookup = get_baselines_lookup(self, dump)\n        sync_time = self.cam_sensors.get_values(\"synch_epoch\")\n        scale_factor_timestamp = self.cam_sensors.get_values(\"scale_factor_timestamp\")\n        inp = self.cam_sensors.get_values(\"input_labels\")[0][0]\n        inp_autocorr_idx = baseline_lookup[(inp, inp)]\n        # FFT input sliding window size = 8 spectra\n        # fft_sliding_window = dump['n_chans'].value * 2 * 8\n        # Get number of ticks per dump and ensure it is divisible by 8 (FPGA\n        # clock runs 8 times slower)\n        dump_ticks = self.cam_sensors.get_values(\"int_time\") * self.cam_sensors.get_values(\"adc_sample_rate\")\n        # print dump_ticks\n        dump_ticks = self.cam_sensors.get_values(\"n_accs\") * self.cam_sensors.get_values(\"n_chans\") * 2\n        # print dump_ticks\n        # print ['adc_sample_rate'].value\n        # print dump['timestamp']\n        if not (dump_ticks / 8.0).is_integer():\n            self.Failed(\"Number of ticks per dump is not divisible\" \" by 8: {:.3f}\".format(dump_ticks))\n        # Create a linear array spaced by 8 for finding dump timestamp edge\n        tick_array = np.linspace(-dump_ticks / 2, dump_ticks / 2, num=(dump_ticks / 8) + 1)\n        # num=fft_sliding_window+1)\n        # Offset into tick array to step impulse.\n        tckar_idx = len(tick_array) / 2\n        tckar_upper_idx = len(tick_array) - 1\n        tckar_lower_idx = 0\n        future_ticks = dump_ticks * future_dump\n        found = False\n        # prev_imp_loc = 0\n        first_run = True\n        split_found = False\n        single_step = False\n        while not found:\n            if manual:\n                found = True\n                offset = manual_offset\n            else:\n                offset = tick_array[int(tckar_idx)]\n            dump = self.receiver.get_clean_dump()\n            print dump[\"timestamp\"]\n            dump_ts = dump[\"timestamp\"]\n            dump_abs_t = datetime.datetime.fromtimestamp(sync_time + dump_ts / scale_factor_timestamp)\n            print \"Start dump time = {}:{}.{}\".format(dump_abs_t.minute, dump_abs_t.second, dump_abs_t.microsecond)\n            load_timestamp = dump_ts + future_ticks\n            load_dsim_impulse(load_timestamp, offset)\n            dump_list = []\n            cnt = 0\n            for i in range(future_dump):\n                cnt += 1\n                dump = self.receiver.data_queue.get()\n                print dump[\"timestamp\"]\n                dval = dump[\"xeng_raw\"]\n                auto_corr = dval[:, inp_autocorr_idx, :]\n                curr_ts = dump[\"timestamp\"]\n                delta_ts = curr_ts - dump_ts\n                dump_ts = curr_ts\n                if delta_ts != dump_ticks:\n                    self.Failed(\n                        \"Accumulation dropped, Expected timestamp = {}, \"\n                        \"received timestamp = {}\".format(dump_ts + dump_ticks, curr_ts)\n                    )\n                print \"Maximum value found in dump {} = {}, average = {}\".format(\n                    cnt, np.max(auto_corr), np.average(auto_corr)\n                )\n                dump_list.append(dval)\n            # Find dump containing impulse, check that other dumps are empty.\n            # val_found = 0\n            auto_corr = []\n            auto_corr_avg = []\n            dumps_nzero = 0\n            for idx in range(len(dump_list)):\n                dmp = dump_list[idx][:, inp_autocorr_idx, :]\n                auto_corr.append(dmp)\n                auto_corr_std = np.std(dmp)\n                auto_corr_avg_val = np.average(dmp)\n                if auto_corr_avg_val > 0:\n                    print auto_corr_avg_val\n                    print auto_corr_std\n                    print auto_corr_avg_val - auto_corr_std\n                    if abs(auto_corr_avg_val - auto_corr_std) < (auto_corr_avg_val * 0.4):\n                        dumps_nzero += 1\n                        auto_corr_avg.append(auto_corr_avg_val)\n                    else:\n                        dumps_nzero = 3\n                        auto_corr_avg.append(0)\n                else:\n                    auto_corr_avg.append(0)\n            # imp_loc = np.argmax(auto_corr_avg) + 1\n            imp_loc = next((i for i, x in enumerate(auto_corr_avg) if x), None) + 1\n            # if (dumps_nzero == 1) and split_found:\n            #    single_step = True\n            if dumps_nzero == 2:\n                self.Step(\"Two dumps found containing impulse.\")\n                # Only start stepping by one once the split is close\n                # split_found = True\n            elif dumps_nzero > 2:\n                self.Failed(\"Invalid data found in dumps.\")\n                # for dmp in auto_corr:\n                #    plt.plot(dmp)\n                # plt.show()\n            # Set the index into the time stamp offset array\n            print\n            print\n            if first_run:\n                tckar_idx_prev = tckar_idx\n                first_run = False\n                if imp_loc == future_dump - 1:\n                    tckar_idx = tckar_upper_idx\n                elif imp_loc == future_dump:\n                    tckar_idx = tckar_lower_idx\n                else:\n                    self.Failed(\"Impulse not where expected.\")\n                    found = True\n            else:\n                idx_diff = abs(tckar_idx_prev - tckar_idx)\n                tckar_idx_prev = tckar_idx\n                if single_step and (dumps_nzero == 1):\n                    found = True\n                    print \"Edge of dump found at offset {} (ticks)\".format(offset)\n                elif ((idx_diff < 10) and (dumps_nzero == 2)) or single_step:\n                    single_step = True\n                    tckar_idx += 1\n                elif imp_loc == future_dump - 1:\n                    tckar_lower_idx = tckar_idx\n                    tckar_idx = tckar_idx + (tckar_upper_idx - tckar_idx) / 2\n                elif imp_loc == future_dump:\n                    tckar_upper_idx = tckar_idx\n                    tckar_idx = tckar_idx - (tckar_idx - tckar_lower_idx) / 2\n                else:\n                    self.Failed(\"Impulse not where expected.\")\n                    found = True\n            print \"Tick array index = {}, Diff = {}\".format(tckar_idx, tckar_idx - tckar_idx_prev)\n\n            # for idx in range(len(auto_corr_list)):\n            #     #plt.plot(auto_corr_list[idx][:,inp_autocorr_idx,:])\n            #     if idx != future_dump-2:\n            #         for i in range(4096):\n            #             for j in range(40):\n            #                 if auto_corr_list[idx][i, j, 0] > 0:\n            #                     print i, j\n\n            # plt.show()\n\n    def _test_timestamp_shift(self):\n        \"\"\"Testing timestamp accuracy\n        Confirm that the CBF subsystem do not modify and correctly interprets\n        timestamps contained in each digitiser SPEAD accumulations (dump)\n        \"\"\"\n        if self.set_instrument():\n            self.Step(\"Checking timestamp accuracy: {}\\n\".format(self.corr_fix.get_running_instrument()))\n            main_offset = 2153064\n            minor_offset = 0\n            minor_offset = -10 * 4096 * 2\n            manual_offset = main_offset + minor_offset\n            self._timestamp_shift(offset=manual_offset)\n\n    def _timestamp_shift(self, shift_nr=12, offset=0, future_dump=3):\n        \"\"\"\n\n        Parameters\n        ----------\n        shift_nr : Number of shifts to perform during shift test\n        future_dump : Dump in which impulse is expected\n\n        Returns\n        -------\n\n        \"\"\"\n\n        def load_dsim_impulse(load_timestamp, offset=0):\n            self.dhost.registers.src_sel_cntrl.write(src_sel_0=2)\n            self.dhost.registers.src_sel_cntrl.write(src_sel_1=0)\n            self.dhost.registers.impulse_delay_correction.write(reg=16)\n            load_timestamp = load_timestamp + offset\n            lt_abs_t = datetime.datetime.fromtimestamp(sync_time + load_timestamp / scale_factor_timestamp)\n            print \"Impulse load time = {}:{}.{}\".format(lt_abs_t.minute, lt_abs_t.second, lt_abs_t.microsecond)\n            print \"Number of dumps in future = {:.10f}\".format((load_timestamp - dump_ts) / dump_ticks)\n            # Digitiser simulator local clock factor of 8 slower\n            # (FPGA clock = sample clock / 8).\n            load_timestamp = load_timestamp / 8\n            if not load_timestamp.is_integer():\n                self.Failed(\"Timestamp received in accumulation not divisible\" \" by 8: {:.15f}\".format(load_timestamp))\n            load_timestamp = int(load_timestamp)\n            reg_size = 32\n            load_ts_lsw = load_timestamp & (pow(2, reg_size) - 1)\n            load_ts_msw = load_timestamp >> reg_size\n            self.dhost.registers.impulse_load_time_lsw.write(reg=load_ts_lsw)\n            self.dhost.registers.impulse_load_time_msw.write(reg=load_ts_msw)\n\n        dsim_set_success = set_input_levels(\n            self.corr_fix, self.dhost, awgn_scale=0.0, cw_scale=0.0, freq=100000000, fft_shift=0, gain=\"32767+0j\"\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        self.dhost.outputs.out_1.scale_output(0)\n        dump = self.receiver.get_clean_dump()\n        baseline_lookup = get_baselines_lookup(self, dump)\n        sync_time = self.cam_sensors.get_value(\"synch_epoch\")\n        scale_factor_timestamp = self.cam_sensors.get_value(\"scale_factor_timestamp\")\n        inp = self.cam_sensors.input_labels[0][0]\n        inp_autocorr_idx = baseline_lookup[(inp, inp)]\n        # FFT input sliding window size = 8 spectra\n        # fft_sliding_window = self.n_chans_selected * 2 * 8\n        # Get number of ticks per dump and ensure it is divisible by 8 (FPGA\n        # clock runs 8 times slower)\n        dump_ticks = self.cam_sensors.get_value(\"int_time\") * self.cam_sensors.get_value(\"adc_sample_rate\")\n        dump_ticks = self.cam_sensors.get_value(\"n_accs\") * self.n_chans_selected * 2\n        input_spec_ticks = self.n_chans_selected * 2\n        if not (dump_ticks / 8.0).is_integer():\n            self.Failed(\"Number of ticks per dump is not divisible\" \" by 8: {:.3f}\".format(dump_ticks))\n        future_ticks = dump_ticks * future_dump\n        shift_set = [[[], []] for x in range(5)]\n        for shift in range(len(shift_set)):\n            set_offset = offset + 1024 * shift\n            list0 = []\n            list1 = []\n            for step in range(shift_nr):\n                set_offset = set_offset + input_spec_ticks\n                dump = self.receiver.get_clean_dump()\n                dump_ts = dump[\"timestamp\"]\n                sync_time = self.cam_sensors.get_value(\"synch_epoch\")\n                scale_factor_timestamp = self.cam_sensors.get_value(\"scale_factor_timestamp\")\n                dump_abs_t = datetime.datetime.fromtimestamp(sync_time + dump_ts / scale_factor_timestamp)\n                print \"Start dump time = {}:{}.{}\".format(dump_abs_t.minute, dump_abs_t.second, dump_abs_t.microsecond)\n                load_timestamp = dump_ts + future_ticks\n                load_dsim_impulse(load_timestamp, set_offset)\n                dump_list = []\n                cnt = 0\n                for i in range(future_dump):\n                    cnt += 1\n                    dump = self.receiver.data_queue.get()\n                    print dump[\"timestamp\"]\n                    dval = dump[\"xeng_raw\"]\n                    auto_corr = dval[:, inp_autocorr_idx, :]\n                    curr_ts = dump[\"timestamp\"]\n                    delta_ts = curr_ts - dump_ts\n                    dump_ts = curr_ts\n                    if delta_ts != dump_ticks:\n                        self.Failed(\n                            \"Accumulation dropped, Expected timestamp = {}, \"\n                            \"received timestamp = {}\"\n                            \"\".format(dump_ts + dump_ticks, curr_ts)\n                        )\n                    print \"Maximum value found in dump {} = {}, average = {}\" \"\".format(\n                        cnt, np.max(auto_corr), np.average(auto_corr)\n                    )\n                    dump_list.append(auto_corr)\n                list0.append(np.std(dump_list[future_dump - 1]))\n                list1.append(np.std(dump_list[future_dump - 2]))\n            shift_set[shift][0] = list0\n            shift_set[shift][1] = list1\n\n        # shift_output0 = [np.log(x) if x > 0 else 0 for x in shift_output0]\n        # shift_output1 = [np.log(x) if x > 0 else 0 for x in shift_output1]\n        for std_dev_set in shift_set:\n            plt.plot(std_dev_set[0])\n            plt.plot(std_dev_set[1])\n        plt.show()\n\n    # def _test_bc8n856M32k_input_levels(self):\n    #     \"\"\"\n    #     Testing Digitiser simulator input levels\n    #     Set input levels to requested values and check that the ADC and the\n    #     quantiser block do not see saturated samples.\n    #     \"\"\"\n    #     Aqf.procedure(TestProcedure.Channelisation)\n    #     try:\n    #         assert eval(os.getenv('DRY_RUN', 'False'))\n    #     except AssertionError:\n    #         instrument_success = self.set_instrument()\n    #         _running_inst = self.corr_fix.get_running_instrument()\n    #         if instrument_success:\n    #             fft_shift = pow(2, 15) - 1\n    #             self._set_input_levels_and_gain(profile='cw', cw_freq=200000000, cw_margin=0.6,\n    #                                             trgt_bits=5, trgt_q_std=0.30, fft_shift=fft_shift)\n    #         else:\n    #             self.Failed(self.errmsg)\n\n    def _test_input_levels(self):\n        \"\"\"Testing Digitiser simulator input levels\n        Set input levels to requested values and check that the ADC and the\n        quantiser block do not see saturated samples.\n        \"\"\"\n        if self.set_instrument():\n            self.Step(\"Setting and checking Digitiser simulator input levels\")\n            self._set_input_levels_and_gain(\n                profile=\"cw\", cw_freq=100000, cw_margin=0.3, trgt_bits=4, trgt_q_std=0.30, fft_shift=8191\n            )\n\n    def _set_input_levels_and_gain(\n        self, profile=\"noise\", cw_freq=0, cw_src=0, cw_margin=0.05, trgt_bits=3.5, trgt_q_std=0.30, fft_shift=511\n    ):\n        \"\"\" Set the digitiser simulator (dsim) output levels, FFT shift\n            and quantiser gain to optimum levels. ADC and quantiser snapshot\n            data is used to determine levels.\n            Param:\n                profile (default = noise):\n                    noise - digitiser output is gaussian noise.\n                    cw    - digitiser output is a constant wave pertubated by\n                            noise\n                cw_freq\n                    required cw frequency, the center of the closest channel\n                    will be chosen and then offset by 50 Hz. Center freqency\n                    is not used as this contains DC.\n                cw_src\n                    required cw source\n                cw_margin\n                    margin from full scale for cw tone. 0.1 equates to approx\n                    1.2 bits\n                trgt_bits (default = 3.5, valid = 1-9):\n                    the standard deviation of ADC snapblock data is calculated.\n                    This value sets the target standard deviation expressed in\n                    ADC bits toggling for noise. If a cw is selected, the noise\n                    specified here will be added.\n                trgt_q_std (default = 0.3):\n                    the target standard deviation of a quantiser snapblock,\n                    will be used to set the quantiser gain if profile = noise.\n                    In the case of a CW this value is not used.\n\n            Return:\n                dict containing input labels, for each input:\n                    std_dev   : ADC snapblock standard deviation. If profile =\n                                CW then this is of the added noise.\n                    bits_t    : calculated bits toggling at standard deviation\n                    fft_shift : current FFT shift value\n                    scale     : dsim output scale\n                    profile   : dsim output profile (noise or cw)\n                    adc_satr  : ADC snapshot contains saturated samples\n                    q_gain    : quantiser gain\n                    q_std_dev : quantiser snapshot standard deviation\n                    q_satr    : quantiser snapshot contains saturated samples\n                    num_sat   : number of quantiser snapshot saturated samples\n                    cw_freq   : actual returned cw frequency\n\n        \"\"\"\n\n        # helper functions\n        def set_sine_source(scale, cw_freq, cw_src):\n            # if cw_src == 0:\n            self.dhost.sine_sources.sin_0.set(frequency=cw_freq, scale=round(scale, 3))\n            #    return self.dhost.sine_sources.sin_0.frequency\n            # else:\n            self.dhost.sine_sources.sin_1.set(frequency=cw_freq, scale=round(scale, 3))\n            return self.dhost.sine_sources.sin_1.frequency\n\n        def adc_snapshot(source):\n            try:\n                reply, informs = self.katcp_req.adc_snapshot(source)\n                assert reply.reply_ok()\n                adc_data = eval(informs[0].arguments[1])\n                assert len(adc_data) == 8192\n                return adc_data\n            except AssertionError as e:\n                errmsg = \"Failed to get adc snapshot for input {}, reply = {}. {}\".format(source, reply, str(e))\n                self.Error(errmsg, exc_info=True)\n                return False\n            except Exception:\n                errmsg = \"Exception\"\n                self.Error(errmsg, exc_info=True)\n                return False\n\n        def quant_snapshot(source):\n            try:\n                reply, informs = self.katcp_req.quantiser_snapshot(source)\n                assert reply.reply_ok()\n                quant_data = eval(informs[0].arguments[1])\n                assert len(quant_data) == 4096\n                return quant_data\n            except AssertionError as e:\n                errmsg = \"Failed to get quantiser snapshot for input {}, reply = {}. {}\".format(source, reply, str(e))\n                self.Error(errmsg, exc_info=True)\n                return False\n            except Exception:\n                errmsg = \"Exception\"\n                self.Error(errmsg, exc_info=True)\n                return False\n\n        def set_gain(source, gain_str):\n            try:\n                reply, informs = self.katcp_req.gain(source, gain_str)\n                assert reply.reply_ok()\n                assert reply.arguments[1:][0] == gain_str\n            except AssertionError as e:\n                errmsg = \"Failed to set gain for input {}, reply = {}. {}\".format(source, reply, str(e))\n                self.Error(errmsg, exc_info=True)\n                return False\n            except Exception:\n                errmsg = \"Exception\"\n                self.Error(errmsg, exc_info=True)\n                return False\n\n        # main code\n        self.Step(\"Requesting input labels.\")\n        try:\n            katcp_rct = self.corr_fix.katcp_rct.sensors\n            input_labels = eval(katcp_rct.input_labelling.get_value())\n            assert isinstance(input_labels, list)\n            inp_labels = [x[0] for x in input_labels]\n        except AssertionError as e:\n            errmsg = \"Failed to get input labels. {}\".format(str(e))\n            self.Error(errmsg, exc_info=True)\n            return False\n        except Exception:\n            errmsg = \"Exception\"\n            self.Error(errmsg, exc_info=True)\n            return False\n\n        # Set digitiser input level of one random input,\n        # store values from other inputs for checking\n        inp = random.choice(inp_labels)\n        ret_dict = dict.fromkeys(inp_labels, {})\n        scale = 0.1\n        margin = 0.005\n        self.dhost.noise_sources.noise_corr.set(scale=round(scale, 3))\n        # Get target standard deviation. ADC is represented by Q10.9\n        # signed fixed point.\n        target_std = pow(2.0, trgt_bits) / 512\n        found = False\n        count = 1\n        self.Step(\"Setting input noise level to toggle {} bits at \" \"standard deviation.\".format(trgt_bits))\n        while not found:\n            self.Step(\"Capturing ADC Snapshot {} for input {}.\".format(count, inp))\n            adc_data = adc_snapshot(inp)\n            cur_std = np.std(adc_data)\n            cur_diff = target_std - cur_std\n            if (abs(cur_diff) < margin) or count > 6:\n                found = True\n            else:\n                count += 1\n                perc_change = target_std / cur_std\n                scale = scale * perc_change\n                # Maximum noise power\n                if scale > 1:\n                    scale = 1\n                    found = True\n                self.dhost.noise_sources.noise_corr.set(scale=round(scale, 3))\n        noise_scale = scale\n        p_std = np.std(adc_data)\n        p_bits = np.log2(p_std * 512)\n        self.Step(\n            \"Digitiser simulator noise scale set to {:.3f}, toggling {:.2f} bits at \"\n            \"standard deviation.\".format(noise_scale, p_bits)\n        )\n\n        if profile == \"cw\":\n            self.Step(\"Setting CW scale to {} below saturation point.\" \"\".format(cw_margin))\n            # Find closest center frequency to requested value to ensure\n            # correct quantiser gain is set. Requested frequency will be set\n            # at the end.\n\n            # reply, informs = self.corr_fix.katcp_rct. \\\n            #    req.quantiser_snapshot(inp)\n            # data = [eval(v) for v in (reply.arguments[2:])]\n            # nr_ch = len(data)\n            # ch_bw = bw / nr_ch\n            # ch_list = np.linspace(0, bw, nr_ch, endpoint=False)\n\n            # bw = self.cam_sensors.get_value('bandwidth')\n            # nr_ch = self.n_chans_selected\n            ch_bw = self.cam_sensors.ch_center_freqs[1]\n            ch_list = self.cam_sensors.ch_center_freqs\n            freq_ch = int(round(cw_freq / ch_bw))\n            scale = 1.0\n            step = 0.005\n            count = 1\n            found = False\n            while not found:\n                self.Step(\"Capturing ADC Snapshot {} for input {}.\".format(count, inp))\n                set_sine_source(scale, ch_list[freq_ch] + 50, cw_src)\n                adc_data = adc_snapshot(inp)\n                if (count < 5) and (np.abs(np.max(adc_data) or np.min(adc_data)) >= 0b111111111 / 512.0):\n                    scale -= step\n                    count += 1\n                else:\n                    scale -= step + cw_margin\n                    freq = set_sine_source(scale, ch_list[freq_ch] + 50, cw_src)\n                    adc_data = adc_snapshot(inp)\n                    found = True\n            self.Step(\"Digitiser simulator CW scale set to {:.3f}.\".format(scale))\n            aqf_plot_histogram(\n                adc_data,\n                plot_filename=\"{}/adc_hist_{}.png\".format(self.logs_path, inp),\n                plot_title=(\n                    \"ADC Histogram for input {}\\nAdded Noise Profile: \"\n                    \"Std Dev: {:.3f} equates to {:.1f} bits \"\n                    \"toggling.\".format(inp, p_std, p_bits)\n                ),\n                caption=\"ADC Input Histogram\",\n                bins=256,\n                ranges=(-1, 1),\n            )\n\n        else:\n            aqf_plot_histogram(\n                adc_data,\n                plot_filename=\"{}/adc_hist_{}.png\".format(self.logs_path, inp),\n                plot_title=(\n                    \"ADC Histogram for input {}\\n Standard Deviation: {:.3f} equates \"\n                    \"to {:.1f} bits toggling\".format(inp, p_std, p_bits)\n                ),\n                caption=\"ADC Input Histogram\",\n                bins=256,\n                ranges=(-1, 1),\n            )\n\n        for key in ret_dict.keys():\n            self.Step(\"Capturing ADC Snapshot for input {}.\".format(key))\n            # adc_data = adc_snapshot(key)\n            if profile != \"cw\":  # use standard deviation of noise before CW\n                p_std = np.std(adc_data)\n                p_bits = np.log2(p_std * 512)\n            ret_dict[key][\"std_dev\"] = p_std\n            ret_dict[key][\"bits_t\"] = p_bits\n            ret_dict[key][\"scale\"] = scale\n            ret_dict[key][\"noise_scale\"] = noise_scale\n            ret_dict[key][\"profile\"] = profile\n            ret_dict[key][\"adc_satr\"] = False\n            if np.abs(np.max(adc_data) or np.min(adc_data)) >= 0b111111111 / 512.0:\n                ret_dict[key][\"adc_satr\"] = True\n\n        # Set the fft shift to 511 for noise. This should be automated once\n        # a sensor is available to determine fft shift overflow.\n\n        self.Step(\"Setting FFT Shift to {}.\".format(fft_shift))\n        try:\n            reply, informs = self.katcp_req.fft_shift(fft_shift)\n            assert reply.reply_ok()\n            for key in ret_dict.keys():\n                ret_dict[key][\"fft_shift\"] = reply.arguments[1:][0]\n        except AssertionError as e:\n            errmsg = \"Failed to set FFT shift, reply = {}. {}\".format(reply, str(e))\n            self.Error(errmsg, exc_info=True)\n        except Exception:\n            errmsg = \"Exception\"\n            self.Error(errmsg, exc_info=True)\n\n        if profile == \"cw\":\n            self.Step(\"Setting quantiser gain for CW input.\")\n            gain = 1\n            gain_str = \"{}\".format(int(gain)) + \"+0j\"\n            set_gain(inp, gain_str)\n\n            try:\n                dump = self.receiver.get_clean_dump()\n            except Queue.Empty:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Failed(errmsg)\n                self.Error(errmsg, exc_info=True)\n            else:\n                baseline_lookup = get_baselines_lookup(self, dump)\n                inp_autocorr_idx = baseline_lookup[(inp, inp)]\n                dval = dump[\"xeng_raw\"]\n                auto_corr = dval[:, inp_autocorr_idx, :]\n                ch_val = auto_corr[freq_ch][0]\n                next_ch_val = 0\n                # n_accs = self.cam_sensors.get_value('n_accs')\n                ch_val_array = []\n                ch_val_array.append([ch_val, gain])\n                count = 0\n                prev_ch_val_diff = 0\n                found = False\n                max_count = 100\n                two_found = False\n                while count < max_count:\n                    count += 1\n                    ch_val = next_ch_val\n                    gain += 1\n                    gain_str = \"{}\".format(int(gain)) + \"+0j\"\n                    self.Step(\"Setting quantiser gain of {} for input {}.\".format(gain_str, inp))\n                    set_gain(inp, gain_str)\n                    try:\n                        dump = self.receiver.get_clean_dump()\n                    except Queue.Empty:\n                        errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                        self.Failed(errmsg)\n                        self.Error(errmsg, exc_info=True)\n                    except AssertionError:\n                        errmsg = (\n                            \"No of channels (%s) in the spead data is inconsistent with the no of\"\n                            \" channels (%s) expected\" % (dump[\"xeng_raw\"].shape[0], self.n_chans_selected)\n                        )\n                        self.Failed(errmsg)\n                        return False\n                    else:\n                        dval = dump[\"xeng_raw\"]\n                        auto_corr = dval[:, inp_autocorr_idx, :]\n                        next_ch_val = auto_corr[freq_ch][0]\n                        ch_val_diff = next_ch_val - ch_val\n                        # When the gradient start decreasing the center of the linear\n                        # section has been found. Grab the same number of points from\n                        # this point. Find 2 decreasing differences in a row\n                        if (not found) and (ch_val_diff < prev_ch_val_diff):\n                            if two_found:\n                                found = True\n                                count = max_count - count - 1\n                            else:\n                                two_found = True\n                        else:\n                            two_found = False\n                        ch_val_array.append([next_ch_val, gain])\n                        prev_ch_val_diff = ch_val_diff\n\n            y = [x[0] for x in ch_val_array]\n            x = [x[1] for x in ch_val_array]\n            grad = np.gradient(y)\n            # This does not work relibably\n            # grad_delta = []\n            # for i in range(len(grad) - 1):\n            #    grad_delta.append(grad[i + 1] / grad[i])\n            # The setpoint is where grad_delta is closest to 1\n            # grad_delta = np.asarray(grad_delta)\n            # set_point = np.argmax(grad_delta - 1.0 < 0) + 1\n            set_point = np.argmax(grad)\n            gain_str = \"{}\".format(int(x[set_point])) + \"+0j\"\n            plt.plot(x, y, label=\"Channel Response\")\n            plt.plot(x[set_point], y[set_point], \"ro\", label=\"Gain Set Point = \" \"{}\".format(x[set_point]))\n            plt.title(\"CW Channel Response for Quantiser Gain\\n\" \"Channel = {}, Frequency = {}Hz\".format(freq_ch, freq))\n            plt.ylabel(\"Channel Magnitude\")\n            plt.xlabel(\"Quantiser Gain\")\n            plt.legend(loc=\"upper left\")\n            caption = \"CW Channel Response for Quantiser Gain\"\n            plot_filename = \"{}/cw_ch_response_{}.png\".format(self.logs_path, inp)\n            Aqf.matplotlib_fig(plot_filename, caption=caption)\n        else:\n            # Set quantiser gain for selected input to produces required\n            # standard deviation of quantiser snapshot\n            self.Step(\n                \"Setting quantiser gain for noise input with a target \" \"standard deviation of {}.\".format(trgt_q_std)\n            )\n            found = False\n            count = 0\n            margin = 0.01\n            gain = 300\n            gain_str = \"{}\".format(int(gain)) + \"+0j\"\n            set_gain(inp, gain_str)\n            while not found:\n                self.Step(\"Capturing quantiser snapshot for gain of \" + gain_str)\n                data = quant_snapshot(inp)\n                cur_std = np.std(data)\n                cur_diff = trgt_q_std - cur_std\n                if (abs(cur_diff) < margin) or count > 20:\n                    found = True\n                else:\n                    count += 1\n                    perc_change = trgt_q_std / cur_std\n                    gain = gain * perc_change\n                    gain_str = \"{}\".format(int(gain)) + \"+0j\"\n                    set_gain(inp, gain_str)\n\n        # Set calculated gain for remaining inputs\n        for key in ret_dict.keys():\n            if profile == \"cw\":\n                ret_dict[key][\"cw_freq\"] = freq\n            set_gain(key, gain_str)\n            data = quant_snapshot(key)\n            p_std = np.std(data)\n            ret_dict[key][\"q_gain\"] = gain_str\n            ret_dict[key][\"q_std_dev\"] = p_std\n            ret_dict[key][\"q_satr\"] = False\n            rmax = np.max(np.asarray(data).real)\n            rmin = np.min(np.asarray(data).real)\n            imax = np.max(np.asarray(data).imag)\n            imin = np.min(np.asarray(data).imag)\n            if abs(rmax or rmin or imax or imin) >= 0b1111111 / 128.0:\n                ret_dict[key][\"q_satr\"] = True\n                count = 0\n                for val in data:\n                    if abs(val) >= 0b1111111 / 128.0:\n                        count += 1\n                ret_dict[key][\"num_sat\"] = count\n\n        if profile == \"cw\":\n            try:\n                dump = self.receiver.get_clean_dump()\n            except Queue.Empty:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Failed(errmsg)\n                self.Error(errmsg, exc_info=True)\n            except AssertionError:\n                errmsg = (\n                    \"No of channels (%s) in the spead data is inconsistent with the no of\"\n                    \" channels (%s) expected\" % (dump[\"xeng_raw\"].shape[0], self.n_chans_selected)\n                )\n                self.Failed(errmsg)\n                return False\n            else:\n                dval = dump[\"xeng_raw\"]\n                auto_corr = dval[:, inp_autocorr_idx, :]\n                plot_filename = \"{}/spectrum_plot_{}.png\".format(self.logs_path, key)\n                plot_title = \"Spectrum for Input {}\\n\" \"Quantiser Gain: {}\".format(key, gain_str)\n                caption = \"Spectrum for CW input\"\n                aqf_plot_channels(\n                    10 * np.log10(auto_corr[:, 0]),\n                    plot_filename=plot_filename,\n                    plot_title=plot_title,\n                    caption=caption,\n                    show=True,\n                )\n        else:\n            p_std = np.std(data)\n            aqf_plot_histogram(\n                np.abs(data),\n                plot_filename=\"{}/quant_hist_{}.png\".format(self.logs_path, key),\n                plot_title=(\n                    \"Quantiser Histogram for input {}\\n \"\n                    \"Standard Deviation: {:.3f},\"\n                    \"Quantiser Gain: {}\".format(key, p_std, gain_str)\n                ),\n                caption=\"Quantiser Histogram\",\n                bins=64,\n                ranges=(0, 1.5),\n            )\n\n        key = ret_dict.keys()[0]\n        if profile == \"cw\":\n            self.Step(\"Digitiser simulator Sine Wave scaled at {:0.3f}\".format(ret_dict[key][\"scale\"]))\n        self.Step(\"Digitiser simulator Noise scaled at {:0.3f}\".format(ret_dict[key][\"noise_scale\"]))\n        self.Step(\"FFT Shift set to {}\".format(ret_dict[key][\"fft_shift\"]))\n        for key in ret_dict.keys():\n            self.Step(\n                \"{} ADC standard deviation: {:0.3f} toggling {:0.2f} bits\".format(\n                    key, ret_dict[key][\"std_dev\"], ret_dict[key][\"bits_t\"]\n                )\n            )\n            self.Step(\n                \"{} quantiser standard deviation: {:0.3f} at a gain of {}\".format(\n                    key, ret_dict[key][\"q_std_dev\"], ret_dict[key][\"q_gain\"]\n                )\n            )\n            if ret_dict[key][\"adc_satr\"]:\n                self.Failed(\"ADC snapshot for {} contains saturated samples.\".format(key))\n            if ret_dict[key][\"q_satr\"]:\n                self.Failed(\"Quantiser snapshot for {} contains saturated samples.\".format(key))\n                self.Failed(\"{} saturated samples found\".format(ret_dict[key][\"num_sat\"]))\n        return ret_dict\n\n    def _small_voltage_buffer(self):\n        channel_list = self.cam_sensors.ch_center_freqs\n        # Choose a frequency 3 quarters through the band\n        cw_chan_set = int(self.n_chans_selected * 3 / 4)\n        cw_freq = channel_list[cw_chan_set]\n        dsim_clk_factor = 1.712e9 / self.cam_sensors.sample_period\n        bandwidth = self.cam_sensors.get_value(\"bandwidth\")\n        # eff_freq = (cw_freq + bandwidth) * dsim_clk_factor\n        channel_bandwidth = self.cam_sensors.delta_f\n        input_labels = self.cam_sensors.input_labels\n\n        if \"4k\" in self.instrument:\n            # 4K\n            cw_scale = 0.675\n            awgn_scale = 0.05\n            gain = \"11+0j\"\n            fft_shift = 8191\n        else:\n            # 32K\n            cw_scale = 0.375\n            awgn_scale = 0.085\n            gain = \"11+0j\"\n            fft_shift = 32767\n\n        self.Step(\n            \"Digitiser simulator configured to generate a continuous wave at %s Hz (channel=%s),\"\n            \" with cw scale: %s, awgn scale: %s, eq gain: %s, fft shift: %s\"\n            % (cw_freq, cw_chan_set, cw_scale, awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(\n            self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=cw_freq, fft_shift=fft_shift, gain=gain, cw_src=0\n        )\n        if not dsim_set_success:\n            self.Failed(\"Failed to configure digitise simulator levels\")\n            return False\n\n        try:\n            self.Step(\"Confirm that the `Transient Buffer ready` is implemented.\")\n            reply, informs = self.katcp_req.transient_buffer_trigger(timeout=120)\n            assert reply.reply_ok()\n            Aqf.passed(\"Transient buffer trigger present.\")\n        except Exception:\n            self.Failed(\"Transient buffer trigger failed. \\nReply: %s\" % str(reply).replace(\"_\", \" \"))\n\n        try:\n            self.Step(\"Randomly select an input to capture ADC snapshot\")\n            input_label = random.choice(input_labels)\n            self.Progress(\"Selected input %s to capture ADC snapshot from\" % input_label)\n            self.Step(\"Capture an ADC snapshot and confirm the fft length\")\n            reply, informs = self.katcp_req.adc_snapshot(input_label, timeout=60)\n            assert reply.reply_ok()\n            informs = informs[0]\n        except Exception:\n            self.Error(\"Failed to capture ADC snapshot.\", exc_info=True)\n            self.Failed(\"Failed to capture ADC snapshot. \\nReply: %s\" % str(reply).replace(\"_\", \" \"))\n            return\n        else:\n            adc_data = eval(informs.arguments[-1])\n            fft_len = len(adc_data)\n            self.Progress(\"ADC capture length: {}\".format(fft_len))\n            fft_real = np.abs(np.fft.fft(adc_data))\n            fft_pos = fft_real[0 : int(fft_len / 2)]\n            cw_chan = np.argmax(fft_pos)\n            cw_freq_found = cw_chan / (fft_len / 2) * bandwidth\n            msg = (\n                \"Confirm that the expected frequency: {}Hz and measured frequency: \"\n                \"{}Hz matches to within a channel bandwidth: {:.3f}Hz\".format(cw_freq_found, cw_freq, channel_bandwidth)\n            )\n            Aqf.almost_equals(cw_freq_found, cw_freq, channel_bandwidth, msg)\n            aqf_plot_channels(\n                np.log10(fft_pos),\n                plot_filename=\"{}/{}_fft_{}.png\".format(self.logs_path, self._testMethodName, input_label),\n                plot_title=(\n                    \"Input Frequency = %s Hz\\nMeasured Frequency at FFT bin %s \"\n                    \"= %sHz\" % (cw_freq, cw_chan, cw_freq_found)\n                ),\n                log_dynamic_range=None,\n                caption=(\n                    \"FFT of captured small voltage buffer. %s voltage points captured \"\n                    \"on input %s. Input bandwidth = %sHz\" % (fft_len, input_label, bandwidth)\n                ),\n                xlabel=\"FFT bins\",\n            )\n\n    def _test_informal(self):\n        pass\n\n    def _test_global_manual(self, ve_num):\n        \"\"\"Manual Test Method, for executing all manual tests\n\n        Parameters\n        ----------\n            ve_num: str, Verification Event Number\n        Returns\n        -------\n            results:\n                Pass or TBD\n        \"\"\"\n        # Assumes dict is returned\n        _results = self.csv_manual_tests.csv_to_dict(ve_num)\n        ve_desc = _results.get(\"Verification Event Description\", \"TBD\")\n        Aqf.procedure(r\"%s\" % ve_desc)\n        try:\n            assert eval(os.getenv(\"MANUAL_TEST\", \"False\")) or eval(os.getenv(\"DRY_RUN\", \"False\"))\n        except AssertionError:\n            results = r\"%s\" % _results.get(\"Verification Event Results\", \"TBD\")\n            if results != \"TBD\":\n                self.Step(r\"%s\" % _results.get(\"Verification Requirement Description\", \"TBD\"))\n                Aqf.passed(r\"%s\" % results)\n                perf = _results.get(\"Verification Event Performed By\", \"TBD\")\n                _date = _results.get(\"Date of Verification Event\", \"TBD\")\n                if perf != \"TBD\":\n                    Aqf.hop(r\"Test ran by: %s on %s\" % (perf, _date))\n            else:\n                Aqf.tbd(\"This test results outstanding.\")\n\n    def _test_efficiency(self):\n\n        csv_filename = \"/\".join([self._katreport_dir, r\"CBF_Efficiency_Data.csv\"])\n\n        def get_samples():\n\n            n_chans = self.cam_sensors.get_value(\"n_chans\")\n            test_chan = random.choice(range(n_chans)[: self.n_chans_selected])\n            requested_test_freqs = self.cam_sensors.calc_freq_samples(test_chan, samples_per_chan=101, chans_around=2)\n            expected_fc = self.cam_sensors.ch_center_freqs[test_chan]\n            # Get baseline 0 data, i.e. auto-corr of m000h\n            test_baseline = 0\n            # [CBF-REQ-0053]\n            min_bandwithd_req = 770e6\n            # Channel magnitude responses for each frequency\n            chan_responses = []\n            last_source_freq = None\n            print_counts = 3\n            req_chan_spacing = 250e3\n\n            if \"4k\" in self.instrument:\n                # 4K\n                cw_scale = 0.675\n                awgn_scale = 0.05\n                gain = \"11+0j\"\n                fft_shift = 8191\n            else:\n                # 32K\n                cw_scale = 0.375\n                awgn_scale = 0.085\n                gain = \"11+0j\"\n                fft_shift = 32767\n\n            self.Step(\n                \"Digitiser simulator configured to generate a continuous wave, \"\n                \"with cw scale: {}, awgn scale: {}, eq gain: {}, fft shift: {}\".format(\n                    cw_scale, awgn_scale, gain, fft_shift\n                )\n            )\n            dsim_set_success = set_input_levels(\n                self, awgn_scale=awgn_scale, cw_scale=cw_scale, freq=expected_fc, fft_shift=fft_shift, gain=gain\n            )\n            if not dsim_set_success:\n                self.Failed(\"Failed to configure digitise simulator levels\")\n                return False\n            try:\n                self.Step(\n                    \"Randomly select a frequency channel to test. Capture an initial correlator \"\n                    \"SPEAD accumulation, determine the number of frequency channels\"\n                )\n                initial_dump = self.receiver.get_clean_dump()\n                self.assertIsInstance(initial_dump, dict)\n            except Exception:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Error(errmsg, exc_info=True)\n                self.Failed(errmsg)\n            else:\n\n                bls_to_test = eval(self.cam_sensors.get_value(\"bls_ordering\"))[test_baseline]\n                self.Progress(\n                    \"Randomly selected frequency channel to test: {} and \"\n                    \"selected baseline {} / {} to test.\".format(test_chan, test_baseline, bls_to_test)\n                )\n                Aqf.equals(\n                    np.shape(initial_dump[\"xeng_raw\"])[0],\n                    self.n_chans_selected,\n                    \"Confirm that the number of channels in the SPEAD accumulation, is equal \"\n                    \"to the number of frequency channels as calculated: {}\".format(\n                        np.shape(initial_dump[\"xeng_raw\"])[0]\n                    ),\n                )\n\n                Aqf.is_true(\n                    self.cam_sensors.get_value(\"bandwidth\") >= min_bandwithd_req,\n                    \"Channelise total bandwidth {}Hz shall be >= {}Hz.\".format(\n                        self.cam_sensors.get_value(\"bandwidth\"), min_bandwithd_req\n                    ),\n                )\n                chan_spacing = self.cam_sensors.get_value(\"bandwidth\") / n_chans\n                chan_spacing_tol = [chan_spacing - (chan_spacing * 1 / 100), chan_spacing + (chan_spacing * 1 / 100)]\n                self.Step(\"Confirm that the number of calculated channel \" \"frequency step is within requirement.\")\n                msg = \"Verify that the calculated channel \" \"frequency ({} Hz)step size is between {} and {} Hz\".format(\n                    chan_spacing, req_chan_spacing / 2, req_chan_spacing\n                )\n                Aqf.in_range(chan_spacing, req_chan_spacing / 2, req_chan_spacing, msg)\n\n                self.Step(\n                    \"Confirm that the channelisation spacing and confirm that it is \" \"within the maximum tolerance.\"\n                )\n                msg = \"Channelisation spacing is within maximum tolerance of 1% of the \" \"channel spacing.\"\n                Aqf.in_range(chan_spacing, chan_spacing_tol[0], chan_spacing_tol[1], msg)\n\n            self.Step(\n                \"Sweep the digitiser simulator over the centre frequencies of at \"\n                \"least all the channels that fall within the complete L-band\"\n            )\n\n            for i, freq in enumerate(requested_test_freqs):\n                if i < print_counts:\n                    self.Progress(\n                        \"Getting channel response for freq {} @ {}: {:.3f} MHz.\".format(\n                            i + 1, len(requested_test_freqs), freq / 1e6\n                        )\n                    )\n                elif i == print_counts:\n                    self.Progress(\".\" * print_counts)\n                elif i >= (len(requested_test_freqs) - print_counts):\n                    self.Progress(\n                        \"Getting channel response for freq {} @ {}: {:.3f} MHz.\".format(\n                            i + 1, len(requested_test_freqs), freq / 1e6\n                        )\n                    )\n                else:\n                    self.logger.debug(\n                        \"Getting channel response for freq %s @ %s: %s MHz.\"\n                        % (i + 1, len(requested_test_freqs), freq / 1e6)\n                    )\n\n                self.dhost.sine_sources.sin_0.set(frequency=freq, scale=cw_scale)\n                this_source_freq = self.dhost.sine_sources.sin_0.frequency\n\n                if this_source_freq == last_source_freq:\n                    self.logger.debug(\n                        \"Skipping channel response for freq %s @ %s: %s MHz.\\n\"\n                        \"Digitiser frequency is same as previous.\" % (i + 1, len(requested_test_freqs), freq / 1e6)\n                    )\n                    continue  # Already calculated this one\n                else:\n                    last_source_freq = this_source_freq\n\n                try:\n                    this_freq_dump = self.receiver.get_clean_dump()\n                    # self.receiver.get_clean_dump()\n                    self.assertIsInstance(this_freq_dump, dict)\n                except AssertionError:\n                    errmsg = \"Could not retrieve clean SPEAD accumulation\"\n                    self.Failed(errmsg)\n                    self.Error(errmsg, exc_info=True)\n                    return False\n                else:\n                    # No of spead heap discards relevant to vacc\n                    discards = 0\n                    max_wait_dumps = 100\n                    deng_timestamp = self.dhost.registers.sys_clkcounter.read().get(\"timestamp\")\n                    while True:\n                        try:\n                            queued_dump = self.receiver.data_queue.get(timeout=DUMP_TIMEOUT)\n                            self.assertIsInstance(queued_dump, dict)\n                        except Exception:\n                            errmsg = \"Could not retrieve clean accumulation.\"\n                            self.Error(errmsg, exc_info=True)\n                        else:\n                            timestamp_diff = np.abs(queued_dump[\"dump_timestamp\"] - deng_timestamp)\n                            if timestamp_diff < 0.5:\n                                msg = (\n                                    \"Received correct accumulation timestamp: %s, relevant to \"\n                                    \"DEngine timestamp: %s (Difference %.2f)\"\n                                    % (queued_dump[\"dump_timestamp\"], deng_timestamp, timestamp_diff)\n                                )\n                                self.logger.info(msg)\n                                break\n\n                            if discards > max_wait_dumps:\n                                errmsg = (\n                                    \"Could not get accumulation with correct timestamp within %s \"\n                                    \"accumulation periods.\" % max_wait_dumps\n                                )\n                                self.Failed(errmsg)\n                                break\n                            else:\n                                msg = (\n                                    \"Discarding subsequent dumps (%s) with dump timestamp (%s) \"\n                                    \"and DEngine timestamp (%s) with difference of %s.\"\n                                    % (discards, queued_dump[\"dump_timestamp\"], deng_timestamp, timestamp_diff)\n                                )\n                                self.logger.info(msg)\n                        discards += 1\n\n                    this_freq_response = normalised_magnitude(queued_dump[\"xeng_raw\"][:, test_baseline, :])\n                    chan_responses.append(this_freq_response)\n\n            chan_responses = np.array(chan_responses)\n            requested_test_freqs = np.asarray(requested_test_freqs)\n            csv_filename = \"/\".join([self._katreport_dir, r\"CBF_Efficiency_Data.csv\"])\n            np.savetxt(csv_filename, zip(chan_responses[:, test_chan], requested_test_freqs), delimiter=\",\")\n\n        def efficiency_calc(f, P_dB, binwidth, debug=False):\n            # Adapted from SSalie\n            # Sidelobe & scalloping loss requires f to be normalized to bins\n            # Normalize the filter response\n            self.Step(\"Measure/record the filter-bank spectral response from a channel\")\n            P_dB -= P_dB.max()\n            f = f - f[P_dB > -3].mean()  # CHANGED: center on zero\n\n            # It's critical to get precise estimates of critical points so to minimize measurement\n            # resolution impact, up-sample!\n            _f_, _P_dB_ = f, P_dB\n            _f10_ = np.linspace(f[0], f[-1], len(f) * 10)  # up-sample 10x\n            # CHANGED: slightly better than np.interp(_f10_, f, P_dB) e.g. for poorly sampled data\n            P_dB = scipy.interpolate.interp1d(f, P_dB, \"quadratic\", bounds_error=False)(_f10_)\n            f = _f10_\n\n            # Measure critical bandwidths\n            f_HPBW = f[P_dB >= -3.0]\n            # CHANGED: with better interpolation don't need earlier \"fudged\" 3.05 & 6.05\n            f_HABW = f[P_dB >= -6.0]\n            HPBW = (f_HPBW[-1] - f_HPBW[0]) / binwidth\n            HABW = (f_HABW[-1] - f_HABW[0]) / binwidth\n            h = 10 ** (P_dB / 10.0)\n            NEBW = np.sum(h[:-1] * np.diff(f)) / binwidth  # Noise Equivalent BW\n            self.Step(\n                \"Determine the Half Power Bandwidth as well as the Noise Equivalent Bandwidth \" \"for each swept channel\"\n            )\n            self.Progress(\"Half Power Bandwidth: %s, Noise Equivalent Bandwidth: %s\" % (HPBW, NEBW))\n\n            self.Step(\n                \"Compute the efficiency as the ratio of Half Power Bandwidth to the Noise \"\n                \"Equivalent Bandwidth: efficiency = HPBW/NEBW\"\n            )\n            _efficiency = HPBW / NEBW\n            Aqf.more(_efficiency, 0.98, \"Efficiency factor = {:.3f}\".format(_efficiency))\n            # Measure critical points\n            pk = f.searchsorted(f[P_dB > -6].mean())  # The peak\n            # Channel-to-channel separation intervals\n            ch = f.searchsorted(f[0] + binwidth)\n            # Scalloping loss at mid-point between channel peaks\n            SL = P_dB[pk + ch // 2 - 1]\n            # Max scalloping loss within 80% of a channel\n            SL80 = P_dB[pk : pk + int((0.8 * ch) // 2 - 1)].min()\n            # Smooth it over 1/8th of a bin width to get rid of main lobe ripples\n            DDP = np.diff(scipy.signal.medfilt(np.diff(P_dB), (ch // 16) * 2 + 1))\n            # The first large inflection point after the peak is the null\n            mn = pk + ch // 2 + (DDP[pk + ch // 2 :] > 0.01).argmax()\n            # The nearest one is typically the peak sidelobe\n            SLL = P_dB[mn:].max()\n            # Upper half of the channel & the excluding main lobe\n            plt.figure()\n            plt.subplot(211)\n            plt.title(\"Efficiency factor = {:.3f}\".format(_efficiency))\n            plt.plot(_f_, _P_dB_, label=\"Channel Response\")\n            plt.plot(f[pk:], P_dB[pk:], \"g.\", label=\"Peak\")\n            plt.plot(f[mn:], P_dB[mn:], \"r.\", label=\"After Null\")\n            plt.legend()\n            plt.grid(True)\n            plt.subplot(212, sharex=plt.gca())\n            plt.plot(f[1:-1], DDP, label=\"Data diff\")\n            plt.grid(True)\n            plt.legend()\n            if debug:\n                plt.show()\n\n            cap = \"SLL = %.f, SL = %.1f(%.f), NE/3dB/6dB BW = %.2f/%.2f/%.2f, HPBW/NEBW = %4f, \" % (\n                SLL,\n                SL,\n                SL80,\n                NEBW,\n                HPBW,\n                HABW,\n                HPBW / NEBW,\n            )\n            filename = \"{}/{}.png\".format(self.logs_path, self._testMethodName)\n            Aqf.matplotlib_fig(filename, caption=cap, autoscale=True)\n\n        try:\n            pfb_data = np.loadtxt(csv_filename, delimiter=\",\", unpack=False)\n            self.Step(\"Retrieved channelisation (Frequencies and Power_dB) data results from CSV file\")\n        except IOError:\n            try:\n                get_samples()\n                csv_file = max(glob.iglob(csv_filename), key=os.path.getctime)\n                assert \"CBF\" in csv_file\n                pfb_data = np.loadtxt(csv_file, delimiter=\",\", unpack=False)\n            except Exception:\n                msg = \"Failed to load CBF_Efficiency_Data.csv file\"\n                self.Error(msg, exc_info=True)\n                return\n\n        chan_responses, requested_test_freqs = pfb_data[:, 0][1:], pfb_data[:, 1][1:]\n        # Summarize isn't clever enough to cope with the spurious spike in first sample\n        requested_test_freqs = np.asarray(requested_test_freqs)\n        chan_responses = 10 * np.log10(np.abs(np.asarray(chan_responses)))\n        try:\n            binwidth = self.cam_sensors.get_value(\"bandwidth\") / (self.n_chans_selected - 1)\n            efficiency_calc(requested_test_freqs, chan_responses, binwidth)\n        except Exception:\n            msg = \"Could not compute the data, rerun test\"\n            self.Error(msg, exc_info=True)\n            self.Failed(msg)\n        # else:\n        #     subprocess.check_call([\"rm\", csv_filename])\n\n    def _test_product_baseline_leakage(self):\n        heading(\"CBF Baseline Correlation Product Leakage\")\n        if \"4k\" in self.instrument:\n            # 4K\n            awgn_scale = 0.0645\n            gain = \"113+0j\"\n            fft_shift = 511\n        else:\n            # 32K\n            awgn_scale = 0.063\n            gain = \"344+0j\"\n            fft_shift = 4095\n\n        self.Step(\n            \"Digitiser simulator configured to generate Gaussian noise, \"\n            \"with scale: {}, eq gain: {}, fft shift: {}\".format(awgn_scale, gain, fft_shift)\n        )\n        dsim_set_success = set_input_levels(\n            self, awgn_scale=awgn_scale, corr_noise=False, fft_shift=fft_shift, gain=gain\n        )\n\n        self.Step(\n            \"Capture an initial correlator SPEAD accumulation, and retrieve list \"\n            \"of all the correlator input labels via Cam interface.\"\n        )\n        try:\n            test_dump = self.receiver.get_clean_dump(discard=50)\n            self.assertIsInstance(test_dump, dict)\n        except AssertionError:\n            errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n            self.Error(errmsg, exc_info=True)\n        else:\n            # Get bls ordering from get dump\n            self.Step(\n                \"Get list of all possible baselines (including redundant baselines) present \"\n                \"in the correlator output from SPEAD accumulation\"\n            )\n\n            bls_ordering = eval(self.cam_sensors.get_value(\"bls_ordering\"))\n            input_labels = sorted(self.cam_sensors.input_labels)\n            inputs_to_plot = random.shuffle(input_labels)\n            inputs_to_plot = input_labels[:8]\n            bls_to_plot = [0, 2, 4, 8, 11, 14, 23, 33]\n            baselines_lookup = get_baselines_lookup(self)\n            present_baselines = sorted(baselines_lookup.keys())\n            possible_baselines = set()\n            _ = [possible_baselines.add((li, lj)) for li in input_labels for lj in input_labels]\n\n            test_bl = sorted(list(possible_baselines))\n            self.Step(\n                \"Confirm that each baseline (or its reverse-order counterpart) is present in \" \"the correlator output\"\n            )\n\n            baseline_is_present = {}\n            for test_bl in possible_baselines:\n                baseline_is_present[test_bl] = test_bl in present_baselines or test_bl[::-1] in present_baselines\n            # Select some baselines to plot\n            plot_baselines = (\n                (input_labels[0], input_labels[0]),\n                (input_labels[0], input_labels[1]),\n                (input_labels[0], input_labels[2]),\n                (input_labels[-1], input_labels[-1]),\n                (input_labels[-1], input_labels[-2]),\n            )\n            plot_baseline_inds = []\n            for bl in plot_baselines:\n                if bl in baselines_lookup:\n                    plot_baseline_inds.append(baselines_lookup[bl])\n                else:\n                    plot_baseline_inds.append(baselines_lookup[bl[::-1]])\n\n            plot_baseline_legends = tuple(\n                \"{bl[0]}, {bl[1]}: {ind}\".format(bl=bl, ind=ind) for bl, ind in zip(plot_baselines, plot_baseline_inds)\n            )\n\n            msg = \"Confirm that all baselines are present in correlator output.\"\n            Aqf.is_true(all(baseline_is_present.values()), msg)\n            test_data = test_dump[\"xeng_raw\"]\n            self.Step(\n                \"Expect all baselines and all channels to be \" \"non-zero with Digitiser Simulator set to output AWGN.\"\n            )\n            msg = \"Confirm that no baselines have all-zero visibilities.\"\n            Aqf.is_false(zero_baselines(test_data), msg)\n\n            msg = \"Confirm that all baseline visibilities are non-zero across all channels\"\n            Aqf.equals(nonzero_baselines(test_data), all_nonzero_baselines(test_data), msg)\n\n            self.Step(\"Save initial f-engine equalisations, and ensure they are \" \"restored at the end of the test\")\n\n            initial_equalisations = get_and_restore_initial_eqs(self)\n            Aqf.passed(\"Stored initial F-engine equalisations\")\n\n            def prt_arr(array, print_len=4):\n                try:\n                    if len(array) < print_len:\n                        print_len = len(array)\n                        out_arr = array[:print_len]\n                        out_arr = \", \".join([str(e) for e in out_arr])\n                    else:\n                        out_arr = array[:print_len]\n                        out_arr = \", \".join([str(e) for e in out_arr]) + \", ...\"\n                except BaseException:\n                    out_arr = str(array)\n\n                return out_arr\n\n            ref_auto = True\n            ref_x = True\n            ref_y = True\n            idnt = \" \" * 28\n            auto_phase = []\n            auto_mag = []\n            cross_phase = []\n            cross_mag = []\n            for inputs, index in baselines_lookup.iteritems():\n                # Auto correlations\n                if inputs[0][-1] == inputs[1][-1]:\n                    test_data_complex = complexise(test_data[:, index, :])\n                    phase = np.angle(test_data_complex)\n                    mag = np.abs(test_data_complex)\n                    auto_phase.append(phase)\n                    auto_mag.append(mag)\n                    if ref_auto:\n                        ref_auto_phase = phase\n                        ref_auto_mag = mag\n                        ref_auto = False\n                        self.Step(\n                            \"Using {}, baseline {}, as an auto-correlation \"\n                            \"reference with:\\n{}\\n{}\".format(\n                                inputs, index, idnt + \"Magnitude: \" + prt_arr(mag), idnt + \"Phase:  \" + prt_arr(phase)\n                            )\n                        )\n                    else:\n                        phase_match = ref_auto_phase == phase\n                        mag_match = ref_auto_mag == mag\n                        if not (np.all(mag_match)):\n                            err_idx = np.where(np.invert(mag_match))\n                            err_arr = np.take(mag, err_idx)[0]\n                            ref_arr = np.take(ref_auto_mag, err_idx)[0]\n                            err_idx = err_idx[0]\n                            self.Failed(\n                                \"{}, baseline {}, auto-correlation magnitudes do not match:\\n{}\\n{}\\n{}\"\n                                \"\".format(\n                                    inputs,\n                                    index,\n                                    idnt + \"Error indices:    \" + prt_arr(err_idx),\n                                    idnt + \"Reference values: \" + prt_arr(ref_arr),\n                                    idnt + \"Magnitude values: \" + prt_arr(err_arr),\n                                )\n                            )\n                        elif not (np.all(phase_match)):\n                            err_idx = np.where(np.invert(phase_match))\n                            err_arr = np.take(phase, err_idx)[0]\n                            ref_arr = np.take(ref_auto_phase, err_idx)[0]\n                            err_idx = err_idx[0]\n                            self.Failed(\n                                \"{}, baseline {}, auto-correlation phases do not match:\\n{}\\n{}\\n{}\"\n                                \"\".format(\n                                    inputs,\n                                    index,\n                                    idnt + \"Error indices:    \" + prt_arr(err_idx),\n                                    idnt + \"Reference values: \" + prt_arr(ref_arr),\n                                    idnt + \"Phase values:     \" + prt_arr(err_arr),\n                                )\n                            )\n                        else:\n                            Aqf.passed(\n                                \"{}, baseline {}, is an auto-correlation, magnitude and phase matches:\\n{}\\n{}\"\n                                \"\".format(\n                                    inputs,\n                                    index,\n                                    idnt + \"Magnitude values: \" + prt_arr(mag),\n                                    idnt + \"Phase values:     \" + prt_arr(phase),\n                                )\n                            )\n\n            for inputs, index in baselines_lookup.iteritems():\n                # Cross correlations\n                if inputs[0][-1] != inputs[1][-1]:\n                    test_data_complex = complexise(test_data[:, index, :])\n                    phase = np.angle(test_data_complex)\n                    mag = np.abs(test_data_complex)\n                    cross_phase.append(phase)\n                    cross_mag.append(mag)\n                    if inputs[0][-1] == \"x\":\n                        if ref_x:\n                            ref_phase_x = phase\n                            ref_mag_x = mag\n                            ref_x = False\n                            self.Step(\n                                \"Using {}, baseline {}, as a x-pol cross-correlation reference with:\\n{}\\n{}\"\n                                \"\".format(\n                                    inputs,\n                                    index,\n                                    idnt + \"Magnitude: \" + prt_arr(mag),\n                                    idnt + \"Phase:     \" + prt_arr(phase),\n                                )\n                            )\n                        else:\n                            phase_match = ref_phase_x == phase\n                            mag_match = ref_mag_x == mag\n                            if not (np.all(mag_match)):\n                                err_idx = np.where(np.invert(mag_match))\n                                err_arr = np.take(mag, err_idx)[0]\n                                ref_arr = np.take(ref_auto_mag, err_idx)[0]\n                                err_idx = err_idx[0]\n                                self.Failed(\n                                    \"{}, baseline {}, x-pol cross-correlation magnitudes do not match:\\n{}\\n{}\\n{}\"\n                                    \"\".format(\n                                        inputs,\n                                        index,\n                                        idnt + \"Error indices:    \" + prt_arr(err_idx),\n                                        idnt + \"Reference values: \" + prt_arr(ref_arr),\n                                        idnt + \"Magnitude values: \" + prt_arr(err_arr),\n                                    )\n                                )\n                            elif not (np.all(phase_match)):\n                                err_idx = np.where(np.invert(phase_match))\n                                err_arr = np.take(phase, err_idx)[0]\n                                ref_arr = np.take(ref_auto_phase, err_idx)[0]\n                                err_idx = err_idx[0]\n                                self.Failed(\n                                    \"{}, baseline {}, x-pol cross-correlation phases do not match:\\n{}\\n{}\\n{}\"\n                                    \"\".format(\n                                        inputs,\n                                        index,\n                                        idnt + \"Error indices:    \" + prt_arr(err_idx),\n                                        idnt + \"Reference values: \" + prt_arr(ref_arr),\n                                        idnt + \"Phase values:     \" + prt_arr(err_arr),\n                                    )\n                                )\n                            else:\n                                Aqf.passed(\n                                    \"{}, baseline {}, is a x-poll cross-correlation, magnitude and phase matches:\\n{}\\n{}\"\n                                    \"\".format(\n                                        inputs,\n                                        index,\n                                        idnt + \"Magnitude values: \" + prt_arr(mag),\n                                        idnt + \"Phase values:     \" + prt_arr(phase),\n                                    )\n                                )\n\n                    else:\n                        if ref_y:\n                            ref_phase_y = phase\n                            ref_mag_y = mag\n                            ref_y = False\n                            self.Step(\n                                \"Using {}, baseline {}, as a y-pol cross-correlation reference with:\\n{}\\n{}\"\n                                \"\".format(\n                                    inputs,\n                                    index,\n                                    idnt + \"Magnitude: \" + prt_arr(mag),\n                                    idnt + \"Phase:     \" + prt_arr(phase),\n                                )\n                            )\n                        else:\n                            phase_match = ref_phase_y == phase\n                            mag_match = ref_mag_y == mag\n                            if False and not (np.all(mag_match)):\n                                err_idx = np.where(np.invert(mag_match))\n                                err_arr = np.take(mag, err_idx)[0]\n                                ref_arr = np.take(ref_auto_mag, err_idx)[0]\n                                err_idx = err_idx[0]\n                                self.Failed(\n                                    \"{}, baseline {}, y-pol cross-correlation magnitudes do not match:\\n{}\\n{}\\n{}\"\n                                    \"\".format(\n                                        inputs,\n                                        index,\n                                        idnt + \"Error indices:    \" + prt_arr(err_idx),\n                                        idnt + \"Reference values: \" + prt_arr(ref_arr),\n                                        idnt + \"Magnitude values: \" + prt_arr(err_arr),\n                                    )\n                                )\n                            elif not (np.all(phase_match)):\n                                err_idx = np.where(np.invert(phase_match))\n                                err_arr = np.take(phase, err_idx)[0]\n                                ref_arr = np.take(ref_auto_phase, err_idx)[0]\n                                err_idx = err_idx[0]\n                                self.Failed(\n                                    \"{}, baseline {}, y-pol cross-correlation phases do not match:\\n{}\\n{}\\n{}\"\n                                    \"\".format(\n                                        inputs,\n                                        index,\n                                        idnt + \"Error indices:    \" + prt_arr(err_idx),\n                                        idnt + \"Reference values: \" + prt_arr(ref_arr),\n                                        idnt + \"Phase values:     \" + prt_arr(err_arr),\n                                    )\n                                )\n                            else:\n                                Aqf.passed(\n                                    \"{}, baseline {}, is a y-poll cross-correlation, magnitude and phase matches:\\n{}\\n{}\"\n                                    \"\".format(\n                                        inputs,\n                                        index,\n                                        idnt + \"Magnitude values: \" + prt_arr(mag),\n                                        idnt + \"Phase values:     \" + prt_arr(phase),\n                                    )\n                                )\n\n            plt_filename = \"{}/{}_autocorrelation_channel_response.png\".format(self.logs_path, self._testMethodName)\n            plt_caption = \"Channel responses for all auto correlation baselines.\"\n            plt_title = \"Channel responses for all auto correlation baselines.\"\n            aqf_plot_channels(auto_mag, plot_filename=plt_filename, plot_title=plt_title)\n\n    def _test_linearity(self, test_channel, cw_start_scale, noise_scale, gain, fft_shift, max_steps):\n        # # Get instrument parameters\n        # bw = self.cam_sensors.get_value('bandwidth')\n        # nr_ch = self.cam_sensors.get_value('n_chans')\n        # ants = self.cam_sensors.get_value('n_ants')\n        # ch_bw = ch_list[1]\n        # scale_factor_timestamp = self.cam_sensors.get_value('scale_factor_timestamp')\n        # dsim_factor = (float(self.conf_file['instrument_params']['sample_freq'])/\n        #                scale_factor_timestamp)\n        # substreams = self.cam_sensors.get_value('n_xengs')\n\n        ch_list = self.cam_sensors.ch_center_freqs\n\n        def get_cw_val(cw_scale, noise_scale, gain, fft_shift, test_channel, inp, f_offset=50000):\n            self.Step(\n                \"Digitiser simulator configured to generate a continuous wave, \"\n                \"with cw scale: {}, awgn scale: {}, eq gain: {}, fft shift: {}\".format(\n                    cw_scale, noise_scale, gain, fft_shift\n                )\n            )\n            dsim_set_success = set_input_levels(\n                self,\n                awgn_scale=noise_scale,\n                cw_scale=cw_scale,\n                freq=ch_list[test_channel] + f_offset,\n                fft_shift=fft_shift,\n                gain=gain,\n            )\n            if not dsim_set_success:\n                self.Failed(\"Failed to configure digitise simulator levels\")\n                return False\n\n            try:\n                dump = self.receiver.get_clean_dump(DUMP_TIMEOUT)\n            except Queue.Empty:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Error(errmsg, exc_info=True)\n            try:\n                baseline_lookup = get_baselines_lookup(self, dump)\n                # Choose baseline for phase comparison\n                baseline_index = baseline_lookup[(inp, inp)]\n            except KeyError:\n                self.Failed(\"Initial SPEAD accumulation does not contain correct baseline \" \"ordering format.\")\n                return False\n            data = dump[\"xeng_raw\"]\n            freq_response = complexise(data[:, baseline_index, :])\n            if freq_response[test_channel] == 0:\n                return 0\n            else:\n                return 10 * np.log10(np.abs(freq_response[test_channel]))\n\n        Aqf.hop(\"Requesting input labels.\")\n        try:\n            # Build dictionary with inputs and\n            # which fhosts they are associated with.\n            reply, informs = self.katcp_req.input_labels()\n            if reply.reply_ok():\n                inp = reply.arguments[1:][0]\n        except Exception:\n            self.Failed(\"Failed to get input labels. KATCP Reply: {}\".format(reply))\n            return False\n        Aqf.hop(\"Sampling input {}\".format(inp))\n        cw_scale = cw_start_scale\n        cw_delta = 0.1\n        threshold = 10 * np.log10(pow(2, 30))\n        curr_val = threshold\n        Aqf.hop(\"Finding starting cw input scale...\")\n        max_cnt = max_steps\n        while (curr_val >= threshold) and max_cnt:\n            prev_val = curr_val\n            curr_val = get_cw_val(cw_scale, noise_scale, gain, fft_shift, test_channel, inp)\n            cw_scale -= cw_delta\n            if cw_scale < 0:\n                max_cnt = 0\n                cw_scale = 0\n            else:\n                max_cnt -= 1\n        cw_start_scale = cw_scale + cw_delta\n        Aqf.hop(\"Starting cw input scale set to {}\".format(cw_start_scale))\n        cw_scale = cw_start_scale\n        output_power = []\n        x_val_array = []\n        # Find closes point to this power to place linear expected line.\n        exp_step = 6\n        exp_y_lvl = 70\n        exp_y_dlt = exp_step / 2\n        exp_y_lvl_lwr = exp_y_lvl - exp_y_dlt\n        exp_y_lvl_upr = exp_y_lvl + exp_y_dlt\n        exp_y_val = 0\n        exp_x_val = 0\n        min_cnt_val = 3\n        min_cnt = min_cnt_val\n        max_cnt = max_steps\n        while min_cnt and max_cnt:\n            curr_val = get_cw_val(cw_scale, noise_scale, gain, fft_shift, test_channel, inp)\n            if exp_y_lvl_lwr < curr_val < exp_y_lvl_upr:\n                exp_y_val = curr_val\n                exp_x_val = 20 * np.log10(cw_scale)\n            step = curr_val - prev_val\n            if curr_val == 0:\n                break\n            if np.abs(step) < 0.2:\n                min_cnt -= 1\n            else:\n                min_cnt = min_cnt_val\n            x_val_array.append(20 * np.log10(cw_scale))\n            self.Step(\"CW power = {}dB, Step = {}dB, channel = {}\".format(curr_val, step, test_channel))\n            prev_val = curr_val\n            output_power.append(curr_val)\n            cw_scale = cw_scale / 2\n            max_cnt -= 1\n        output_power = np.array(output_power)\n        output_power_max = output_power.max()\n        output_power = output_power - output_power_max\n        exp_y_val = exp_y_val - output_power_max\n\n        plt_filename = \"{}_cbf_response_{}_{}_{}.png\".format(self._testMethodName, gain, noise_scale, cw_start_scale)\n        plt_title = \"CBF Response (Linearity Test)\"\n        caption = (\n            \"Digitiser Simulator start scale: {}, end scale: {}. Scale \"\n            \"halved for every step. FFT Shift: {}, Quantiser Gain: {}, \"\n            \"Noise scale: {}\".format(cw_start_scale, cw_scale * 2, fft_shift, gain, noise_scale)\n        )\n        m = 1\n        c = exp_y_val - m * exp_x_val\n        y_exp = []\n        for x in x_val_array:\n            y_exp.append(m * x + c)\n        # import IPython;IPython.embed()\n        aqf_plot_xy(\n            zip(([x_val_array, output_power], [x_val_array, y_exp]), [\"Response\", \"Expected\"]),\n            plt_filename,\n            plt_title,\n            caption,\n            xlabel=\"Input Power [dBm]\",\n            ylabel=\"Integrated Output Power [dBfs]\",\n        )\n        Aqf.end(passed=True, message=\"Linearity plot generated.\")\n\n    def get_clean_dump(self):\n        retries = 20\n        while retries:\n            retries -= 1\n            try:\n                dump = self.receiver.get_clean_dump(discard=0)\n                assert hasattr(self.dhost.registers, \"sys_clkcounter\"), \"Dhost is broken, missing sys_clkcounter\"\n                dhost_timestamp = self.dhost.registers.sys_clkcounter.read().get(\"timestamp\")\n                errmsg = \"Queue is empty will retry (%s) ie EMPTY DUMPS!!!!!!!!!!!!!!!!!!!!!\" % retries\n                assert isinstance(dump, dict), errmsg\n                discard = 0\n                while True:\n                    dump = self.receiver.data_queue.get(timeout=10)\n                    assert isinstance(dump, dict), errmsg\n                    dump_timestamp = dump[\"dump_timestamp\"]\n                    time_diff = np.abs(dump_timestamp - dhost_timestamp)\n                    if time_diff < 1:\n                        msg = (\n                            \"Yeyyyyyyyyy: Dump timestamp (%s) in-sync with digitiser sync epoch (%s)\"\n                            \" [diff: %s] within %s retries and discarded %s dumps\"\n                            % (dump_timestamp, dhost_timestamp, time_diff, retries, discard)\n                        )\n                        self.logger.info(msg)\n                        break\n                    else:\n                        msg = \"Dump timestamp (%s) is not in-sync with digitiser sync epoch (%s) [diff: %s]\" % (\n                            dump_timestamp,\n                            dhost_timestamp,\n                            time_diff,\n                        )\n                        self.logger.info(msg)\n                    if discard > 10:\n                        errmsg = \"Could not retrieve clean queued SPEAD accumulation.\"\n                        raise AssertionError(errmsg)\n                    discard += 1\n            except AssertionError:\n                errmsg = \"Could not retrieve clean queued SPEAD accumulation.\"\n                self.logger.warning(errmsg)\n            except Queue.Empty:\n                errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n                self.Error(errmsg, exc_info=True)\n                if retries < 15:\n                    self.logger.exception(\"Exiting brutally with no Accumulation\")\n                    return False\n            else:\n                return dump\n",
					"file": "mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/test_cbf.py",
					"file_size": 403091,
					"file_write_time": 131862514900000000,
					"settings":
					{
						"buffer_size": 403055,
						"encoding": "UTF-8",
						"line_ending": "Unix"
					}
				},
				{
					"contents": "Searching 1 file for \"except E\" (case sensitive)\n\n/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/test_cbf.py:\n   94              self.katcp_req_sensors = self.corr_fix.katcp_rct_sensor.req\n   95              self.Note(\"Connecting to katcp client on %s\" % self.corr_fix.katcp_client)\n   96:         except Exception:\n   97              self.Error(\"Failed to read test config file.\", exc_info=True)\n   98          try:\n   ..\n  100              errmsg = \"Failed to instantiate the dsim, investigate\"\n  101              assert isinstance(self.dhost, corr2.dsimhost_fpga.FpgaDsimHost), errmsg\n  102:         except Exception:\n  103              self.logger.exception(errmsg)\n  104          else:\n  ...\n  134                      self.logger.info(\"Digitiser sync epoch set successfully\")\n  135                      set_dsim_epoch = self._dsim_set = True\n  136:                 except Exception:\n  137                      self.Error(errmsg, exc_info=True)\n  138  \n  ...\n  164                  \"Currently running instrument %s-%s as per /etc/corr\" % (self.corr_fix.array_name, self.instrument)\n  165              )\n  166:         except Exception:\n  167              errmsg = \"No running instrument on array: %s, Exiting....\" % self.corr_fix.array_name\n  168              self.logger.exception(errmsg)\n  ...\n  188              self.Step(\"Set and confirm accumulation period via CAM interface.\")\n  189              self.Progress(\"Accumulation time set to {:.3f} seconds\".format(acc_time))\n  190:         except Exception as e:\n  191              self.Error(\"Failed to set accumulation time.\", exc_info=True)\n  192  \n  ...\n  239              self.n_chans_selected = int(_test_dump.get(\"n_chans_selected\", self.cam_sensors.get_value(\"n_chans\")))\n  240              self.logger.info(\"Confirmed number of channels %s, from initial dump\" % self.n_chans_selected)\n  241:         except Exception as e:\n  242              self.Error(str(e), exc_info=True)\n  243              return False\n  ...\n 1190              FNULL = open(os.devnull, \"w\")\n 1191              subprocess.check_call([\"pgrep\", \"-fol\", \"corr2_sensor_servlet.py\"], stdout=FNULL, stderr=FNULL)\n 1192:         except Exception:\n 1193              self.Error(\"Sensor_Servlet PID could not be discovered, might not be running.\",\n 1194                  exc_info=True)\n ....\n 1206                  try:\n 1207                      reply, informs = self.corr_fix.katcp_rct_sensor.req.sensor_value(timeout=30)\n 1208:                 except Exception:\n 1209                      reply, informs = self.katcp_req.sensor_value(timeout=30)\n 1210                  time.sleep(10)\n ....\n 1216                  sorted(list(set([i.arguments[2] for i in informs if \"warn\" in i.arguments[-2]])))\n 1217              )\n 1218:         except Exception:\n 1219              self.Note(\"Could not retrieve sensors via CAM interface.\")\n 1220          else:\n ....\n 1347              #            reply_, informs = self.katcp_req.sensor_value()\n 1348              #        assert reply_.reply_ok()\n 1349:             #    except Exception:\n 1350              #        self.logger.exception('Weirdly I could not get the sensor values')\n 1351              #    else:\n ....\n 1369              #        cam_max_load_time)\n 1370              # Aqf.less(cmd_load_time, cam_max_load_time, msg)\n 1371:         except Exception:\n 1372              self.Failed(errmsg, exc_info=True)\n 1373              return\n ....\n 1386                  dump = self.receiver.data_queue.get()\n 1387                  self.assertIsInstance(dump, dict)\n 1388:             except Exception:\n 1389                  errmsg = \"Could not retrieve clean SPEAD accumulation: Queue might be Empty.\"\n 1390                  self.Failed(errmsg, exc_info=True)\n ....\n 1437                  dump = self.receiver.data_queue.get()\n 1438                  self.assertIsInstance(dump, dict)\n 1439:             except Exception:\n 1440                  errmsg = \"Could not retrieve clean SPEAD accumulation: Queue might be Empty.\"\n 1441                  self.Error(errmsg, exc_info=True)\n ....\n 1742              initial_dump = self.receiver.get_clean_dump(discard=5)\n 1743              self.assertIsInstance(initial_dump, dict)\n 1744:         except Exception:\n 1745              errmsg = \"Could not retrieve initial clean SPEAD accumulation: Queue is Empty.\"\n 1746              self.logger.exception(errmsg)\n ....\n 1870                          deng_timestamp = float(self.dhost.registers.sys_clkcounter.read().get(\"timestamp\"))\n 1871                          assert isinstance(deng_timestamp, float)\n 1872:                     except Exception:\n 1873                          errmsg = \"Could not retrieve clean queued accumulation for freq(%s @ %s: \" \"%s MHz).\" % (\n 1874                              i + 1,\n ....\n 2001                  att_bw = actual_test_freqs[att_bw_min_max[-1]] - actual_test_freqs[att_bw_min_max[0]]\n 2002  \n 2003:             except Exception:\n 2004                  msg = (\n 2005                      \"Could not compute if, CBF performs channelisation such that the 53dB \"\n ....\n 2237                  power_logger.setName(\"CBF Power Consumption\")\n 2238                  self.addCleanup(power_logger.stop)\n 2239:             except Exception:\n 2240                  errmsg = \"Failed to start power usage logging.\"\n 2241                  self.Error(errmsg, exc_info=True)\n ....\n 2445                  heading(\"CBF Power Consumption\")\n 2446                  self._process_power_log(start_timestamp, power_log_file)\n 2447:             except Exception:\n 2448                  msg = \"Failed to read/decode the PDU log.\"\n 2449                  self.Error(msg, exc_info=True)\n ....\n 2532              ori_source_name = reply_.arguments[1:]\n 2533              self.Progress(\"Original source names: {}\".format(\", \".join(ori_source_name)))\n 2534:         except Exception:\n 2535              self.Error(\"Failed to retrieve input labels via CAM interface\", exc_info=True)\n 2536          try:\n ....\n 2538              reply, _ = self.katcp_req.input_labels(*local_src_names)\n 2539              assert reply.reply_ok()\n 2540:         except Exception:\n 2541              self.Failed(\"Could not retrieve new source names via CAM interface:\\n %s\" % (str(reply)))\n 2542          else:\n ....\n 2632                      reply, _ = self.katcp_req.gain_all(0)\n 2633                      assert reply.reply_ok()\n 2634:                 except Exception:\n 2635                      self.Error(\"Failed to set equalisations on all F-engines\", exc_info=True)\n 2636                  else:\n ....\n 2642                      assert reply.reply_ok()\n 2643                      eq_values = reply.arguments[-1]\n 2644:                 except Exception:\n 2645                      self.Failed(\"Failed to retrieve gains/equalisations.\")\n 2646                  else:\n ....\n 2713                          # test_dump = self.receiver.get_clean_dump()\n 2714                          self.assertIsInstance(test_dump, dict)\n 2715:                     except Exception:\n 2716                          errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n 2717                          self.Error(errmsg, exc_info=True)\n ....\n 2913              test_dump = self.receiver.get_clean_dump(discard=50)\n 2914              assert isinstance(test_dump, dict)\n 2915:         except Exception:\n 2916              errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n 2917              self.Error(errmsg, exc_info=True)\n ....\n 2943                              this_freq_dump = self.receiver.get_clean_dump(discard=20)\n 2944                              assert isinstance(this_freq_dump, dict)\n 2945:                         except Exception:\n 2946                              errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 2947                              self.Error(errmsg, exc_info=True)\n ....\n 2959                              this_freq_dump = self.receiver.get_clean_dump(discard=20)\n 2960                              assert isinstance(this_freq_dump, dict)\n 2961:                         except Exception:\n 2962                              errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 2963                              self.Error(errmsg, exc_info=True)\n ....\n 3295                          #            reply, informs = self.katcp_req.sensor_value()\n 3296                          #        assert reply.reply_ok()\n 3297:                         #    except Exception:\n 3298                          #        self.Error('Weirdly I couldnt get the sensor values', exc_info=True)\n 3299                          #    else:\n ....\n 3319                          #      .format(cmd_load_time, cam_max_load_time, int_time))\n 3320                          # Aqf.less(cmd_load_time, cam_max_load_time, msg)\n 3321:                     except Exception as e:\n 3322                          self.Failed(errmsg + \" Exception: {}\".format(e))\n 3323                          self.Error(errmsg, exc_info=True)\n ....\n 3338                              \"after %s number of discards \\n\" % (dump[\"dump_timestamp_readable\"], _num_discards)\n 3339                          )\n 3340:                     except Exception:\n 3341                          errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 3342                          self.Error(errmsg, exc_info=True)\n ....\n 3455                                      actual_phases[count][5:-5], expected_phases_[count][5:-5], msg, degree\n 3456                                  )\n 3457:                             except Exception:\n 3458                                  Aqf.array_abs_error(\n 3459                                      actual_phases[count][5:-5],\n ....\n 3462                                      degree,\n 3463                                  )\n 3464:                     except Exception as e:\n 3465                          self.Failed(e.message)\n 3466                          self.Error(e.message, exc_info=True)\n 3467                          return\n 3468:             except Exception as e:\n 3469                  self.Failed(e.message)\n 3470                  self.Error(e.message, exc_info=True)\n ....\n 3517              try:\n 3518                  assert self.katcp_req.transient_buffer_trigger.is_active()\n 3519:             except Exception:\n 3520                  errmsg = \"CBF Transient buffer ready for triggering\" \"'Not' implemented in this release.\\n\"\n 3521                  self.Error(errmsg, exc_info=True)\n ....\n 3576              fft_shift = int(reply.arguments[-1])\n 3577              self.Progress(\"Current system FFT Shift: %s\" % fft_shift)\n 3578:         except Exception:\n 3579              self.Error(\"Could not get the F-Engine FFT Shift value\", exc_info=True)\n 3580              return\n ....\n 3588                      reply, informs = self.katcp_req.sensor_value(timeout=60)\n 3589                  assert reply.reply_ok()\n 3590:         except Exception:\n 3591              msg = \"Failed to retrieve sensor values via CAM interface\"\n 3592              self.Error(msg, exc_info=True)\n ....\n 3616                      reply, informs = self.katcp_req.sensor_value()\n 3617                  assert reply.reply_ok()\n 3618:         except Exception:\n 3619              msg = \"Failed to retrieve sensor values via CAM interface\"\n 3620              self.Error(msg, exc_info=True)\n ....\n 3631              assert reply.reply_ok()\n 3632              Aqf.passed(\"FFT Shift: %s restored.\" % fft_shift)\n 3633:         except Exception:\n 3634              self.Error(\"Could not set the F-Engine FFT Shift value\", exc_info=True)\n 3635              return\n ....\n 3795          try:\n 3796              internal_accumulations = int(self.cam_sensors.get_value(\"xeng_acc_len\"))\n 3797:         except Exception as e:\n 3798              errmsg = \"Failed to retrieve X-engine accumulation length: %s.\" % str(e)\n 3799              self.Error(errmsg, exc_info=True)\n ....\n 3802              initial_dump = self.receiver.get_clean_dump()\n 3803              assert isinstance(initial_dump, dict)\n 3804:         except Exception:\n 3805              errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 3806              self.Failed(errmsg)\n ....\n 3821              assert reply.reply_ok()\n 3822              Aqf.hop(\"Gain successfully set on input %s via CAM interface.\" % test_input)\n 3823:         except Exception:\n 3824              errmsg = \"Gains/Eq could not be set on input %s via CAM interface\" % test_input\n 3825              self.Failed(errmsg)\n ....\n 3851              assert reply.reply_ok()\n 3852              informs = informs[0]\n 3853:         except Exception:\n 3854              errmsg = \"Failed to retrieve quantiser snapshot of input %s via \" \"CAM Interface: \\nReply %s\" % (\n 3855                  test_input,\n ....\n 3887                      reply = self.katcp_req.accumulation_length(acc_time, timeout=60)\n 3888                      assert reply.succeeded\n 3889:                 except Exception:\n 3890                      self.Failed(\n 3891                          \"Failed to set accumulation length of {} after maximum vacc \"\n ....\n 3909                          dump = self.receiver.get_clean_dump()\n 3910                          assert isinstance(dump, dict)\n 3911:                     except Exception:\n 3912                          errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 3913                          self.Failed(errmsg)\n ....\n 4436                          reply, _informs = self.katcp_req.delays(t_apply, *delay_coefficients)\n 4437                          assert reply.reply_ok()\n 4438:                     except Exception:\n 4439                          errmsg = \"%s\" % str(reply).replace(\"\\_\", \" \")\n 4440                          self.Failed(errmsg)\n ....\n 4450                          )\n 4451                          dump = self.receiver.get_clean_dump(discard=35)\n 4452:                     except Exception:\n 4453                          errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 4454                          self.Failed(errmsg)\n ....\n 4570              #            reply, informs = self.katcp_req.sensor_value()\n 4571              #        assert reply.reply_ok()\n 4572:             #    except Exception:\n 4573              #        self.Error('Weirdly I couldnt get the sensor values', exc_info=True)\n 4574              #    else:\n ....\n 4583              #    time.sleep(1)\n 4584  \n 4585:         except Exception:\n 4586              errmsg = \"%s: Failed to set delays via CAM interface with load-time: %s, \" \"Delay coefficients: %s\" % (\n 4587                  str(reply),\n ....\n 4662                  corr2_version = \"\".join([i for i in corr2_version.split(\".\") if len(i) == 7])\n 4663                  corr2_link = \"https://github.com/ska-sa/%s/commit/%s\" % (corr2_name, corr2_version)\n 4664:             except Exception:\n 4665                  corr2_link = \"Not Version Controlled at this time.\"\n 4666  \n ....\n 4672                  casper_version = \"\".join([i for i in casper_version.split(\".\") if len(i) == 7])\n 4673                  casper_link = \"https://github.com/ska-sa/%s/commit/%s\" % (casper_name, casper_version)\n 4674:             except Exception:\n 4675                  casper_link = \"Not Version Controlled at this time.\"\n 4676  \n ....\n 4683                  assert len(katcp_version) == 7\n 4684                  katcp_link = \"https://github.com/ska-sa/%s-python/commit/%s\" % (katcp_name, katcp_version)\n 4685:             except Exception:\n 4686                  katcp_link = \"https://github.com/ska-sa/%s/releases/tag/v%s\" % (katcp_name, katcp_version)\n 4687  \n ....\n 4694                  spead2_version = \"\".join([i for i in spead2_version.split(\".\") if len(i) == 7])\n 4695                  spead2_link = \"https://github.com/ska-sa/%s/commit/%s\" % (spead2_name, spead2_version)\n 4696:             except Exception:\n 4697                  spead2_link = \"https://github.com/ska-sa/%s/releases/tag/v%s\" % (spead2_name, spead2_version)\n 4698  \n ....\n 4705                  assert len(mkat_version) == 7\n 4706                  mkat_link = \"https://github.com/ska-sa/%s/commit/%s\" % (mkat_name, mkat_version)\n 4707:             except Exception:\n 4708                  mkat_name = \"mkat_fpga\"\n 4709                  mkat_link = \"Not Version Controlled at this time.\"\n ....\n 4729                  assert len(config_version) == 7\n 4730                  config_link = \"https://github.com/ska-sa/%s/commit/%s\" % (config_dir_name, config_version)\n 4731:             except Exception:\n 4732                  config_dir_name = \"mkat_config_templates\"\n 4733                  config_version = \"Not Version Controlled\"\n ....\n 4787                  else:\n 4788                      self.Progress(\"Repo: %s | Git Tag: %s | GitHub: %s\" % (name, repo_dir[0], repo_dir[1]))\n 4789:             except Exception:\n 4790                  pass\n 4791  \n ....\n 4827                  test_dump = self.receiver.get_clean_dump()\n 4828                  assert isinstance(test_dump, dict)\n 4829:             except Exception:\n 4830                  errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n 4831                  self.Failed(errmsg)\n ....\n 4903                  self.Failed(errmsg)\n 4904                  return False\n 4905:             except Exception as e:\n 4906                  errmsg = \"Exception: {}\".format(str(e))\n 4907                  self.Failed(errmsg)\n ....\n 4943                  self.Failed(errmsg)\n 4944                  return False\n 4945:             except Exception as e:\n 4946                  errmsg = \"Exception: {}\".format(str(e))\n 4947                  self.Failed(errmsg)\n ....\n 5025                      plot_type=\"bf\",\n 5026                  )\n 5027:             except Exception as e:\n 5028                  self.Failed(str(e))\n 5029  \n ....\n 5090              reply, informs = self.katcp_req.gain(test_input, base_gain)\n 5091              assert reply.reply_ok()\n 5092:         except Exception as e:\n 5093              self.Failed(\"Gain correction on %s could not be set to %s.: \" \"KATCP Reply: %s\" % (test_input, gain, reply))\n 5094              return False\n ....\n 5099              self.assertIsInstance(initial_dump, dict)\n 5100              assert np.any(initial_dump[\"xeng_raw\"])\n 5101:         except Exception:\n 5102              errmsg = \"Could not retrieve clean SPEAD accumulation, as Queue is Empty.\"\n 5103              self.Failed(errmsg)\n ....\n 5126                  reply, informs = self.katcp_req.gain(test_input, *gain_vector, timeout=60)\n 5127                  assert reply.reply_ok()\n 5128:             except Exception as e:\n 5129                  self.Failed(\n 5130                      \"Gain correction on %s could not be set to %s.: \" \"KATCP Reply: %s\" % (test_input, gain, reply)\n ....\n 5263              self.Failed(errmsg)\n 5264              return False\n 5265:         except Exception as e:\n 5266              errmsg = \"Exception: {}\".format(str(e))\n 5267              self.Failed(errmsg)\n ....\n 5301              self.Failed(errmsg)\n 5302              return False\n 5303:         except Exception as e:\n 5304              errmsg = \"Exception: {}\".format(str(e))\n 5305              self.Failed(errmsg)\n ....\n 5352                  ingest_kcp_client.stop()\n 5353                  raise RuntimeError(errmsg)\n 5354:         except Exception as e:\n 5355              self.Error(str(e), exc_info=True)\n 5356              self.Failed(str(e))\n ....\n 5371                  )\n 5372                  assert reply.reply_ok()\n 5373:             except Exception as e:\n 5374                  print e\n 5375                  errmsg = \"Failed to issues ingest node capture-init: {}\".format(str(reply))\n ....\n 5445                          if (len(in_wgts) == 0) and (isinstance(act_wgts, dict)):\n 5446                              in_wgts = act_wgts.copy()\n 5447:                     except Exception as e:\n 5448                          self.Failed(\n 5449                              \"Confirm that the Docker container is running and also confirm the \" \"igmp version = 2\"\n ....\n 5503                              else:\n 5504                                  raw_idx = raw_idx + spectra_per_heap\n 5505:                 except Exception as e:\n 5506                      errmsg = \"Failed to capture beam data due to error: %s\" % str(e)\n 5507                      self.Error(errmsg, exc_info=True)\n ....\n 5673                  # Use weights from previous test\n 5674                  d, l, rl, exp0, nc, act_wgts, dummy = get_beam_data(beam, beam_dict=beam_dict, conf_data_type=True)\n 5675:             except Exception as e:\n 5676                  errmsg = \"Failed to retrieve beamformer data\"\n 5677                  self.Failed(errmsg)\n ....\n 5713                          return False\n 5714                      continue\n 5715:                 except Exception as e:\n 5716                      retry_cnt += 1\n 5717                      errmsg = \"Test failed due to %s\" % str(e)\n ....\n 5737                          \"(using reference value) = {:.2f}\".format(cap_mean, exp_mean)\n 5738                      )\n 5739:                 except Exception as e:\n 5740                      errmsg = \"Failed to retrieve beamformer data\"\n 5741                      self.Failed(errmsg)\n ....\n 5773              try:\n 5774                  d, l, rl, exp1, nc, act_wgts, dummy = get_beam_data(beam, beam_dict, rl)\n 5775:             except Exception as e:\n 5776                  errmsg = \"Failed to retrieve beamformer data: %s\" % str(e)\n 5777                  self.Failed(errmsg)\n ....\n 5784              try:\n 5785                  d, l, rl, exp0, nc, act_wgts, dummy = get_beam_data(beam, beam_dict, rl)\n 5786:             except Exception as e:\n 5787                  errmsg = \"Failed to retrieve beamformer data\"\n 5788                  self.Failed(errmsg)\n ....\n 5819                  # Use weights from previous test\n 5820                  d, l, rl, exp0, nc, act_wgts, dummy = get_beam_data(beam, beam_quant_gain=bq_gain, act_wgts=act_wgts)\n 5821:             except Exception as e:\n 5822                  errmsg = \"Failed to retrieve beamformer data: %s\" % str(e)\n 5823                  self.Failed(errmsg)\n ....\n 5834                      beam, inp_ref_lvl=rl, beam_quant_gain=bq_gain, act_wgts=act_wgts\n 5835                  )\n 5836:             except Exception as e:\n 5837                  errmsg = \"Failed to retrieve beamformer data: %s\" % str(e)\n 5838                  self.Failed(errmsg)\n ....\n 5931                      if failed:\n 5932                          aligned_failed = True\n 5933:                 except Exception as e:\n 5934                      errmsg = \"Failed to retrieve beamformer data\"\n 5935                      self.Failed(errmsg)\n ....\n 5998              self.Failed(errmsg)\n 5999              return False\n 6000:         except Exception as e:\n 6001              errmsg = \"Exception: {}\".format(str(e))\n 6002              self.Failed(errmsg)\n ....\n 6036              self.Failed(errmsg)\n 6037              return False\n 6038:         except Exception as e:\n 6039              errmsg = \"Exception: {}\".format(str(e))\n 6040              self.Failed(errmsg)\n ....\n 6275              self.Failed(errmsg)\n 6276              return False\n 6277:         except Exception as e:\n 6278              errmsg = \"Exception: {}\".format(str(e))\n 6279              self.Failed(errmsg)\n ....\n 6313              self.Failed(errmsg)\n 6314              return False\n 6315:         except Exception as e:\n 6316              errmsg = \"Exception: {}\".format(str(e))\n 6317              self.Failed(errmsg)\n ....\n 6363                  ingest_kcp_client.stop()\n 6364                  raise RuntimeError(errmsg)\n 6365:         except Exception as e:\n 6366              self.Error(str(e), exc_info=True)\n 6367              self.Failed(str(e))\n ....\n 6396                      self, beam, ingest_kcp_client=ingest_kcp_client, stop_only=True\n 6397                  )\n 6398:             except Exception as e:\n 6399                  errmsg = (\n 6400                      \"Failed to capture beam data: %s\\n\\n Confirm that Docker container is \"\n ....\n 6556              try:\n 6557                  assert future_mcount\n 6558:             except Exception:\n 6559                  return False\n 6560              trgt_spectra_idx = np.where(bf_ts > future_mcount)[0]\n ....\n 6636              else:\n 6637                  raise Exception\n 6638:         except Exception as e:\n 6639              self.Failed(e)\n 6640              return\n ....\n 6682          try:\n 6683              reply, informs = self.katcp_req.quantiser_snapshot(inp, timeout=60)\n 6684:         except Exception:\n 6685              self.Failed(\"Failed to grab quantiser snapshot.\")\n 6686          quant_snap = [eval(v) for v in (reply.arguments[1:][1:])]\n 6687          try:\n 6688              reply, informs = self.katcp_req.adc_snapshot(inp, timeout=60)\n 6689:         except Exception:\n 6690              self.Failed(\"Failed to grab adc snapshot.\")\n 6691          fpga = self.correlator.fhosts[0]\n ....\n 7195                  self.Error(errmsg, exc_info=True)\n 7196                  return False\n 7197:             except Exception as e:\n 7198                  errmsg = \"Exception: {}\".format(str(e))\n 7199                  self.Failed(errmsg)\n ....\n 7213                  self.Error(errmsg, exc_info=True)\n 7214                  return False\n 7215:             except Exception as e:\n 7216                  errmsg = \"Exception: {}\".format(str(e))\n 7217                  self.Failed(errmsg)\n ....\n 7229                  self.Error(errmsg, exc_info=True)\n 7230                  return False\n 7231:             except Exception as e:\n 7232                  errmsg = \"Exception: {}\".format(str(e))\n 7233                  self.Failed(errmsg)\n ....\n 7247              self.Error(errmsg, exc_info=True)\n 7248              return False\n 7249:         except Exception as e:\n 7250              errmsg = \"Exception: {}\".format(str(e))\n 7251              self.Failed(errmsg)\n ....\n 7379              self.Failed(errmsg)\n 7380              self.Error(errmsg, exc_info=True)\n 7381:         except Exception as e:\n 7382              errmsg = \"Exception: {}\".format(str(e))\n 7383              self.Failed(errmsg)\n ....\n 7627              assert reply.reply_ok()\n 7628              Aqf.passed(\"Transient buffer trigger present.\")\n 7629:         except Exception:\n 7630              self.Failed(\"Transient buffer trigger failed. \\nReply: %s\" % str(reply).replace(\"_\", \" \"))\n 7631  \n ....\n 7638              assert reply.reply_ok()\n 7639              informs = informs[0]\n 7640:         except Exception:\n 7641              self.Error(\"Failed to capture ADC snapshot.\", exc_info=True)\n 7642              self.Failed(\"Failed to capture ADC snapshot. \\nReply: %s\" % str(reply).replace(\"_\", \" \"))\n ....\n 7754                  initial_dump = self.receiver.get_clean_dump()\n 7755                  self.assertIsInstance(initial_dump, dict)\n 7756:             except Exception:\n 7757                  errmsg = \"Could not retrieve clean SPEAD accumulation: Queue is Empty.\"\n 7758                  self.Error(errmsg, exc_info=True)\n ....\n 7850                              queued_dump = self.receiver.data_queue.get(timeout=DUMP_TIMEOUT)\n 7851                              self.assertIsInstance(queued_dump, dict)\n 7852:                         except Exception:\n 7853                              errmsg = \"Could not retrieve clean accumulation.\"\n 7854                              self.Error(errmsg, exc_info=True)\n ....\n 7976                  assert \"CBF\" in csv_file\n 7977                  pfb_data = np.loadtxt(csv_file, delimiter=\",\", unpack=False)\n 7978:             except Exception:\n 7979                  msg = \"Failed to load CBF_Efficiency_Data.csv file\"\n 7980                  self.Error(msg, exc_info=True)\n ....\n 7989              binwidth = self.cam_sensors.get_value(\"bandwidth\") / (self.n_chans_selected - 1)\n 7990              efficiency_calc(requested_test_freqs, chan_responses, binwidth)\n 7991:         except Exception:\n 7992              msg = \"Could not compute the data, rerun test\"\n 7993              self.Error(msg, exc_info=True)\n ....\n 8361              if reply.reply_ok():\n 8362                  inp = reply.arguments[1:][0]\n 8363:         except Exception as ex:\n 8364              print ex\n 8365              self.Failed(\"Failed to get input lables. KATCP Reply: {}\".format(reply))\n\n97 matches in 1 file\n",
					"settings":
					{
						"buffer_size": 28611,
						"line_ending": "Unix",
						"name": "Find Results",
						"scratch": true
					}
				}
			],
			"build_system": "",
			"build_system_choices":
			[
				[
					[
						[
							"Packages/C++/C++ Single File.sublime-build",
							""
						],
						[
							"Packages/C++/C++ Single File.sublime-build",
							"Run"
						]
					],
					[
						"Packages/C++/C++ Single File.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/Makefile/Make.sublime-build",
							""
						],
						[
							"Packages/Makefile/Make.sublime-build",
							"Clean"
						],
						[
							"Packages/Python/Python.sublime-build",
							""
						],
						[
							"Packages/Python/Python.sublime-build",
							"Syntax Check"
						],
						[
							"Packages/User/C++.sublime-build",
							""
						],
						[
							"Packages/User/C++.sublime-build",
							"Run"
						]
					],
					[
						"Packages/Python/Python.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/Python/Python.sublime-build",
							""
						],
						[
							"Packages/Python/Python.sublime-build",
							"Syntax Check"
						]
					],
					[
						"Packages/Python/Python.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/Python/Python.sublime-build",
							""
						],
						[
							"Packages/Python/Python.sublime-build",
							"Syntax Check"
						],
						[
							"Packages/User/C++.sublime-build",
							""
						],
						[
							"Packages/User/C++.sublime-build",
							"Run"
						]
					],
					[
						"Packages/Python/Python.sublime-build",
						""
					]
				],
				[
					[
						[
							"Packages/User/C++.sublime-build",
							""
						],
						[
							"Packages/User/C++.sublime-build",
							"Run"
						]
					],
					[
						"Packages/User/C++.sublime-build",
						"Run"
					]
				]
			],
			"build_varint": "",
			"command_palette":
			{
				"height": 392.0,
				"last_filter": "",
				"selected_items":
				[
					[
						"Package Control: ",
						"Package Control: Install Package"
					],
					[
						"Package Control: ins",
						"Package Control: Install Package"
					],
					[
						"in",
						"Package Control: Install Package"
					],
					[
						"pac",
						"Package Control: Install Package"
					],
					[
						"outli",
						"Browse Mode: Outline (Left)"
					],
					[
						"instal",
						"Package Control: Install Package"
					],
					[
						"Snippet: ",
						"Snippet: #include <…>"
					],
					[
						"insta",
						"Package Control: Install Package"
					],
					[
						"Snippet: int",
						"Snippet: printf …"
					],
					[
						"install",
						"Package Control: Install Package"
					],
					[
						"Package Control: install",
						"Package Control: Install Package"
					],
					[
						"ins",
						"Package Control: Install Package"
					],
					[
						"menu",
						"View: Toggle Menu"
					],
					[
						"Snippet: ip",
						"Snippet: ipython"
					],
					[
						"Snippet:",
						"Snippet: __magic__"
					],
					[
						"parkage",
						"Package Control: Install Package"
					],
					[
						"python",
						"Set Syntax: Python"
					]
				],
				"width": 551.0
			},
			"console":
			{
				"height": 502.0,
				"history":
				[
					"exit",
					"ls"
				]
			},
			"distraction_free":
			{
				"menu_visible": true,
				"show_minimap": false,
				"show_open_files": false,
				"show_tabs": false,
				"side_bar_visible": false,
				"status_bar_visible": false
			},
			"expanded_folders":
			[
				"/home/mmphego/mnt/cmc3/usr/local/src",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
				"/home/mmphego/mnt/cmc3/srv/corr2",
				"/home/mmphego/mnt/cmc3/home/alec/katsdpingest",
				"/home/mmphego/mnt/cmc3/home/mmphego/learning_fast"
			],
			"file_history":
			[
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/Logger.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/logger.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/test_cbf.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/utils.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/__init__.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/corr2_rx.py",
				"/home/mmphego/mnt/cmc3/home/alec/katsdpingest/katsdpingest/receiver.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/build/lib.linux-x86_64-2.7/casperfpga/casperfpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/aqf_utils.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_fengops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/instrument.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/beam.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_bengops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/xhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/sensors.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_xengops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/fxcorrelator_filterops.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/filthost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/corr2/corr2LogHandlers.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/bhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/data_stream.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/dsimhost_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/host_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/fxcorrelator.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/src/transport_skarab.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/casperfpga/transport_skarab.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/corr2/fxcorrelator.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/lib.linux-x86_64-2.7/corr2/fhost_fpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/corr2/host_fpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/.venv/lib/python2.7/site-packages/corr2/fhost_fpga.py",
				"/home/mmphego/GitHub/My-Dockerfiles/fast.ai/Dockerfile",
				"/home/mmphego/GitHub/corr2/corr2/fxcorrelator.py",
				"/home/mmphego/GitHub/corr2/src/corr2LogHandlers.py",
				"/home/mmphego/GitHub/corr2/src/fxcorrelator.py",
				"/home/mmphego/GitHub/corr2/corr2/instrument.py",
				"/home/mmphego/GitHub/new_DSTV_A6_esp8266_IRRemote/.piolibdeps/ArduinoJson/third-party/catch/catch.hpp",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/Corr_RX.py",
				"/home/mmphego/GitHub/corr2/src/host_fpga.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/delays_debugging.sh",
				"/home/mmphego/GitHub/My-Dockerfiles/fast.ai/Makefile",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-11-05-My-docker-container-has-no-internet.md",
				"/home/mmphego/GitHub/My-Dockerfiles/fast.ai/README.md",
				"/home/mmphego/GitHub/learning_fastai/Dockerfile",
				"/home/mmphego/mnt/cmc3/home/mmphego/learning_fast/Dockerfile",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/.coverage",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/casperfpga/utils.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/dsimhost_fpga.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/sensor_poll.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/run_cbf_tests.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/setup_virtualenv.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/pre_setup.sh",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/poll.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/Dockerfile",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/DockerfileSensorPoll",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/cbf_sensors_dash.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/Makefile",
				"/home/mmphego/mnt/cmc3/home/mmphego/temp/index.html",
				"/home/mmphego/mnt/cmc3/home/mmphego/temp/test.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/temp/flask.py",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/rx_test_4.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/config/test_conf_site.ini",
				"/home/mmphego/.config/sublime-text-3/Packages/User/highlight_duplicates.sublime-settings",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-09-25-Automated-Qualification-Testing-for-the-64-Antennas-MeerKAT-Correlator-Beamformer.md",
				"/home/mmphego/Dropbox/MEng_Stuff/CPUT Logistics/ITS CPUT Logins",
				"/home/mmphego/Dropbox/BTech Project/Proposal and Reports 2015/Final Report/test.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Notes/Section B/Literature-Review.md",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Proposal_Latex/misc/abbreviations.tex",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/README.md",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/Makefile",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/json_dumps/sensor_values.json",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src/pip-requirements.txt",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/corr2_sensor_servlet.py",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-10-23-How-I-configured-JenkinsCI-server-in-a-Docker-container-2.md",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/readme.md",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/Dockerfile",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-08-28-How-I-configured-JenkinsCI-server-in-a-Docker-container-2.md",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-08-20-How-I-configured-JenkinsCI-server-in-a-Docker-container.md",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/Jenkinsfile",
				"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation/fabfile.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/src/corr2LogHandlers.py",
				"/tmp/mozilla_mmphego0/code.py",
				"/home/mmphego/mnt/cmc3/usr/local/src/git-hooks/hooks/pre-commit",
				"/home/mmphego/mnt/cmc3/usr/local/src/nosekatreport/nosekatreport/decorators.py",
				"/home/mmphego/GitHub/mmphego.github.io/_posts/2018-10-22-Better-Git-Commit-Messages-using-Templates.md",
				"/tmp/mozilla_mmphego0/dbelab06ProfilerResultsSortedByNoCalls.txt",
				"/home/mmphego/mnt/cmc3/usr/local/src/git-hooks/templates/README.md",
				"/home/mmphego/.cache/.fr-R9JoZp/WhatsApp Chat with Mpho.txt",
				"/home/mmphego/mnt/cmc3/usr/local/src/git-hooks/README.md",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/example.bib",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/main.tex",
				"/home/mmphego/.cache/.fr-vRhRD6/main.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/Appendices/AppendixA.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/Appendices/AppendixTemplate.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/main.aux",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/MastersThesis.cls",
				"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Tests/MastersDoctoralThesis.cls",
				"/home/mmphego/Dropbox/MEng_Stuff/Tests/Chapters/ChapterTemplate.tex",
				"/home/mmphego/Dropbox/MEng_Stuff/Tests/Chapters/.Chapter1.tex.swp",
				"/home/mmphego/Dropbox/MEng_Stuff/Tests/Chapters/Chapter1.tex",
				"/home/mmphego/.cache/.fr-nEtW8x/LibreOffice_6.1.2.1_Linux_x86-64_deb/readmes/README_en-US",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/test.txt",
				"/home/mmphego/mnt/cmc3/srv/corr2/debug/vaccbug/inspect_rx_packets.py",
				"/home/mmphego/.cache/.fr-WV1LlY/python-data-science/03-matplotlib/02-matplotlib-subplots.ipynb",
				"/home/mmphego/mnt/cmc3/srv/corr2/build/scripts-2.7/corr2_rx.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/scripts/corr2_dsim_control.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/src/casperfpga.py",
				"/home/mmphego/mnt/cmc3/srv/corr2/corr2/host_fpga.py",
				"/home/mmphego/mnt/cmc3/srv/casperfpga/src/transport_tapcp.py",
				"/tmp/mozilla_mmphego0/errorband_lineplots.py",
				"/home/mmphego/GitHub/mmphego.github.io/must-watch-talks.md",
				"/home/mmphego/GitHub/linkedin/http_api.py",
				"/home/mmphego/GitHub/linkedin/.env",
				"/home/mmphego/mnt/cmc3/home/alec/katsdpingest/spead2/examples/test_recv.py",
				"/home/mmphego/Python/python-data-science/Makefile",
				"/home/mmphego/GitHub/linkedin/linkedin.py",
				"/home/mmphego/Python/python-data-science/README.md",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/spead2_rx_debug.py",
				"/home/mmphego/GitHub/mmphego.github.io/resume.html",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/Makefile",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/init_instrument_3.sh",
				"/home/mmphego/GitHub/mmphego.github.io/_data/resume.yml",
				"/home/mmphego/GitHub/mmphego.github.io/mentions.md",
				"/home/mmphego/GitHub/mmphego.github.io/assets/devopsdays.jpeg",
				"/home/mmphego/.cache/.fr-rqHVKv/netl1c63x64.inf",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/check_dep_2.sh",
				"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts/Jenkins_Scripts/install_dep_1.sh"
			],
			"find":
			{
				"height": 39.0
			},
			"find_in_files":
			{
				"height": 352.0,
				"where_history":
				[
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/test_cbf.py",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/srv/casperfpga",
					"/home/mmphego/mnt/cmc3/srv/corr2/src",
					"/home/mmphego/mnt/cmc3/usr/local/src/CBF-System-Dashboard/src",
					"/home/mmphego/GitHub/mmphego.github.io",
					"/home/mmphego/mnt/cmc3/srv/corr2",
					"/home/mmphego/mnt/cmc3/srv/casperfpga/src",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/srv/casperfpga",
					"/home/mmphego/mnt/cmc3/srv/corr2/src",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/scripts",
					"/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
					"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation",
					"/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Notes/Summarised.Papers",
					"/home/mmphego/mnt/cmc3/usr/local/src/CBF-Tests-Automation",
					"/home/mmphego/mnt/cmc1/home/avnuser/AVNTests/AVNTests/avn_tests",
					"/home/mmphego/mnt/cmc1/home/avnuser/AVNTests/AVNTests",
					"/home/mmphego/mnt/cmc3/usr/local/src/katcp-python",
					"/home/mmphego/mnt/cmc3/usr/local/src/corr2",
					"/home/mmphego/mnt/cmc3/usr/local/src/corr2/src"
				]
			},
			"find_state":
			{
				"case_sensitive": true,
				"find_history":
				[
					"self.Failed(errmsg)\nself.Error(errmsg, exc_info=True)",
					"self.Failed(errmsg)\nself.Error(errmsg, exc_info=True)\n",
					"self.Error(errmsg, exc_info=True)",
					"            self.Failed(errmsg)\n            self.Error(errmsg, exc_info=True)\n",
					"            errmsg = \"Exception\"\n            self.Failed(errmsg)\n",
					"\"Exception: {}\".format(str(e))",
					"self.Failed(errmsg)",
					"self.Error(errmsg, exc_info=True)",
					"\n            ",
					"self.Error(errmsg, exc_info=True)\n",
					"self.Error(errmsg, exc_info=True)",
					"self.logger.error(errmsg)",
					"%s\" % str(e)",
					"TypeError as e",
					"except Exception as e",
					"            self.Failed(errmsg)\n",
					"except E",
					"Aqf.note",
					"            self.Failed(errmsg)\n",
					"self.Failed(errmsg)",
					"except",
					"self.logger.exception",
					"exc_info=True",
					"Aqf.failed",
					"Aqf.progress",
					"Aqf.step",
					"_logLevel",
					"get_username",
					"setLevel",
					"self.logger",
					"LOGGER",
					"getLogger",
					"LOGGER",
					"setlevel",
					"setLe",
					"LOGGER",
					"_logLevel",
					"LOGGER",
					"set_input_levels",
					"add_cleanup",
					"LOGGER",
					"self._frames",
					"_read_stream",
					"get_delay_bounds",
					"DTIME",
					"pdebug",
					"corr_config",
					"raise",
					"CorrReceiver",
					"print ",
					"LoggingClass",
					"handler",
					"self",
					"corr_instance",
					"self",
					"DictObject",
					"evaluate_corr",
					"#!/",
					"test_heading",
					"logging.ERROR",
					"ERROR",
					"logging.ERROR",
					"ERROR",
					"logging.ERROR",
					"IPyt",
					"FEngineOperations",
					"LOGGER",
					"IPython",
					"self.init",
					"initialise",
					"FEngineOperations",
					"configure",
					"logging.INFO",
					"log_level=INFO",
					"INFO",
					"getLogger",
					"logLevel",
					"INFO",
					"FpgaHost",
					"IPy",
					"FpgaHost",
					"SkarabTransport",
					"__init__",
					"SkarabTransport",
					"IPyth",
					"getLogger",
					"INFO",
					"getLogger",
					"INFO",
					"_create_hosts",
					"INFO",
					"info",
					"INFO",
					"\\\n",
					"IPy",
					"print",
					"_test_delay_tracking",
					"get_sensors",
					"sync_time",
					"get_sensors",
					"scale_factor_timestamp",
					"scale_f",
					"process_xeng_data",
					"logger",
					"Logger",
					"LOGGER",
					"self.logger",
					"logger",
					"Logger",
					"LOGGER",
					"_spead_stream",
					"corr2_rx",
					"corr2",
					"%i",
					"FATAL",
					"jenkins",
					"_delays_setup",
					"_test_report_config",
					"fft_shift = 511",
					"gain = \"113+0j\"",
					"awgn_scale = 0.0645",
					"cw_scale",
					"self.get_clean_dump()",
					"self.get_clean_dump",
					"get_clean_dump",
					"print (time.",
					"\n        ",
					"\n    "
				],
				"highlight": false,
				"in_selection": false,
				"preserve_case": false,
				"regex": false,
				"replace_history":
				[
					"self.Note",
					"self.Failed",
					"self.Progress",
					"self.Step",
					"self.logger",
					"heading",
					"_logLevel",
					"self.receiver.get_clean_dump()",
					"     ",
					"SensorPoll",
					"channels",
					"network",
					"Warning -m pip",
					"$(command -v  python) -W ignore::Warning pip",
					"Section-A",
					"-",
					"avn_tests"
				],
				"reverse": false,
				"show_context": true,
				"use_buffer2": true,
				"whole_word": false,
				"wrap": false
			},
			"folders":
			[
				{
					"path": "/home/mmphego/GitHub"
				},
				{
					"path": "/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress"
				},
				{
					"path": "/home/mmphego/mnt/cmc3/usr/local/src"
				},
				{
					"path": "/home/mmphego/Dropbox/MEng_Stuff/MEng-Progress/Notes"
				},
				{
					"path": "/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests"
				},
				{
					"path": "/home/mmphego/mnt/cmc3/srv/corr2"
				},
				{
					"path": "/home/mmphego/mnt/cmc3/srv/casperfpga"
				},
				{
					"path": "/home/mmphego/mnt/cmc3/home/alec/katsdpingest"
				},
				{
					"path": "/home/mmphego/exercism"
				},
				{
					"path": "/home/mmphego/mnt/cmc3/home/mmphego/learning_fast"
				}
			],
			"groups":
			[
				{
					"selected": 1,
					"sheets":
					[
						{
							"buffer": 0,
							"file": "mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/__init__.py",
							"semi_transient": false,
							"settings":
							{
								"buffer_size": 33557,
								"regions":
								{
								},
								"selection":
								[
									[
										0,
										0
									]
								],
								"settings":
								{
									"bracket_highlighter.busy": false,
									"bracket_highlighter.clone": -1,
									"bracket_highlighter.clone_locations":
									{
										"close":
										{
											"1":
											[
												2272,
												2273
											]
										},
										"icon":
										{
											"1":
											[
												"Packages/BracketHighlighter/icons/double_quote.png",
												"region.greenish"
											]
										},
										"open":
										{
											"1":
											[
												2261,
												2262
											]
										},
										"unmatched":
										{
										}
									},
									"bracket_highlighter.clone_regions":
									[
										"bh_unmatched",
										"bh_unmatched_center",
										"bh_unmatched_open",
										"bh_unmatched_close",
										"bh_unmatched_content",
										"bh_angle",
										"bh_angle_center",
										"bh_angle_open",
										"bh_angle_close",
										"bh_angle_content",
										"bh_round",
										"bh_round_center",
										"bh_round_open",
										"bh_round_close",
										"bh_round_content",
										"bh_double_quote",
										"bh_double_quote_center",
										"bh_double_quote_open",
										"bh_double_quote_close",
										"bh_double_quote_content",
										"bh_curly",
										"bh_curly_center",
										"bh_curly_open",
										"bh_curly_close",
										"bh_curly_content",
										"bh_single_quote",
										"bh_single_quote_center",
										"bh_single_quote_open",
										"bh_single_quote_close",
										"bh_single_quote_content",
										"bh_regex",
										"bh_regex_center",
										"bh_regex_open",
										"bh_regex_close",
										"bh_regex_content",
										"bh_c_define",
										"bh_c_define_center",
										"bh_c_define_open",
										"bh_c_define_close",
										"bh_c_define_content",
										"bh_default",
										"bh_default_center",
										"bh_default_open",
										"bh_default_close",
										"bh_default_content",
										"bh_square",
										"bh_square_center",
										"bh_square_open",
										"bh_square_close",
										"bh_square_content",
										"bh_tag",
										"bh_tag_center",
										"bh_tag_open",
										"bh_tag_close",
										"bh_tag_content"
									],
									"bracket_highlighter.locations":
									{
										"close":
										{
										},
										"icon":
										{
										},
										"open":
										{
										},
										"unmatched":
										{
										}
									},
									"bracket_highlighter.regions":
									[
										"bh_unmatched",
										"bh_unmatched_center",
										"bh_unmatched_open",
										"bh_unmatched_close",
										"bh_unmatched_content",
										"bh_angle",
										"bh_angle_center",
										"bh_angle_open",
										"bh_angle_close",
										"bh_angle_content",
										"bh_round",
										"bh_round_center",
										"bh_round_open",
										"bh_round_close",
										"bh_round_content",
										"bh_double_quote",
										"bh_double_quote_center",
										"bh_double_quote_open",
										"bh_double_quote_close",
										"bh_double_quote_content",
										"bh_curly",
										"bh_curly_center",
										"bh_curly_open",
										"bh_curly_close",
										"bh_curly_content",
										"bh_single_quote",
										"bh_single_quote_center",
										"bh_single_quote_open",
										"bh_single_quote_close",
										"bh_single_quote_content",
										"bh_regex",
										"bh_regex_center",
										"bh_regex_open",
										"bh_regex_close",
										"bh_regex_content",
										"bh_c_define",
										"bh_c_define_center",
										"bh_c_define_open",
										"bh_c_define_close",
										"bh_c_define_content",
										"bh_default",
										"bh_default_center",
										"bh_default_open",
										"bh_default_close",
										"bh_default_content",
										"bh_square",
										"bh_square_center",
										"bh_square_open",
										"bh_square_close",
										"bh_square_content",
										"bh_tag",
										"bh_tag_center",
										"bh_tag_open",
										"bh_tag_close",
										"bh_tag_content"
									],
									"function_name_status_row": 0,
									"git_gutter_is_enabled": true,
									"show_definitions": false,
									"syntax": "Packages/Python/Python.sublime-syntax",
									"tab_size": 4,
									"translate_tabs_to_spaces": true
								},
								"translation.x": 0.0,
								"translation.y": 1171.0,
								"zoom_level": 1.0
							},
							"stack_index": 2,
							"type": "text"
						},
						{
							"buffer": 1,
							"file": "mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests/test_cbf.py",
							"semi_transient": false,
							"settings":
							{
								"buffer_size": 403055,
								"regions":
								{
								},
								"selection":
								[
									[
										3793,
										3793
									]
								],
								"settings":
								{
									"bracket_highlighter.busy": false,
									"bracket_highlighter.clone": -1,
									"bracket_highlighter.clone_locations":
									{
										"close":
										{
										},
										"icon":
										{
										},
										"open":
										{
										},
										"unmatched":
										{
											"1":
											[
												3806,
												3807
											]
										}
									},
									"bracket_highlighter.clone_regions":
									[
										"bh_curly",
										"bh_curly_center",
										"bh_curly_open",
										"bh_curly_close",
										"bh_curly_content",
										"bh_double_quote",
										"bh_double_quote_center",
										"bh_double_quote_open",
										"bh_double_quote_close",
										"bh_double_quote_content",
										"bh_angle",
										"bh_angle_center",
										"bh_angle_open",
										"bh_angle_close",
										"bh_angle_content",
										"bh_square",
										"bh_square_center",
										"bh_square_open",
										"bh_square_close",
										"bh_square_content",
										"bh_c_define",
										"bh_c_define_center",
										"bh_c_define_open",
										"bh_c_define_close",
										"bh_c_define_content",
										"bh_single_quote",
										"bh_single_quote_center",
										"bh_single_quote_open",
										"bh_single_quote_close",
										"bh_single_quote_content",
										"bh_default",
										"bh_default_center",
										"bh_default_open",
										"bh_default_close",
										"bh_default_content",
										"bh_round",
										"bh_round_center",
										"bh_round_open",
										"bh_round_close",
										"bh_round_content",
										"bh_regex",
										"bh_regex_center",
										"bh_regex_open",
										"bh_regex_close",
										"bh_regex_content",
										"bh_unmatched",
										"bh_unmatched_center",
										"bh_unmatched_open",
										"bh_unmatched_close",
										"bh_unmatched_content",
										"bh_tag",
										"bh_tag_center",
										"bh_tag_open",
										"bh_tag_close",
										"bh_tag_content"
									],
									"bracket_highlighter.locations":
									{
										"close":
										{
										},
										"icon":
										{
										},
										"open":
										{
										},
										"unmatched":
										{
										}
									},
									"bracket_highlighter.regions":
									[
										"bh_curly",
										"bh_curly_center",
										"bh_curly_open",
										"bh_curly_close",
										"bh_curly_content",
										"bh_double_quote",
										"bh_double_quote_center",
										"bh_double_quote_open",
										"bh_double_quote_close",
										"bh_double_quote_content",
										"bh_angle",
										"bh_angle_center",
										"bh_angle_open",
										"bh_angle_close",
										"bh_angle_content",
										"bh_square",
										"bh_square_center",
										"bh_square_open",
										"bh_square_close",
										"bh_square_content",
										"bh_c_define",
										"bh_c_define_center",
										"bh_c_define_open",
										"bh_c_define_close",
										"bh_c_define_content",
										"bh_single_quote",
										"bh_single_quote_center",
										"bh_single_quote_open",
										"bh_single_quote_close",
										"bh_single_quote_content",
										"bh_default",
										"bh_default_center",
										"bh_default_open",
										"bh_default_close",
										"bh_default_content",
										"bh_round",
										"bh_round_center",
										"bh_round_open",
										"bh_round_close",
										"bh_round_content",
										"bh_regex",
										"bh_regex_center",
										"bh_regex_open",
										"bh_regex_close",
										"bh_regex_content",
										"bh_unmatched",
										"bh_unmatched_center",
										"bh_unmatched_open",
										"bh_unmatched_close",
										"bh_unmatched_content",
										"bh_tag",
										"bh_tag_center",
										"bh_tag_open",
										"bh_tag_close",
										"bh_tag_content"
									],
									"function_name_status_row": 113,
									"git_gutter_is_enabled": true,
									"show_definitions": false,
									"syntax": "Packages/Python/Python.sublime-syntax",
									"tab_size": 4,
									"translate_tabs_to_spaces": true
								},
								"translation.x": 0.0,
								"translation.y": 585.0,
								"zoom_level": 1.0
							},
							"stack_index": 0,
							"type": "text"
						},
						{
							"buffer": 2,
							"semi_transient": false,
							"settings":
							{
								"buffer_size": 28611,
								"regions":
								{
									"match":
									{
										"flags": 112,
										"regions":
										[
											[
												323,
												331
											],
											[
												628,
												636
											],
											[
												896,
												904
											],
											[
												1148,
												1156
											],
											[
												1521,
												1529
											],
											[
												1890,
												1898
											],
											[
												2183,
												2191
											],
											[
												2499,
												2507
											],
											[
												2786,
												2794
											],
											[
												3066,
												3074
											],
											[
												3346,
												3354
											],
											[
												3587,
												3595
											],
											[
												3907,
												3915
											],
											[
												4239,
												4247
											],
											[
												4625,
												4633
											],
											[
												4948,
												4956
											],
											[
												5248,
												5256
											],
											[
												5555,
												5563
											],
											[
												5869,
												5877
											],
											[
												6145,
												6153
											],
											[
												6438,
												6446
											],
											[
												6725,
												6733
											],
											[
												7033,
												7041
											],
											[
												7369,
												7377
											],
											[
												7739,
												7747
											],
											[
												8138,
												8146
											],
											[
												8529,
												8537
											],
											[
												8903,
												8911
											],
											[
												9256,
												9264
											],
											[
												9638,
												9646
											],
											[
												9912,
												9920
											],
											[
												10114,
												10122
											],
											[
												10374,
												10382
											],
											[
												10718,
												10726
											],
											[
												11005,
												11013
											],
											[
												11293,
												11301
											],
											[
												11572,
												11580
											],
											[
												11840,
												11848
											],
											[
												12151,
												12159
											],
											[
												12459,
												12467
											],
											[
												12719,
												12727
											],
											[
												13060,
												13068
											],
											[
												13374,
												13382
											],
											[
												13735,
												13743
											],
											[
												14026,
												14034
											],
											[
												14359,
												14367
											],
											[
												14571,
												14579
											],
											[
												14980,
												14988
											],
											[
												15319,
												15327
											],
											[
												15614,
												15622
											],
											[
												15992,
												16000
											],
											[
												16317,
												16325
											],
											[
												16650,
												16658
											],
											[
												16967,
												16975
											],
											[
												17170,
												17178
											],
											[
												17433,
												17441
											],
											[
												17666,
												17674
											],
											[
												17888,
												17896
											],
											[
												18105,
												18113
											],
											[
												18429,
												18437
											],
											[
												18750,
												18758
											],
											[
												19024,
												19032
											],
											[
												19237,
												19245
											],
											[
												19477,
												19485
											],
											[
												19689,
												19697
											],
											[
												20024,
												20032
											],
											[
												20360,
												20368
											],
											[
												20740,
												20748
											],
											[
												20984,
												20992
											],
											[
												21269,
												21277
											],
											[
												21557,
												21565
											],
											[
												21850,
												21858
											],
											[
												22191,
												22199
											],
											[
												22481,
												22489
											],
											[
												22749,
												22757
											],
											[
												22984,
												22992
											],
											[
												23197,
												23205
											],
											[
												23410,
												23418
											],
											[
												23623,
												23631
											],
											[
												23863,
												23871
											],
											[
												24119,
												24127
											],
											[
												24368,
												24376
											],
											[
												24580,
												24588
											],
											[
												24791,
												24799
											],
											[
												25067,
												25075
											],
											[
												25314,
												25322
											],
											[
												25561,
												25569
											],
											[
												25808,
												25816
											],
											[
												26043,
												26051
											],
											[
												26277,
												26285
											],
											[
												26529,
												26537
											],
											[
												26769,
												26777
											],
											[
												27135,
												27143
											],
											[
												27518,
												27526
											],
											[
												27847,
												27855
											],
											[
												28198,
												28206
											],
											[
												28445,
												28453
											]
										],
										"scope": ""
									}
								},
								"selection":
								[
									[
										5253,
										5253
									]
								],
								"settings":
								{
									"bracket_highlighter.busy": false,
									"bracket_highlighter.clone": -1,
									"bracket_highlighter.locations":
									{
										"close":
										{
										},
										"icon":
										{
										},
										"open":
										{
										},
										"unmatched":
										{
											"1":
											[
												4995,
												4996
											]
										}
									},
									"bracket_highlighter.regions":
									[
										"bh_unmatched",
										"bh_unmatched_center",
										"bh_unmatched_open",
										"bh_unmatched_close",
										"bh_unmatched_content",
										"bh_angle",
										"bh_angle_center",
										"bh_angle_open",
										"bh_angle_close",
										"bh_angle_content",
										"bh_round",
										"bh_round_center",
										"bh_round_open",
										"bh_round_close",
										"bh_round_content",
										"bh_double_quote",
										"bh_double_quote_center",
										"bh_double_quote_open",
										"bh_double_quote_close",
										"bh_double_quote_content",
										"bh_curly",
										"bh_curly_center",
										"bh_curly_open",
										"bh_curly_close",
										"bh_curly_content",
										"bh_single_quote",
										"bh_single_quote_center",
										"bh_single_quote_open",
										"bh_single_quote_close",
										"bh_single_quote_content",
										"bh_regex",
										"bh_regex_center",
										"bh_regex_open",
										"bh_regex_close",
										"bh_regex_content",
										"bh_c_define",
										"bh_c_define_center",
										"bh_c_define_open",
										"bh_c_define_close",
										"bh_c_define_content",
										"bh_default",
										"bh_default_center",
										"bh_default_open",
										"bh_default_close",
										"bh_default_content",
										"bh_square",
										"bh_square_center",
										"bh_square_open",
										"bh_square_close",
										"bh_square_content",
										"bh_tag",
										"bh_tag_center",
										"bh_tag_open",
										"bh_tag_close",
										"bh_tag_content"
									],
									"default_dir": "/home/mmphego/mnt/cmc3/home/mmphego/src/mkat_fpga_tests/mkat_fpga_tests",
									"detect_indentation": false,
									"function_name_status_row": 101,
									"git_gutter_is_enabled": false,
									"line_numbers": false,
									"output_tag": 1,
									"result_base_dir": "",
									"result_file_regex": "^([^ \t].*):$",
									"result_line_regex": "^ +([0-9]+):",
									"scroll_past_end": true,
									"syntax": "Packages/Default/Find Results.hidden-tmLanguage",
									"translate_tabs_to_spaces": false
								},
								"translation.x": 0.0,
								"translation.y": 855.0,
								"zoom_level": 1.0
							},
							"stack_index": 1,
							"type": "text"
						}
					]
				}
			],
			"incremental_find":
			{
				"height": 27.0
			},
			"input":
			{
				"height": 123.0
			},
			"layout":
			{
				"cells":
				[
					[
						0,
						0,
						1,
						1
					]
				],
				"cols":
				[
					0.0,
					1.0
				],
				"rows":
				[
					0.0,
					1.0
				]
			},
			"menu_visible": true,
			"output.1484047395.6373365":
			{
				"height": 38.0
			},
			"output.build|/home/mmphego/Apts/arduino-1.6.12/test|1500630185.3137703":
			{
				"height": 118.0
			},
			"output.build|/home/mmphego/Apts/arduino-1.6.12/test|1500630228.8832595":
			{
				"height": 118.0
			},
			"output.clangautocomplete":
			{
				"height": 171.0
			},
			"output.exec":
			{
				"height": 37.0
			},
			"output.find_results":
			{
				"height": 0.0
			},
			"output.mdpopups":
			{
				"height": 0.0
			},
			"output.unsaved_changes":
			{
				"height": 132.0
			},
			"output.upload|/home/mmphego/Arduino/hcsr04|1488449906.015194":
			{
				"height": 94.0
			},
			"output.upload|/home/mmphego/OneDrive/Documents/Proposal 2016/HomeAutoPi/MQTT Pub/mqtt_esp8266_nodemcuV2|1484047356.5805616":
			{
				"height": 178.0
			},
			"pinned_build_system": "",
			"position": "0,1,0,0,0,0,0,1200,1856,3120,1920",
			"project": "",
			"replace":
			{
				"height": 94.0
			},
			"save_all_on_build": false,
			"select_file":
			{
				"height": 0.0,
				"last_filter": "",
				"selected_items":
				[
					[
						"test",
						"mkat_fpga_tests/test_cbf.py"
					],
					[
						"repor",
						"report_generator/report.py"
					],
					[
						"943",
						"CBF_tests_reports/bc8n856M32k-20170911-14h22/html/_static/jquery-3.1.0.js"
					],
					[
						"baseline",
						"mkat_fpga_tests/ipython_notebooks/experimental/baseline_product_test.ipynb"
					],
					[
						"",
						"PFB_ch_test.py~"
					]
				],
				"width": 0.0
			},
			"select_project":
			{
				"height": 500.0,
				"last_filter": "",
				"selected_items":
				[
				],
				"width": 380.0
			},
			"select_symbol":
			{
				"height": 392.0,
				"last_filter": "",
				"selected_items":
				[
				],
				"width": 1308.0
			},
			"selected_group": 0,
			"settings":
			{
			},
			"show_minimap": false,
			"show_open_files": true,
			"show_tabs": true,
			"side_bar_visible": true,
			"side_bar_width": 240.0,
			"status_bar_visible": true,
			"template_settings":
			{
				"max_columns": 2
			},
			"window_id": 168,
			"workspace_name": "/home/mmphego/projects.sublime-workspace"
		}
	],
	"workspaces":
	{
		"recent_workspaces":
		[
			"/home/mmphego/projects.sublime-workspace",
			"/home/mmphego/Documents/untitled.sublime-workspace"
		]
	}
}
